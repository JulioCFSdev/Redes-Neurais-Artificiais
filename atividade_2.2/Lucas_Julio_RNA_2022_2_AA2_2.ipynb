{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulioCFSdev/Redes-Neurais-Artificiais/blob/main/atividade_2.2/Lucas_Julio_RNA_2022_2_AA2_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJtcr0Xkv6Fo"
      },
      "source": [
        "# Redes Neurais Artificiais 2022.2\n",
        "## Atividade Avaliativa 2.2\n",
        "\n",
        "- **Disciplina**: Redes Neurais Artificiais 2022.2  \n",
        "- **Professora**: Elloá B. Guedes (ebgcosta@uea.edu.br)  \n",
        "- **Github**: http://github.com/elloa  \n",
        "\n",
        "O Abalone é um gênero (_Haliotis_) de um moluscos gastrópodes marinhos da família _Haliotidae_. Foi identificado por Linnaeus em 1758 e suas diversas espécies podem ser encontradas em águas costeiras de quase todo o mundo. É usado na indústria alimentícia e em itens decorativos, tais como jóias ou instrumentos musicais [1](https://pt.wikipedia.org/wiki/Abalone). A idade do abalone pode ser obtida diretamente a partir de medidas físicas, porém é necessário cortar a concha, efetuar um processo de pigmentação, e então contar o número de anéis por meio de um microscópio -- tarefa considerada monótona e custosa [2](https://archive.ics.uci.edu/ml/datasets/Abalone).\n",
        "\n",
        "Outras medidas do Abalone, entretanto, são mais fáceis de obter, não danificam a concha e podem ser utilizadas para estimar a idade com um modelo inteligente por meio de um processo de Aprendizado Supervisionado. Nesta Atividade Avaliativa de caráter prático, almeja-se a proposição e avaliação de múltiplas Redes Neurais Artificiais (RNAs) do tipo _Feedforward Multilayer Perceptron_ (MLP) para o problema da classificação multi-classe da idade do abalone a partir de atributos preditores.\n",
        "\n",
        "Base de dados original: https://archive.ics.uci.edu/ml/datasets/Abalone  \n",
        "Base de dados preparada: abalone.csv (Disponível no Google Classroom)  \n",
        "Base de dados a ser utilizada: abalone.csv com One-Hot-Encoding do atributo Sex (exportar a partir da Atividade Avaliativa 1.2)\n",
        "\n",
        "## Equipe\n",
        "\n",
        "Integrante 1 (Matrícula)  \n",
        "Integrante 2 (Matrícula)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avKM19wvXzpF"
      },
      "outputs": [],
      "source": [
        "## bibliotecas\n",
        "##Equipe = {\n",
        "##    Lucas: (2115310015),\n",
        "##    Julio: (2115310019)\n",
        "##}\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IAJCmcWXzpG"
      },
      "source": [
        "## Aquecimento\n",
        "\n",
        "1. Abrir a base de dados\n",
        "2. Separar os atributos preditores (X) e o atributo-alvo (y) nas respectivas variáveis\n",
        "3. Imprimir a dimensão da base de dados (quantidade de exemplos, quantidade de atributos preditores)\n",
        "4. Efetue uma partição holdout 70/30 com o sklearn, distribuindo os exemplos de maneira aleatória"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYbQuIUfXzpH"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/JulioCFSdev/Redes-Neurais-Artificiais/main/atividade_2.2/abalone-One-Hot-Encoding.csv?token=GHSAT0AAAAAAB46FRJ33OA3AVRZPV2S6ZHQY7ZGJGA'\n",
        "data = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUY95U0QXzpI",
        "outputId": "88414bc1-f0d6-4cdf-efce-f3009ae42acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4176\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4176 entries, 0 to 4175\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Length          4176 non-null   float64\n",
            " 1   Diameter        4176 non-null   float64\n",
            " 2   Height          4176 non-null   float64\n",
            " 3   Whole weight    4176 non-null   float64\n",
            " 4   Shucked weight  4176 non-null   float64\n",
            " 5   Viscera weight  4176 non-null   float64\n",
            " 6   Shell weight    4176 non-null   float64\n",
            " 7   Age             4176 non-null   int64  \n",
            " 8   Sex_F           4176 non-null   int64  \n",
            " 9   Sex_I           4176 non-null   int64  \n",
            " 10  Sex_M           4176 non-null   int64  \n",
            "dtypes: float64(7), int64(4)\n",
            "memory usage: 359.0 KB\n"
          ]
        }
      ],
      "source": [
        "print(len(data))\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPj9vyajXzpI"
      },
      "outputs": [],
      "source": [
        "predictive_attributes = data.drop(columns=['Age'], axis=1)\n",
        "target_attributes = data.Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "abBFbJM_wIWM",
        "outputId": "05980307-13ed-4be9-caa7-25789f4064fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantidade de atributos preditores : 4176\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6f3ac26a-ad9f-45f0-9e0d-c95b0fcee5a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_I</th>\n",
              "      <th>Sex_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.350</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.0995</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.530</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.6770</td>\n",
              "      <td>0.2565</td>\n",
              "      <td>0.1415</td>\n",
              "      <td>0.210</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.440</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.5160</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.155</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.330</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.0895</td>\n",
              "      <td>0.0395</td>\n",
              "      <td>0.055</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.425</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.3515</td>\n",
              "      <td>0.1410</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f3ac26a-ad9f-45f0-9e0d-c95b0fcee5a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f3ac26a-ad9f-45f0-9e0d-c95b0fcee5a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f3ac26a-ad9f-45f0-9e0d-c95b0fcee5a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
              "0   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
              "1   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
              "2   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
              "3   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
              "4   0.425     0.300   0.095        0.3515          0.1410          0.0775   \n",
              "\n",
              "   Shell weight  Sex_F  Sex_I  Sex_M  \n",
              "0         0.070      0      0      1  \n",
              "1         0.210      1      0      0  \n",
              "2         0.155      0      0      1  \n",
              "3         0.055      0      1      0  \n",
              "4         0.120      0      1      0  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Quantidade de atributos preditores : {}\".format(len(predictive_attributes)))\n",
        "predictive_attributes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Amn4z7aa1tk1",
        "outputId": "739badc2-55b0-4a5b-925d-c947df29aeef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8563c9db-bd1b-42f7-a190-f24eb8bd1851\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_I</th>\n",
              "      <th>Sex_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4171</th>\n",
              "      <td>0.565</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.165</td>\n",
              "      <td>0.8870</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.2490</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4172</th>\n",
              "      <td>0.590</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.9660</td>\n",
              "      <td>0.4390</td>\n",
              "      <td>0.2145</td>\n",
              "      <td>0.2605</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4173</th>\n",
              "      <td>0.600</td>\n",
              "      <td>0.475</td>\n",
              "      <td>0.205</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>0.5255</td>\n",
              "      <td>0.2875</td>\n",
              "      <td>0.3080</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>0.625</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.150</td>\n",
              "      <td>1.0945</td>\n",
              "      <td>0.5310</td>\n",
              "      <td>0.2610</td>\n",
              "      <td>0.2960</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>0.710</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.195</td>\n",
              "      <td>1.9485</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.3765</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8563c9db-bd1b-42f7-a190-f24eb8bd1851')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8563c9db-bd1b-42f7-a190-f24eb8bd1851 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8563c9db-bd1b-42f7-a190-f24eb8bd1851');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
              "4171   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
              "4172   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
              "4173   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
              "4174   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
              "4175   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
              "\n",
              "      Shell weight  Sex_F  Sex_I  Sex_M  \n",
              "4171        0.2490      1      0      0  \n",
              "4172        0.2605      0      0      1  \n",
              "4173        0.3080      0      0      1  \n",
              "4174        0.2960      1      0      0  \n",
              "4175        0.4950      0      0      1  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictive_attributes.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVH5_VEdwN7x",
        "outputId": "3312e0ec-eeac-4a2c-e386-a0fa51a90836"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        7\n",
              "1        9\n",
              "2       10\n",
              "3        7\n",
              "4        8\n",
              "        ..\n",
              "4171    11\n",
              "4172    10\n",
              "4173     9\n",
              "4174    10\n",
              "4175    12\n",
              "Name: Age, Length: 4176, dtype: int64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hwlv8LLowljt"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(predictive_attributes, target_attributes,test_size=0.30,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1jEoOsmym8V",
        "outputId": "56d983be-5a0b-46a9-e1bf-4acd783fc45a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train : 2923\n",
            "X_test : 1253\n",
            "Y_train: 2923\n",
            "Y_test : 1253\n",
            "Porcentagem de dados X_train : 0.6999521072796935\n",
            "Porcentagem de dados X_test : 0.3000478927203065\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train : {}\\nX_test : {}\\nY_train: {}\\nY_test : {}\".format(len(X_train),len(X_test), len(Y_train), len(Y_test)))\n",
        "print(\"Porcentagem de dados X_train : {}\\nPorcentagem de dados X_test : {}\".format(len(X_train)/len(data), len(X_test)/len(data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jCiqkVYX2OpA",
        "outputId": "761ddf37-7358-4c08-ed03-19a989d58327"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c1df7774-0584-47ae-8744-be9f2e9e811d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_I</th>\n",
              "      <th>Sex_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2070</th>\n",
              "      <td>0.565</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.8300</td>\n",
              "      <td>0.3930</td>\n",
              "      <td>0.1735</td>\n",
              "      <td>0.2380</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>0.690</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.215</td>\n",
              "      <td>1.7190</td>\n",
              "      <td>0.6800</td>\n",
              "      <td>0.2990</td>\n",
              "      <td>0.4700</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1745</th>\n",
              "      <td>0.700</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.175</td>\n",
              "      <td>1.8565</td>\n",
              "      <td>0.8445</td>\n",
              "      <td>0.3935</td>\n",
              "      <td>0.5400</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1736</th>\n",
              "      <td>0.670</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.155</td>\n",
              "      <td>1.5660</td>\n",
              "      <td>0.8580</td>\n",
              "      <td>0.3390</td>\n",
              "      <td>0.3540</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4151</th>\n",
              "      <td>0.370</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.2180</td>\n",
              "      <td>0.0995</td>\n",
              "      <td>0.0545</td>\n",
              "      <td>0.0615</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012</th>\n",
              "      <td>0.470</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.5220</td>\n",
              "      <td>0.2395</td>\n",
              "      <td>0.1525</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>0.455</td>\n",
              "      <td>0.355</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.4495</td>\n",
              "      <td>0.1770</td>\n",
              "      <td>0.1040</td>\n",
              "      <td>0.1500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2912</th>\n",
              "      <td>0.590</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.150</td>\n",
              "      <td>1.1420</td>\n",
              "      <td>0.4850</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.3450</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3968</th>\n",
              "      <td>0.380</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.2770</td>\n",
              "      <td>0.1655</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.0820</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3671</th>\n",
              "      <td>0.595</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.9640</td>\n",
              "      <td>0.5005</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1253 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1df7774-0584-47ae-8744-be9f2e9e811d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1df7774-0584-47ae-8744-be9f2e9e811d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1df7774-0584-47ae-8744-be9f2e9e811d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
              "2070   0.565     0.440   0.135        0.8300          0.3930          0.1735   \n",
              "368    0.690     0.560   0.215        1.7190          0.6800          0.2990   \n",
              "1745   0.700     0.565   0.175        1.8565          0.8445          0.3935   \n",
              "1736   0.670     0.550   0.155        1.5660          0.8580          0.3390   \n",
              "4151   0.370     0.280   0.090        0.2180          0.0995          0.0545   \n",
              "...      ...       ...     ...           ...             ...             ...   \n",
              "2012   0.470     0.365   0.135        0.5220          0.2395          0.1525   \n",
              "281    0.455     0.355   0.120        0.4495          0.1770          0.1040   \n",
              "2912   0.590     0.500   0.150        1.1420          0.4850          0.2650   \n",
              "3968   0.380     0.300   0.090        0.2770          0.1655          0.0625   \n",
              "3671   0.595     0.440   0.135        0.9640          0.5005          0.1715   \n",
              "\n",
              "      Shell weight  Sex_F  Sex_I  Sex_M  \n",
              "2070        0.2380      1      0      0  \n",
              "368         0.4700      1      0      0  \n",
              "1745        0.5400      0      0      1  \n",
              "1736        0.3540      1      0      0  \n",
              "4151        0.0615      0      1      0  \n",
              "...            ...    ...    ...    ...  \n",
              "2012        0.1450      0      0      1  \n",
              "281         0.1500      1      0      0  \n",
              "2912        0.3450      0      0      1  \n",
              "3968        0.0820      0      1      0  \n",
              "3671        0.2575      1      0      0  \n",
              "\n",
              "[1253 rows x 10 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMtJCYE3XzpI"
      },
      "source": [
        "## Normalização dos Atributos Preditores\n",
        "\n",
        "O treinamento de uma RNA MLP é mais eficiente quando os valores que lhes são fornecidos como entrada são pequenos, pois isto favorece a convergência. Isto é feito por meio do escalonamento dos atributos preditores para o intervalo [0,1], mas precisa ser feito de maneira cautelosa, para que informações do conjunto de teste não sejam fornecidas no treinamento.\n",
        "\n",
        "Há duas estratégias para tal escalonamento: normalização e padronização. Ambas possuem características particulares, vantagens e limitações, como é possível ver aqui: https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
        "\n",
        "No nosso caso, vamos usar a normalização. Assim, com os atributos preditores do treinamento, isto é, X_train, deve-se efetuar as seguintes operações\n",
        "\n",
        "X_train_norm = (X_train - min(X_train))/(max(X_train) - min(X_train))\n",
        "\n",
        "Em seguida, o mesmo deve ser feito com os atributos preditores do conjunto de testes, mas com padronização relativa ao conjunto de treinamento:\n",
        "\n",
        "X_test_norm = (X_test - min(X_train)))/(max(X_train) - min(X_train))\n",
        "\n",
        "Se todo o conjunto X for utilizado no escalonamento, a rede neural receberá informações do conjunto de teste por meio dos valores mínimo e máximo utilizados para preparar os dados de treinamento, o que não é desejável."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJJne0MT6seL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUvy2K-sXzpI"
      },
      "outputs": [],
      "source": [
        "X_train_min = X_train.min()\n",
        "X_train_max = X_train.max()\n",
        "X_train_norm = (X_train - X_train_min)/(X_train_max - X_train_min)\n",
        "X_test_norm = (X_test - X_train_min)/(X_train_max - X_train_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5_HtgexX5RU-",
        "outputId": "a1d9fe6c-6bec-4cb2-c0aa-7533048b4537"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3995f9f9-6b9e-4016-8408-a5f8360066db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_I</th>\n",
              "      <th>Sex_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1748</th>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.898148</td>\n",
              "      <td>0.190265</td>\n",
              "      <td>0.710204</td>\n",
              "      <td>0.664423</td>\n",
              "      <td>0.587731</td>\n",
              "      <td>0.558166</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>0.456522</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>0.097345</td>\n",
              "      <td>0.127240</td>\n",
              "      <td>0.082464</td>\n",
              "      <td>0.104222</td>\n",
              "      <td>0.127517</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2696</th>\n",
              "      <td>0.797101</td>\n",
              "      <td>0.787037</td>\n",
              "      <td>0.146018</td>\n",
              "      <td>0.510559</td>\n",
              "      <td>0.465500</td>\n",
              "      <td>0.390501</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>0.724638</td>\n",
              "      <td>0.712963</td>\n",
              "      <td>0.146018</td>\n",
              "      <td>0.393256</td>\n",
              "      <td>0.286436</td>\n",
              "      <td>0.288259</td>\n",
              "      <td>0.348993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3767</th>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.694444</td>\n",
              "      <td>0.128319</td>\n",
              "      <td>0.312156</td>\n",
              "      <td>0.223494</td>\n",
              "      <td>0.287599</td>\n",
              "      <td>0.298098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>0.449275</td>\n",
              "      <td>0.435185</td>\n",
              "      <td>0.101770</td>\n",
              "      <td>0.099556</td>\n",
              "      <td>0.065634</td>\n",
              "      <td>0.072559</td>\n",
              "      <td>0.123602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2361</th>\n",
              "      <td>0.797101</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.181416</td>\n",
              "      <td>0.482165</td>\n",
              "      <td>0.335241</td>\n",
              "      <td>0.381266</td>\n",
              "      <td>0.455257</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3017</th>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.425926</td>\n",
              "      <td>0.092920</td>\n",
              "      <td>0.134694</td>\n",
              "      <td>0.116459</td>\n",
              "      <td>0.094987</td>\n",
              "      <td>0.130872</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4050</th>\n",
              "      <td>0.746377</td>\n",
              "      <td>0.759259</td>\n",
              "      <td>0.154867</td>\n",
              "      <td>0.372138</td>\n",
              "      <td>0.308987</td>\n",
              "      <td>0.337731</td>\n",
              "      <td>0.337808</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3221</th>\n",
              "      <td>0.594203</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.172566</td>\n",
              "      <td>0.342502</td>\n",
              "      <td>0.199260</td>\n",
              "      <td>0.279024</td>\n",
              "      <td>0.393736</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2923 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3995f9f9-6b9e-4016-8408-a5f8360066db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3995f9f9-6b9e-4016-8408-a5f8360066db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3995f9f9-6b9e-4016-8408-a5f8360066db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Length  Diameter    Height  Whole weight  Shucked weight  \\\n",
              "1748  0.869565  0.898148  0.190265      0.710204        0.664423   \n",
              "798   0.456522  0.472222  0.097345      0.127240        0.082464   \n",
              "2696  0.797101  0.787037  0.146018      0.510559        0.465500   \n",
              "291   0.724638  0.712963  0.146018      0.393256        0.286436   \n",
              "3767  0.652174  0.694444  0.128319      0.312156        0.223494   \n",
              "...        ...       ...       ...           ...             ...   \n",
              "541   0.449275  0.435185  0.101770      0.099556        0.065634   \n",
              "2361  0.797101  0.805556  0.181416      0.482165        0.335241   \n",
              "3017  0.478261  0.425926  0.092920      0.134694        0.116459   \n",
              "4050  0.746377  0.759259  0.154867      0.372138        0.308987   \n",
              "3221  0.594203  0.638889  0.172566      0.342502        0.199260   \n",
              "\n",
              "      Viscera weight  Shell weight  Sex_F  Sex_I  Sex_M  \n",
              "1748        0.587731      0.558166    0.0    0.0    1.0  \n",
              "798         0.104222      0.127517    1.0    0.0    0.0  \n",
              "2696        0.390501      0.416667    0.0    0.0    1.0  \n",
              "291         0.288259      0.348993    0.0    0.0    1.0  \n",
              "3767        0.287599      0.298098    0.0    0.0    1.0  \n",
              "...              ...           ...    ...    ...    ...  \n",
              "541         0.072559      0.123602    0.0    0.0    1.0  \n",
              "2361        0.381266      0.455257    1.0    0.0    0.0  \n",
              "3017        0.094987      0.130872    0.0    1.0    0.0  \n",
              "4050        0.337731      0.337808    0.0    0.0    1.0  \n",
              "3221        0.279024      0.393736    0.0    0.0    1.0  \n",
              "\n",
              "[2923 rows x 10 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sw7qGSB56kHB",
        "outputId": "aa920e09-c3e7-4f3f-b0e7-149eae068706"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-855ddb84-c430-45d7-8121-ee67c83aba99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_I</th>\n",
              "      <th>Sex_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2070</th>\n",
              "      <td>0.659420</td>\n",
              "      <td>0.648148</td>\n",
              "      <td>0.119469</td>\n",
              "      <td>0.291748</td>\n",
              "      <td>0.262874</td>\n",
              "      <td>0.226253</td>\n",
              "      <td>0.262864</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>0.840580</td>\n",
              "      <td>0.870370</td>\n",
              "      <td>0.190265</td>\n",
              "      <td>0.607276</td>\n",
              "      <td>0.456075</td>\n",
              "      <td>0.391821</td>\n",
              "      <td>0.522371</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1745</th>\n",
              "      <td>0.855072</td>\n",
              "      <td>0.879630</td>\n",
              "      <td>0.154867</td>\n",
              "      <td>0.656078</td>\n",
              "      <td>0.566813</td>\n",
              "      <td>0.516491</td>\n",
              "      <td>0.600671</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1736</th>\n",
              "      <td>0.811594</td>\n",
              "      <td>0.851852</td>\n",
              "      <td>0.137168</td>\n",
              "      <td>0.552972</td>\n",
              "      <td>0.575900</td>\n",
              "      <td>0.444591</td>\n",
              "      <td>0.392617</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4151</th>\n",
              "      <td>0.376812</td>\n",
              "      <td>0.351852</td>\n",
              "      <td>0.079646</td>\n",
              "      <td>0.074534</td>\n",
              "      <td>0.065298</td>\n",
              "      <td>0.069261</td>\n",
              "      <td>0.065436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012</th>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.509259</td>\n",
              "      <td>0.119469</td>\n",
              "      <td>0.182431</td>\n",
              "      <td>0.159542</td>\n",
              "      <td>0.198549</td>\n",
              "      <td>0.158837</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.490741</td>\n",
              "      <td>0.106195</td>\n",
              "      <td>0.156699</td>\n",
              "      <td>0.117469</td>\n",
              "      <td>0.134565</td>\n",
              "      <td>0.164430</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2912</th>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.759259</td>\n",
              "      <td>0.132743</td>\n",
              "      <td>0.402484</td>\n",
              "      <td>0.324806</td>\n",
              "      <td>0.346966</td>\n",
              "      <td>0.382550</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3968</th>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.079646</td>\n",
              "      <td>0.095475</td>\n",
              "      <td>0.109727</td>\n",
              "      <td>0.079815</td>\n",
              "      <td>0.088367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3671</th>\n",
              "      <td>0.702899</td>\n",
              "      <td>0.648148</td>\n",
              "      <td>0.119469</td>\n",
              "      <td>0.339308</td>\n",
              "      <td>0.335241</td>\n",
              "      <td>0.223615</td>\n",
              "      <td>0.284676</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1253 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-855ddb84-c430-45d7-8121-ee67c83aba99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-855ddb84-c430-45d7-8121-ee67c83aba99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-855ddb84-c430-45d7-8121-ee67c83aba99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Length  Diameter    Height  Whole weight  Shucked weight  \\\n",
              "2070  0.659420  0.648148  0.119469      0.291748        0.262874   \n",
              "368   0.840580  0.870370  0.190265      0.607276        0.456075   \n",
              "1745  0.855072  0.879630  0.154867      0.656078        0.566813   \n",
              "1736  0.811594  0.851852  0.137168      0.552972        0.575900   \n",
              "4151  0.376812  0.351852  0.079646      0.074534        0.065298   \n",
              "...        ...       ...       ...           ...             ...   \n",
              "2012  0.521739  0.509259  0.119469      0.182431        0.159542   \n",
              "281   0.500000  0.490741  0.106195      0.156699        0.117469   \n",
              "2912  0.695652  0.759259  0.132743      0.402484        0.324806   \n",
              "3968  0.391304  0.388889  0.079646      0.095475        0.109727   \n",
              "3671  0.702899  0.648148  0.119469      0.339308        0.335241   \n",
              "\n",
              "      Viscera weight  Shell weight  Sex_F  Sex_I  Sex_M  \n",
              "2070        0.226253      0.262864    1.0    0.0    0.0  \n",
              "368         0.391821      0.522371    1.0    0.0    0.0  \n",
              "1745        0.516491      0.600671    0.0    0.0    1.0  \n",
              "1736        0.444591      0.392617    1.0    0.0    0.0  \n",
              "4151        0.069261      0.065436    0.0    1.0    0.0  \n",
              "...              ...           ...    ...    ...    ...  \n",
              "2012        0.198549      0.158837    0.0    0.0    1.0  \n",
              "281         0.134565      0.164430    1.0    0.0    0.0  \n",
              "2912        0.346966      0.382550    0.0    0.0    1.0  \n",
              "3968        0.079815      0.088367    0.0    1.0    0.0  \n",
              "3671        0.223615      0.284676    1.0    0.0    0.0  \n",
              "\n",
              "[1253 rows x 10 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DativlolXzpJ"
      },
      "source": [
        "## Treinando a primeira RNA MLP para o Abalone\n",
        "\n",
        "1. Treine uma RNA MLP Classificadora para este problema com uma única camada e dez neurônios  \n",
        "    1.1 Utilize a função de ativação ReLU  \n",
        "    1.2 Utilize o solver Adam    \n",
        "    1.3 Imprima o passo a passo do treinamento    \n",
        "    1.4 Utilize o número máximo de épocas igual a 300  \n",
        "2. Imprima um gráfico com a perda da RNA MLP ao longo do treinamento  \n",
        "    2.1 Houve Early Stopping?  \n",
        "3. Com o modelo em questão, após o treinamento, apresente:  \n",
        "    3.1 Matriz de confusão para o conjunto de teste  \n",
        "    3.2 Acurácia  \n",
        "    3.3 F-Score  \n",
        "    3.4 Precisão  \n",
        "    3.5 Revocação  \n",
        "    \n",
        "No tocante ao Passo 3, construa funções para esta tarefa, pois serão recorrentemente utilizadas ao longo do trabalho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DO-qbVLs_Qze"
      },
      "outputs": [],
      "source": [
        "# Treina uma rede neural por classificação, realiza a previsão utilizando o modelo treinado e retorna os arrays de previsão e de perdas durante o treinamento\n",
        "def neural_network_classification(x_train, x_test, y_train, hidder_layer, activation_function, solver, max_epochs):\n",
        "  rede = MLPClassifier(hidden_layer_sizes=hidder_layer, activation=activation_function, solver=solver, max_iter = max_epochs, early_stopping=True, verbose=True)\n",
        "  rede.fit(x_train.values,y_train)\n",
        "  log_loss = rede.loss_curve_\n",
        "  y_prev = rede.predict(x_test)\n",
        "  return y_prev, log_loss\n",
        "\n",
        "# Exibe os gráficos dos atributos de treinamento preditores, de teste e previsões\n",
        "def plot_results(X_train, y_train, X_test, y_test, y_prev):\n",
        "    fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
        "    ax[0].plot(X_train, y_train, '.', color = \"darkblue\")\n",
        "    ax[0].set_title(\"Treinamento: \" + str(len(X_train)) + \" exemplos\")\n",
        "    ax[1].plot(X_test, y_test, '.', color=\"blue\")\n",
        "    ax[1].set_title(\"Teste: \" + str(len(X_test)) + \" exemplos\")\n",
        "    ax[2].plot(X_test, y_prev, '.', color=\"blue\")\n",
        "    ax[2].set_title(\"Previsões: \" + str(len(X_test)) + \" exemplos\")\n",
        "    plt.show()\n",
        "\n",
        "# Exibe a matriz de confusão\n",
        "def confusion_matrix_plot(y_test, y_prev):\n",
        "  cnf_matrix = metrics.confusion_matrix(y_test, y_prev)\n",
        "  fig, ax = plot_confusion_matrix(conf_mat=cnf_matrix, figsize=(10, 10), show_absolute=True, colorbar=True, )\n",
        "  plt.title(\"Matriz de Confusão\")\n",
        "  plt.show()\n",
        "\n",
        "# Exibe as métricas de Acurácia, f_score, precisão, renovação\n",
        "def show_metrics(y_test, y_prev):\n",
        "  print(\"Acurácia: \",accuracy_score(y_test,y_prev))\n",
        "  print(\"F-score: \",f1_score(y_test,y_prev, average='micro'))\n",
        "  print(\"Precisão: \", precision_score(y_test,y_prev, average='micro'))\n",
        "  print(\"Revocação: \", recall_score(y_test,y_prev, average='micro'))\n",
        "\n",
        "# Exibe um gráfico de perda do treinamento de um modelo\n",
        "def show_loss_log(loss_log):\n",
        "  plt.title(\"Curva da perda da RNA durante o treino\")\n",
        "  plt.xlabel(\"Época\")\n",
        "  plt.ylabel(\"Perda\")\n",
        "  plt.plot(loss_log)\n",
        "  plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rGKHgqjXzpJ"
      },
      "outputs": [],
      "source": [
        "## PARAMETROS E HIPEPARÂMETROS\n",
        "HIDDER_LAYER = (10,)\n",
        "ATIVACAO = \"relu\"\n",
        "SOLVER = 'adam'\n",
        "EPOCHS = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt8rTi3XXzpJ",
        "outputId": "9c0b0fb7-ee6b-4854-b7a9-6f55015c605d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.24958725\n",
            "Validation score: 0.017065\n",
            "Iteration 2, loss = 3.19978474\n",
            "Validation score: 0.054608\n",
            "Iteration 3, loss = 3.15364840\n",
            "Validation score: 0.061433\n",
            "Iteration 4, loss = 3.10608235\n",
            "Validation score: 0.098976\n",
            "Iteration 5, loss = 3.05488354\n",
            "Validation score: 0.095563\n",
            "Iteration 6, loss = 3.00040069\n",
            "Validation score: 0.088737\n",
            "Iteration 7, loss = 2.94142320\n",
            "Validation score: 0.156997\n",
            "Iteration 8, loss = 2.88090705\n",
            "Validation score: 0.170648\n",
            "Iteration 9, loss = 2.82045602\n",
            "Validation score: 0.153584\n",
            "Iteration 10, loss = 2.76317346\n",
            "Validation score: 0.143345\n",
            "Iteration 11, loss = 2.71022688\n",
            "Validation score: 0.143345\n",
            "Iteration 12, loss = 2.66188690\n",
            "Validation score: 0.174061\n",
            "Iteration 13, loss = 2.61945718\n",
            "Validation score: 0.201365\n",
            "Iteration 14, loss = 2.58337649\n",
            "Validation score: 0.191126\n",
            "Iteration 15, loss = 2.55364801\n",
            "Validation score: 0.201365\n",
            "Iteration 16, loss = 2.53026521\n",
            "Validation score: 0.191126\n",
            "Iteration 17, loss = 2.51091187\n",
            "Validation score: 0.191126\n",
            "Iteration 18, loss = 2.49401487\n",
            "Validation score: 0.191126\n",
            "Iteration 19, loss = 2.47906311\n",
            "Validation score: 0.191126\n",
            "Iteration 20, loss = 2.46608101\n",
            "Validation score: 0.191126\n",
            "Iteration 21, loss = 2.45414564\n",
            "Validation score: 0.191126\n",
            "Iteration 22, loss = 2.44281936\n",
            "Validation score: 0.191126\n",
            "Iteration 23, loss = 2.43228968\n",
            "Validation score: 0.187713\n",
            "Iteration 24, loss = 2.42202793\n",
            "Validation score: 0.191126\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_prev,log_loss = neural_network_classification(X_train_norm, X_test_norm, Y_train, HIDDER_LAYER, ATIVACAO, SOLVER, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "p6hbOE4aRjNE",
        "outputId": "ca1ce59e-6c80-4663-f3be-7d6c4e48528d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Exibindo a curva de perda da RNA\n",
        "show_loss_log(log_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdz8f9_6hHqp"
      },
      "source": [
        "**Resposta da Pergunta 2.1** : Sim, O gráfico não apresenta as 300 épocas máximas. Logo, assumi-se que houve um Early Stopping tendo a tol = 0.000100 em 10 épocas consecutivas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "gSoXLL8xXzpJ",
        "outputId": "eb3db6e5-e724-4326-960c-fec64ce2415e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Exibe os gráficos dos atributos de treinamento preditores, de teste e previsões\n",
        "plot_results(X_train_norm, Y_train, X_test_norm, Y_test, y_prev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "A_Y18xBFI2zi",
        "outputId": "823b2b53-0f8e-4c89-9fba-9a6e6d4e2199"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "confusion_matrix_plot(Y_test, y_prev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQSq9EOaOjPc",
        "outputId": "042a4d5b-f89f-45ef-ad22-8cc61f159e22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia:  0.20989624900239426\n",
            "F-score:  0.20989624900239426\n",
            "Precisão:  0.20989624900239426\n",
            "Revocação:  0.20989624900239426\n"
          ]
        }
      ],
      "source": [
        "# Métricas\n",
        "show_metrics(Y_test, y_prev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTT7TmyyXzpK"
      },
      "source": [
        "## Estimando o número de neurônios\n",
        "\n",
        "Um dos problemas de pesquisa com redes neurais artificiais consiste na determinação do número de neurônios em sua arquitetura. Embora não seja possível definir a priori qual rede neural é adequada para um problema, pois isto só é possível mediante uma busca exaustiva, há regras na literatura que sugerem o número de neurônios escondidos, tal como a regra da Pirâmide Geométrica, dada a seguir:\n",
        "\n",
        "$$N_h = \\alpha \\cdot \\sqrt{N_i \\cdot N_o},$$\n",
        "\n",
        "em que $N_h$ é o número de neurônios ocultos (a serem distribuídos em uma ou duas camadas ocultas), $N_i$ é o número de neurônios na camada de entrada e $N_o$ é o número de neurônios na camada de saída. \n",
        "\n",
        "1. Consulte a documentação da classe MLPClassifier (disponível em https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) e obtenha os valores de $N_i$ e $N_o$.\n",
        "2. Teste os valores de $\\alpha$ como sendo iguais a $0.5$, $2$ e $3$.\n",
        "3. Proponha pelo menos 30 arquiteturas de neurônios para RNAS MLPs segundo a regra da pirâmide geométrica  \n",
        "    3.1 Ao final desta etapa, deve-se obter uma lista contendo 30 elementos do tipo 2-tupla  \n",
        "    3.2 Obtenha as arquiteturas usando laços, listas, tuplas, etc. Soluções _hard-coded_ são desencorajadas  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_laz_m7TXzpK"
      },
      "outputs": [],
      "source": [
        "def pyramid_rule(a):\n",
        "  input_layer = X_train.shape[1]\n",
        "  output_layer = 1\n",
        "  Nh = a * np.sqrt(input_layer * output_layer)\n",
        "  return Nh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhQ5BEvCb_0q",
        "outputId": "7a86f785-a527-4201-a7f7-4d3ede7846eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.5811388300841898\n",
            "6.324555320336759\n",
            "9.486832980505138\n"
          ]
        }
      ],
      "source": [
        "a = [0.5, 2, 3]\n",
        "\n",
        "number_of_neurons_1 = pyramid_rule(a[0])\n",
        "number_of_neurons_2 = pyramid_rule(a[1])\n",
        "number_of_neurons_3 = pyramid_rule(a[2])\n",
        "\n",
        "print(number_of_neurons_1)\n",
        "print(number_of_neurons_2)\n",
        "print(number_of_neurons_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAm8pfhKb_0r"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations_with_replacement\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "def combinations_architecture(number_of_neurons):\n",
        "  number_of_neurons = np.round(number_of_neurons, decimals=0)\n",
        "  \n",
        "  # lista de números\n",
        "  numbers = [1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "\n",
        "  # conjunto para armazenar as combinações únicas\n",
        "  combinations_set = set()\n",
        "\n",
        "  # loop para gerar as combinações\n",
        "  for a, b in combinations_with_replacement(numbers, 2):\n",
        "      if a + b <= int(number_of_neurons):\n",
        "        combinations_set.add((b, a))\n",
        "        combinations_set.add((a, b))\n",
        "\n",
        "\n",
        "  # converter o conjunto em uma lista\n",
        "  combinations_list = list(combinations_set)\n",
        "  return combinations_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyaPd0sLb_0r",
        "outputId": "f92bf090-9d75-4a1a-be16-8e08f1b5ddc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "15\n",
            "36\n"
          ]
        }
      ],
      "source": [
        "list_architeture_3 = combinations_architecture(number_of_neurons_3)\n",
        "list_architeture_2 = combinations_architecture(number_of_neurons_2)\n",
        "list_architeture_1 = combinations_architecture(number_of_neurons_1)\n",
        "\n",
        "print(len(list_architeture_1))\n",
        "print(len(list_architeture_2))\n",
        "print(len(list_architeture_3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9-G1M1xb_0r",
        "outputId": "be366822-f2d4-4fd9-c42b-219ebfa04da2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([3, 4]), array([4, 3]), array([3, 1]), array([5, 4]), array([5, 1]), array([2, 2]), array([1, 6]), array([2, 5]), array([1, 3]), array([6, 2]), array([7, 1]), array([4, 2]), array([4, 5]), array([3, 3]), array([3, 6]), array([5, 3]), array([2, 4]), array([1, 2]), array([2, 1]), array([2, 7]), array([1, 5]), array([6, 1]), array([1, 8]), array([3, 2]), array([4, 1]), array([3, 5]), array([5, 2]), array([4, 4]), array([8, 1]), array([1, 1]), array([1, 4]), array([2, 3]), array([1, 7]), array([2, 6]), array([7, 2]), array([6, 3])]\n",
            "36\n",
            "[array([1, 7]), array([2, 6]), array([1, 3]), array([2, 4]), array([4, 3]), array([5, 3]), array([2, 5]), array([1, 6]), array([2, 3]), array([1, 1]), array([3, 4]), array([5, 2]), array([1, 4]), array([6, 2]), array([1, 8]), array([4, 4]), array([3, 2]), array([3, 3]), array([6, 3]), array([1, 5]), array([4, 5]), array([5, 1]), array([7, 2]), array([4, 1]), array([1, 2]), array([4, 2]), array([8, 1]), array([6, 1]), array([2, 1]), array([3, 1])]\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "# Concatena as listas\n",
        "list_architetures = np.concatenate([list_architeture_3, list_architeture_2, list_architeture_1])\n",
        "\n",
        "# Mantém apenas os valores únicos\n",
        "list_architetures = set([tuple(arr) for arr in list_architetures])\n",
        "\n",
        "# Converte de volta em lista com apenas arrays únicos\n",
        "list_architetures = [np.array(tupla) for tupla in list_architetures]\n",
        "\n",
        "print(list_architetures)\n",
        "print(len(list_architetures))\n",
        "\n",
        "# Seleciona aleatoriamente 30 das arquiteturas definidas.\n",
        "list_architetures = random.sample(list_architetures, 30)\n",
        "print(list_architetures)\n",
        "print(len(list_architetures))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZcEtNQyXzpK"
      },
      "source": [
        "## Busca em Grade\n",
        "\n",
        "Uma maneira padrão de escolher os parâmetros de um modelo de _Machine Learning_ é por meio de uma busca em grade via força bruta. O algoritmo da busca em grade é dado como segue:\n",
        "\n",
        "1. Escolha a métrica de desempenho que você deseja maximizar  \n",
        "2. Escolha o algoritmo de Machine Learning (exemplo: MLPClassifier). Em seguida, defina os parâmetros ou hiperparâmetros deste tipo de modelo sobre os quais você dseja otimizar (número de épocas, taxa de aprendizado, etc.) e construa um array de valores a serem testados para cada parâmetro ou hiperparâmetro.  \n",
        "3. Defina a grade de busca, a qual é dada como o produto cartesiano de cada parâmetro a ser testado. Por exemplo, para os arrays [50, 100, 1000] e [10, 15], tem-se que a grade é [(50,10), (50,15), (100,10), (100,15), (1000,10), (1000,15)].\n",
        "4. Para cada combinação de parâmetros a serem otimizados, utilize o conjunto de treinamento para realizar uma validação cruzada (holdout ou k-fold) e calcule a métrica de avaliação no conjunto de teste (ou conjuntos de teste)\n",
        "5. Escolha a combinação de parâmetros que maximizam a métrica de avaliação. Este é o modelo otimizado.\n",
        "\n",
        "Por que esta abordagem funciona? Porque a busca em grade efetua uma pesquisa extensiva sobre as possíveis combinações de valores para cada um dos parâmetros a serem ajustados. Para cada combinação, ela estima a performance do modelo em dados novos. Por fim, o modelo com melhor métrica de desempenho é escolhido. Tem-se então que este modelo é o que melhor pode vir a generalizar mediante dados nunca antes vistos.\n",
        "\n",
        "Sua busca em grade deve considerar:\n",
        "\n",
        "1. Validação Cruzada Holdout 70/30 com normalização, como definido anteriormente, com aferição de desempenho no conjunto de testes\n",
        "2. Parâmetros:  \n",
        "  2.1 30 arquiteturas propostas para o número de neurônios ocultos no item anterior  \n",
        "  2.2 Funções de ativação (ReLU e Sigmóide)\n",
        "3. Hiperparâmetros:  \n",
        "  3.1 Batch_size: 16 ou 32  \n",
        "  3.2 Solver: Adam  \n",
        "  3.3 $\\beta_1$: 1, 0.9, 0.8  \n",
        "  3.4 $\\beta_1$: 0.999, 0.95, 0.9  \n",
        "  3.5 Paciência (n_iter_no_change): 25 ou 50    \n",
        "4. Nesta busca em grande, contemple a utilização do objeto [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "5. Apresente as três propostas com melhor desempenho na busca em grade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vR8HIlzXzpL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwPA5AEOXzpL"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'hidden_layer_sizes': list_architetures,\n",
        "    'activation': ['relu', 'logistic'],\n",
        "    'batch_size': [16],\n",
        "    'solver': ['adam'],\n",
        "    'beta_1': [1, 0.9, 0.8],\n",
        "    'beta_2': [0.999, 0.95, 0.9],\n",
        "    'learning_rate_init': [0.009, 0.09, 0.32],\n",
        "    'n_iter_no_change': [25],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxwDOBLab_0s",
        "outputId": "53b35690-8497-44d8-d44f-fda1e5371f3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "Validation score: 0.213675\n",
            "Iteration 41, loss = 2.15805261\n",
            "Validation score: 0.209402\n",
            "Iteration 42, loss = 2.15534848\n",
            "Validation score: 0.205128\n",
            "Iteration 43, loss = 2.15318448\n",
            "Validation score: 0.209402\n",
            "Iteration 44, loss = 2.15014811\n",
            "Validation score: 0.209402\n",
            "Iteration 45, loss = 2.14820127\n",
            "Validation score: 0.200855\n",
            "Iteration 46, loss = 2.14505169\n",
            "Validation score: 0.209402\n",
            "Iteration 47, loss = 2.14246346\n",
            "Validation score: 0.209402\n",
            "Iteration 48, loss = 2.13955343\n",
            "Validation score: 0.205128\n",
            "Iteration 49, loss = 2.13652212\n",
            "Validation score: 0.213675\n",
            "Iteration 50, loss = 2.13505128\n",
            "Validation score: 0.205128\n",
            "Iteration 51, loss = 2.13188225\n",
            "Validation score: 0.200855\n",
            "Iteration 52, loss = 2.13000477\n",
            "Validation score: 0.217949\n",
            "Iteration 53, loss = 2.12738649\n",
            "Validation score: 0.205128\n",
            "Iteration 54, loss = 2.12563309\n",
            "Validation score: 0.205128\n",
            "Iteration 55, loss = 2.12351089\n",
            "Validation score: 0.205128\n",
            "Iteration 56, loss = 2.12155934\n",
            "Validation score: 0.222222\n",
            "Iteration 57, loss = 2.11906074\n",
            "Validation score: 0.205128\n",
            "Iteration 58, loss = 2.11731039\n",
            "Validation score: 0.213675\n",
            "Iteration 59, loss = 2.11472086\n",
            "Validation score: 0.217949\n",
            "Iteration 60, loss = 2.11331282\n",
            "Validation score: 0.226496\n",
            "Iteration 61, loss = 2.11128112\n",
            "Validation score: 0.213675\n",
            "Iteration 62, loss = 2.10887453\n",
            "Validation score: 0.209402\n",
            "Iteration 63, loss = 2.10720735\n",
            "Validation score: 0.217949\n",
            "Iteration 64, loss = 2.10440172\n",
            "Validation score: 0.217949\n",
            "Iteration 65, loss = 2.10342685\n",
            "Validation score: 0.217949\n",
            "Iteration 66, loss = 2.10111553\n",
            "Validation score: 0.222222\n",
            "Iteration 67, loss = 2.09865331\n",
            "Validation score: 0.222222\n",
            "Iteration 68, loss = 2.09772606\n",
            "Validation score: 0.217949\n",
            "Iteration 69, loss = 2.09600329\n",
            "Validation score: 0.209402\n",
            "Iteration 70, loss = 2.09343711\n",
            "Validation score: 0.217949\n",
            "Iteration 71, loss = 2.09208429\n",
            "Validation score: 0.213675\n",
            "Iteration 72, loss = 2.09060835\n",
            "Validation score: 0.226496\n",
            "Iteration 73, loss = 2.08831435\n",
            "Validation score: 0.222222\n",
            "Iteration 74, loss = 2.08677328\n",
            "Validation score: 0.222222\n",
            "Iteration 75, loss = 2.08535265\n",
            "Validation score: 0.213675\n",
            "Iteration 76, loss = 2.08380677\n",
            "Validation score: 0.209402\n",
            "Iteration 77, loss = 2.08241263\n",
            "Validation score: 0.213675\n",
            "Iteration 78, loss = 2.08094466\n",
            "Validation score: 0.217949\n",
            "Iteration 79, loss = 2.07997530\n",
            "Validation score: 0.205128\n",
            "Iteration 80, loss = 2.07703957\n",
            "Validation score: 0.222222\n",
            "Iteration 81, loss = 2.07638311\n",
            "Validation score: 0.209402\n",
            "Iteration 82, loss = 2.07432981\n",
            "Validation score: 0.209402\n",
            "Iteration 83, loss = 2.07265896\n",
            "Validation score: 0.200855\n",
            "Iteration 84, loss = 2.07134478\n",
            "Validation score: 0.196581\n",
            "Iteration 85, loss = 2.07004444\n",
            "Validation score: 0.209402\n",
            "Iteration 86, loss = 2.06859042\n",
            "Validation score: 0.200855\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.20781519\n",
            "Validation score: 0.042735\n",
            "Iteration 2, loss = 2.98609250\n",
            "Validation score: 0.119658\n",
            "Iteration 3, loss = 2.80314951\n",
            "Validation score: 0.119658\n",
            "Iteration 4, loss = 2.67072862\n",
            "Validation score: 0.119658\n",
            "Iteration 5, loss = 2.58974976\n",
            "Validation score: 0.119658\n",
            "Iteration 6, loss = 2.54760098\n",
            "Validation score: 0.119658\n",
            "Iteration 7, loss = 2.52854656\n",
            "Validation score: 0.136752\n",
            "Iteration 8, loss = 2.52003338\n",
            "Validation score: 0.136752\n",
            "Iteration 9, loss = 2.51488437\n",
            "Validation score: 0.136752\n",
            "Iteration 10, loss = 2.51204639\n",
            "Validation score: 0.136752\n",
            "Iteration 11, loss = 2.51006376\n",
            "Validation score: 0.136752\n",
            "Iteration 12, loss = 2.50871016\n",
            "Validation score: 0.136752\n",
            "Iteration 13, loss = 2.50729323\n",
            "Validation score: 0.136752\n",
            "Iteration 14, loss = 2.50678654\n",
            "Validation score: 0.136752\n",
            "Iteration 15, loss = 2.50620305\n",
            "Validation score: 0.136752\n",
            "Iteration 16, loss = 2.50557859\n",
            "Validation score: 0.136752\n",
            "Iteration 17, loss = 2.50560946\n",
            "Validation score: 0.136752\n",
            "Iteration 18, loss = 2.50508568\n",
            "Validation score: 0.136752\n",
            "Iteration 19, loss = 2.50456237\n",
            "Validation score: 0.136752\n",
            "Iteration 20, loss = 2.50482159\n",
            "Validation score: 0.136752\n",
            "Iteration 21, loss = 2.50439223\n",
            "Validation score: 0.136752\n",
            "Iteration 22, loss = 2.50422760\n",
            "Validation score: 0.136752\n",
            "Iteration 23, loss = 2.50415874\n",
            "Validation score: 0.136752\n",
            "Iteration 24, loss = 2.50390670\n",
            "Validation score: 0.136752\n",
            "Iteration 25, loss = 2.50412380\n",
            "Validation score: 0.136752\n",
            "Iteration 26, loss = 2.50368429\n",
            "Validation score: 0.136752\n",
            "Iteration 27, loss = 2.50351035\n",
            "Validation score: 0.136752\n",
            "Iteration 28, loss = 2.50384600\n",
            "Validation score: 0.136752\n",
            "Iteration 29, loss = 2.50375773\n",
            "Validation score: 0.136752\n",
            "Iteration 30, loss = 2.50381562\n",
            "Validation score: 0.136752\n",
            "Iteration 31, loss = 2.50375487\n",
            "Validation score: 0.136752\n",
            "Iteration 32, loss = 2.50367097\n",
            "Validation score: 0.136752\n",
            "Iteration 33, loss = 2.50368494\n",
            "Validation score: 0.136752\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.20515221\n",
            "Validation score: 0.166667\n",
            "Iteration 2, loss = 2.86721161\n",
            "Validation score: 0.196581\n",
            "Iteration 3, loss = 2.61049356\n",
            "Validation score: 0.196581\n",
            "Iteration 4, loss = 2.51328670\n",
            "Validation score: 0.196581\n",
            "Iteration 5, loss = 2.47267505\n",
            "Validation score: 0.188034\n",
            "Iteration 6, loss = 2.44223753\n",
            "Validation score: 0.183761\n",
            "Iteration 7, loss = 2.41496950\n",
            "Validation score: 0.183761\n",
            "Iteration 8, loss = 2.38805183\n",
            "Validation score: 0.179487\n",
            "Iteration 9, loss = 2.36165894\n",
            "Validation score: 0.179487\n",
            "Iteration 10, loss = 2.33672517\n",
            "Validation score: 0.188034\n",
            "Iteration 11, loss = 2.31286817\n",
            "Validation score: 0.188034\n",
            "Iteration 12, loss = 2.29170396\n",
            "Validation score: 0.213675\n",
            "Iteration 13, loss = 2.27158866\n",
            "Validation score: 0.217949\n",
            "Iteration 14, loss = 2.25447538\n",
            "Validation score: 0.239316\n",
            "Iteration 15, loss = 2.24041153\n",
            "Validation score: 0.239316\n",
            "Iteration 16, loss = 2.22717421\n",
            "Validation score: 0.235043\n",
            "Iteration 17, loss = 2.21759787\n",
            "Validation score: 0.256410\n",
            "Iteration 18, loss = 2.20753459\n",
            "Validation score: 0.243590\n",
            "Iteration 19, loss = 2.19997392\n",
            "Validation score: 0.252137\n",
            "Iteration 20, loss = 2.19236060\n",
            "Validation score: 0.260684\n",
            "Iteration 21, loss = 2.18598780\n",
            "Validation score: 0.260684\n",
            "Iteration 22, loss = 2.18048319\n",
            "Validation score: 0.256410\n",
            "Iteration 23, loss = 2.17484606\n",
            "Validation score: 0.264957\n",
            "Iteration 24, loss = 2.17035569\n",
            "Validation score: 0.247863\n",
            "Iteration 25, loss = 2.16594010\n",
            "Validation score: 0.269231\n",
            "Iteration 26, loss = 2.16202295\n",
            "Validation score: 0.273504\n",
            "Iteration 27, loss = 2.15780172\n",
            "Validation score: 0.269231\n",
            "Iteration 28, loss = 2.15562442\n",
            "Validation score: 0.282051\n",
            "Iteration 29, loss = 2.15176037\n",
            "Validation score: 0.260684\n",
            "Iteration 30, loss = 2.14909569\n",
            "Validation score: 0.282051\n",
            "Iteration 31, loss = 2.14704690\n",
            "Validation score: 0.260684\n",
            "Iteration 32, loss = 2.14413322\n",
            "Validation score: 0.273504\n",
            "Iteration 33, loss = 2.14156463\n",
            "Validation score: 0.277778\n",
            "Iteration 34, loss = 2.14021420\n",
            "Validation score: 0.269231\n",
            "Iteration 35, loss = 2.13756778\n",
            "Validation score: 0.260684\n",
            "Iteration 36, loss = 2.13583103\n",
            "Validation score: 0.269231\n",
            "Iteration 37, loss = 2.13556055\n",
            "Validation score: 0.273504\n",
            "Iteration 38, loss = 2.13260091\n",
            "Validation score: 0.273504\n",
            "Iteration 39, loss = 2.13203111\n",
            "Validation score: 0.260684\n",
            "Iteration 40, loss = 2.13037862\n",
            "Validation score: 0.260684\n",
            "Iteration 41, loss = 2.12907021\n",
            "Validation score: 0.282051\n",
            "Iteration 42, loss = 2.12807241\n",
            "Validation score: 0.260684\n",
            "Iteration 43, loss = 2.12696063\n",
            "Validation score: 0.260684\n",
            "Iteration 44, loss = 2.12560927\n",
            "Validation score: 0.264957\n",
            "Iteration 45, loss = 2.12494397\n",
            "Validation score: 0.260684\n",
            "Iteration 46, loss = 2.12384135\n",
            "Validation score: 0.269231\n",
            "Iteration 47, loss = 2.12290693\n",
            "Validation score: 0.269231\n",
            "Iteration 48, loss = 2.12232283\n",
            "Validation score: 0.264957\n",
            "Iteration 49, loss = 2.12136654\n",
            "Validation score: 0.264957\n",
            "Iteration 50, loss = 2.12019649\n",
            "Validation score: 0.264957\n",
            "Iteration 51, loss = 2.11899604\n",
            "Validation score: 0.256410\n",
            "Iteration 52, loss = 2.11845971\n",
            "Validation score: 0.252137\n",
            "Iteration 53, loss = 2.11848362\n",
            "Validation score: 0.273504\n",
            "Iteration 54, loss = 2.11800707\n",
            "Validation score: 0.273504\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.21630206\n",
            "Validation score: 0.132479\n",
            "Iteration 2, loss = 2.90367380\n",
            "Validation score: 0.132479\n",
            "Iteration 3, loss = 2.64752228\n",
            "Validation score: 0.217949\n",
            "Iteration 4, loss = 2.52833029\n",
            "Validation score: 0.175214\n",
            "Iteration 5, loss = 2.45135144\n",
            "Validation score: 0.230769\n",
            "Iteration 6, loss = 2.39569623\n",
            "Validation score: 0.239316\n",
            "Iteration 7, loss = 2.34779112\n",
            "Validation score: 0.213675\n",
            "Iteration 8, loss = 2.30872435\n",
            "Validation score: 0.217949\n",
            "Iteration 9, loss = 2.27912551\n",
            "Validation score: 0.217949\n",
            "Iteration 10, loss = 2.25566524\n",
            "Validation score: 0.230769\n",
            "Iteration 11, loss = 2.23757800\n",
            "Validation score: 0.260684\n",
            "Iteration 12, loss = 2.22287069\n",
            "Validation score: 0.282051\n",
            "Iteration 13, loss = 2.21020133\n",
            "Validation score: 0.290598\n",
            "Iteration 14, loss = 2.20068240\n",
            "Validation score: 0.264957\n",
            "Iteration 15, loss = 2.19252579\n",
            "Validation score: 0.303419\n",
            "Iteration 16, loss = 2.18407655\n",
            "Validation score: 0.264957\n",
            "Iteration 17, loss = 2.17779240\n",
            "Validation score: 0.294872\n",
            "Iteration 18, loss = 2.17095787\n",
            "Validation score: 0.277778\n",
            "Iteration 19, loss = 2.16542721\n",
            "Validation score: 0.277778\n",
            "Iteration 20, loss = 2.15998908\n",
            "Validation score: 0.277778\n",
            "Iteration 21, loss = 2.15512635\n",
            "Validation score: 0.273504\n",
            "Iteration 22, loss = 2.15007227\n",
            "Validation score: 0.299145\n",
            "Iteration 23, loss = 2.14527237\n",
            "Validation score: 0.286325\n",
            "Iteration 24, loss = 2.14066059\n",
            "Validation score: 0.299145\n",
            "Iteration 25, loss = 2.13701710\n",
            "Validation score: 0.286325\n",
            "Iteration 26, loss = 2.13311755\n",
            "Validation score: 0.307692\n",
            "Iteration 27, loss = 2.12901736\n",
            "Validation score: 0.290598\n",
            "Iteration 28, loss = 2.12584653\n",
            "Validation score: 0.294872\n",
            "Iteration 29, loss = 2.12144645\n",
            "Validation score: 0.299145\n",
            "Iteration 30, loss = 2.11753506\n",
            "Validation score: 0.311966\n",
            "Iteration 31, loss = 2.11350433\n",
            "Validation score: 0.299145\n",
            "Iteration 32, loss = 2.10925678\n",
            "Validation score: 0.324786\n",
            "Iteration 33, loss = 2.10789769\n",
            "Validation score: 0.316239\n",
            "Iteration 34, loss = 2.10287817\n",
            "Validation score: 0.329060\n",
            "Iteration 35, loss = 2.09894022\n",
            "Validation score: 0.311966\n",
            "Iteration 36, loss = 2.09727447\n",
            "Validation score: 0.299145\n",
            "Iteration 37, loss = 2.09219767\n",
            "Validation score: 0.307692\n",
            "Iteration 38, loss = 2.08899503\n",
            "Validation score: 0.316239\n",
            "Iteration 39, loss = 2.08653608\n",
            "Validation score: 0.307692\n",
            "Iteration 40, loss = 2.08278705\n",
            "Validation score: 0.311966\n",
            "Iteration 41, loss = 2.08013107\n",
            "Validation score: 0.307692\n",
            "Iteration 42, loss = 2.07714090\n",
            "Validation score: 0.299145\n",
            "Iteration 43, loss = 2.07403819\n",
            "Validation score: 0.303419\n",
            "Iteration 44, loss = 2.07000408\n",
            "Validation score: 0.299145\n",
            "Iteration 45, loss = 2.06924509\n",
            "Validation score: 0.303419\n",
            "Iteration 46, loss = 2.06614230\n",
            "Validation score: 0.299145\n",
            "Iteration 47, loss = 2.06271015\n",
            "Validation score: 0.299145\n",
            "Iteration 48, loss = 2.06079944\n",
            "Validation score: 0.307692\n",
            "Iteration 49, loss = 2.05835499\n",
            "Validation score: 0.294872\n",
            "Iteration 50, loss = 2.05560365\n",
            "Validation score: 0.294872\n",
            "Iteration 51, loss = 2.05396457\n",
            "Validation score: 0.294872\n",
            "Iteration 52, loss = 2.05169842\n",
            "Validation score: 0.290598\n",
            "Iteration 53, loss = 2.04813864\n",
            "Validation score: 0.286325\n",
            "Iteration 54, loss = 2.04720270\n",
            "Validation score: 0.286325\n",
            "Iteration 55, loss = 2.04350094\n",
            "Validation score: 0.294872\n",
            "Iteration 56, loss = 2.04268507\n",
            "Validation score: 0.299145\n",
            "Iteration 57, loss = 2.04072482\n",
            "Validation score: 0.299145\n",
            "Iteration 58, loss = 2.03767980\n",
            "Validation score: 0.303419\n",
            "Iteration 59, loss = 2.03745013\n",
            "Validation score: 0.290598\n",
            "Iteration 60, loss = 2.03421187\n",
            "Validation score: 0.299145\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.02536562\n",
            "Validation score: 0.089744\n",
            "Iteration 2, loss = 2.77824934\n",
            "Validation score: 0.076923\n",
            "Iteration 3, loss = 2.61259751\n",
            "Validation score: 0.102564\n",
            "Iteration 4, loss = 2.55207945\n",
            "Validation score: 0.106838\n",
            "Iteration 5, loss = 2.52649973\n",
            "Validation score: 0.094017\n",
            "Iteration 6, loss = 2.51271669\n",
            "Validation score: 0.094017\n",
            "Iteration 7, loss = 2.50337625\n",
            "Validation score: 0.098291\n",
            "Iteration 8, loss = 2.49597280\n",
            "Validation score: 0.098291\n",
            "Iteration 9, loss = 2.48854132\n",
            "Validation score: 0.098291\n",
            "Iteration 10, loss = 2.48170951\n",
            "Validation score: 0.102564\n",
            "Iteration 11, loss = 2.47368827\n",
            "Validation score: 0.119658\n",
            "Iteration 12, loss = 2.46562674\n",
            "Validation score: 0.128205\n",
            "Iteration 13, loss = 2.45875060\n",
            "Validation score: 0.136752\n",
            "Iteration 14, loss = 2.44601674\n",
            "Validation score: 0.166667\n",
            "Iteration 15, loss = 2.41192928\n",
            "Validation score: 0.205128\n",
            "Iteration 16, loss = 2.36716843\n",
            "Validation score: 0.226496\n",
            "Iteration 17, loss = 2.32207311\n",
            "Validation score: 0.217949\n",
            "Iteration 18, loss = 2.28424594\n",
            "Validation score: 0.217949\n",
            "Iteration 19, loss = 2.25506005\n",
            "Validation score: 0.230769\n",
            "Iteration 20, loss = 2.23459014\n",
            "Validation score: 0.235043\n",
            "Iteration 21, loss = 2.22013247\n",
            "Validation score: 0.230769\n",
            "Iteration 22, loss = 2.20883830\n",
            "Validation score: 0.230769\n",
            "Iteration 23, loss = 2.20024844\n",
            "Validation score: 0.222222\n",
            "Iteration 24, loss = 2.19289854\n",
            "Validation score: 0.222222\n",
            "Iteration 25, loss = 2.18693920\n",
            "Validation score: 0.226496\n",
            "Iteration 26, loss = 2.18213070\n",
            "Validation score: 0.222222\n",
            "Iteration 27, loss = 2.17683058\n",
            "Validation score: 0.243590\n",
            "Iteration 28, loss = 2.17336167\n",
            "Validation score: 0.235043\n",
            "Iteration 29, loss = 2.16974455\n",
            "Validation score: 0.235043\n",
            "Iteration 30, loss = 2.16655197\n",
            "Validation score: 0.226496\n",
            "Iteration 31, loss = 2.16269638\n",
            "Validation score: 0.226496\n",
            "Iteration 32, loss = 2.16128901\n",
            "Validation score: 0.247863\n",
            "Iteration 33, loss = 2.15830666\n",
            "Validation score: 0.230769\n",
            "Iteration 34, loss = 2.15597922\n",
            "Validation score: 0.222222\n",
            "Iteration 35, loss = 2.15484187\n",
            "Validation score: 0.235043\n",
            "Iteration 36, loss = 2.15201447\n",
            "Validation score: 0.243590\n",
            "Iteration 37, loss = 2.15036742\n",
            "Validation score: 0.243590\n",
            "Iteration 38, loss = 2.14900190\n",
            "Validation score: 0.235043\n",
            "Iteration 39, loss = 2.14728505\n",
            "Validation score: 0.243590\n",
            "Iteration 40, loss = 2.14497810\n",
            "Validation score: 0.243590\n",
            "Iteration 41, loss = 2.14385841\n",
            "Validation score: 0.243590\n",
            "Iteration 42, loss = 2.14303866\n",
            "Validation score: 0.235043\n",
            "Iteration 43, loss = 2.14212811\n",
            "Validation score: 0.235043\n",
            "Iteration 44, loss = 2.14082345\n",
            "Validation score: 0.239316\n",
            "Iteration 45, loss = 2.13882905\n",
            "Validation score: 0.239316\n",
            "Iteration 46, loss = 2.13737702\n",
            "Validation score: 0.243590\n",
            "Iteration 47, loss = 2.13682646\n",
            "Validation score: 0.239316\n",
            "Iteration 48, loss = 2.13503865\n",
            "Validation score: 0.243590\n",
            "Iteration 49, loss = 2.13460794\n",
            "Validation score: 0.239316\n",
            "Iteration 50, loss = 2.13419899\n",
            "Validation score: 0.247863\n",
            "Iteration 51, loss = 2.13284364\n",
            "Validation score: 0.239316\n",
            "Iteration 52, loss = 2.13182598\n",
            "Validation score: 0.235043\n",
            "Iteration 53, loss = 2.12957689\n",
            "Validation score: 0.243590\n",
            "Iteration 54, loss = 2.13040461\n",
            "Validation score: 0.235043\n",
            "Iteration 55, loss = 2.12898662\n",
            "Validation score: 0.239316\n",
            "Iteration 56, loss = 2.12758714\n",
            "Validation score: 0.239316\n",
            "Iteration 57, loss = 2.12703544\n",
            "Validation score: 0.239316\n",
            "Iteration 58, loss = 2.12664036\n",
            "Validation score: 0.235043\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.04888603\n",
            "Validation score: 0.081197\n",
            "Iteration 2, loss = 2.74336582\n",
            "Validation score: 0.192308\n",
            "Iteration 3, loss = 2.55374528\n",
            "Validation score: 0.183761\n",
            "Iteration 4, loss = 2.48945133\n",
            "Validation score: 0.209402\n",
            "Iteration 5, loss = 2.45774051\n",
            "Validation score: 0.209402\n",
            "Iteration 6, loss = 2.43581275\n",
            "Validation score: 0.209402\n",
            "Iteration 7, loss = 2.41860139\n",
            "Validation score: 0.209402\n",
            "Iteration 8, loss = 2.40467063\n",
            "Validation score: 0.209402\n",
            "Iteration 9, loss = 2.39431260\n",
            "Validation score: 0.209402\n",
            "Iteration 10, loss = 2.38443130\n",
            "Validation score: 0.209402\n",
            "Iteration 11, loss = 2.37651457\n",
            "Validation score: 0.209402\n",
            "Iteration 12, loss = 2.36952482\n",
            "Validation score: 0.209402\n",
            "Iteration 13, loss = 2.36294533\n",
            "Validation score: 0.209402\n",
            "Iteration 14, loss = 2.35673740\n",
            "Validation score: 0.209402\n",
            "Iteration 15, loss = 2.34388875\n",
            "Validation score: 0.209402\n",
            "Iteration 16, loss = 2.33326974\n",
            "Validation score: 0.209402\n",
            "Iteration 17, loss = 2.32193844\n",
            "Validation score: 0.217949\n",
            "Iteration 18, loss = 2.31117006\n",
            "Validation score: 0.222222\n",
            "Iteration 19, loss = 2.30079766\n",
            "Validation score: 0.226496\n",
            "Iteration 20, loss = 2.29069794\n",
            "Validation score: 0.217949\n",
            "Iteration 21, loss = 2.28082708\n",
            "Validation score: 0.222222\n",
            "Iteration 22, loss = 2.27183761\n",
            "Validation score: 0.226496\n",
            "Iteration 23, loss = 2.26313632\n",
            "Validation score: 0.217949\n",
            "Iteration 24, loss = 2.25531539\n",
            "Validation score: 0.217949\n",
            "Iteration 25, loss = 2.24694904\n",
            "Validation score: 0.226496\n",
            "Iteration 26, loss = 2.23991096\n",
            "Validation score: 0.217949\n",
            "Iteration 27, loss = 2.23361464\n",
            "Validation score: 0.222222\n",
            "Iteration 28, loss = 2.22718779\n",
            "Validation score: 0.222222\n",
            "Iteration 29, loss = 2.22222353\n",
            "Validation score: 0.235043\n",
            "Iteration 30, loss = 2.21778593\n",
            "Validation score: 0.222222\n",
            "Iteration 31, loss = 2.21319685\n",
            "Validation score: 0.226496\n",
            "Iteration 32, loss = 2.20960794\n",
            "Validation score: 0.226496\n",
            "Iteration 33, loss = 2.20594801\n",
            "Validation score: 0.226496\n",
            "Iteration 34, loss = 2.20296193\n",
            "Validation score: 0.226496\n",
            "Iteration 35, loss = 2.19920915\n",
            "Validation score: 0.230769\n",
            "Iteration 36, loss = 2.19623759\n",
            "Validation score: 0.230769\n",
            "Iteration 37, loss = 2.19368322\n",
            "Validation score: 0.235043\n",
            "Iteration 38, loss = 2.19142272\n",
            "Validation score: 0.230769\n",
            "Iteration 39, loss = 2.18884606\n",
            "Validation score: 0.230769\n",
            "Iteration 40, loss = 2.18593132\n",
            "Validation score: 0.217949\n",
            "Iteration 41, loss = 2.18346224\n",
            "Validation score: 0.239316\n",
            "Iteration 42, loss = 2.18212496\n",
            "Validation score: 0.239316\n",
            "Iteration 43, loss = 2.17991776\n",
            "Validation score: 0.217949\n",
            "Iteration 44, loss = 2.17754885\n",
            "Validation score: 0.230769\n",
            "Iteration 45, loss = 2.17530226\n",
            "Validation score: 0.230769\n",
            "Iteration 46, loss = 2.17329505\n",
            "Validation score: 0.217949\n",
            "Iteration 47, loss = 2.17108763\n",
            "Validation score: 0.213675\n",
            "Iteration 48, loss = 2.16810540\n",
            "Validation score: 0.230769\n",
            "Iteration 49, loss = 2.16760811\n",
            "Validation score: 0.213675\n",
            "Iteration 50, loss = 2.16480421\n",
            "Validation score: 0.217949\n",
            "Iteration 51, loss = 2.16177762\n",
            "Validation score: 0.217949\n",
            "Iteration 52, loss = 2.16078947\n",
            "Validation score: 0.213675\n",
            "Iteration 53, loss = 2.15840990\n",
            "Validation score: 0.222222\n",
            "Iteration 54, loss = 2.15709631\n",
            "Validation score: 0.217949\n",
            "Iteration 55, loss = 2.15420648\n",
            "Validation score: 0.222222\n",
            "Iteration 56, loss = 2.15276214\n",
            "Validation score: 0.217949\n",
            "Iteration 57, loss = 2.15069243\n",
            "Validation score: 0.217949\n",
            "Iteration 58, loss = 2.14823853\n",
            "Validation score: 0.226496\n",
            "Iteration 59, loss = 2.14641098\n",
            "Validation score: 0.226496\n",
            "Iteration 60, loss = 2.14378857\n",
            "Validation score: 0.239316\n",
            "Iteration 61, loss = 2.14237107\n",
            "Validation score: 0.235043\n",
            "Iteration 62, loss = 2.13861944\n",
            "Validation score: 0.235043\n",
            "Iteration 63, loss = 2.13510877\n",
            "Validation score: 0.239316\n",
            "Iteration 64, loss = 2.13187914\n",
            "Validation score: 0.247863\n",
            "Iteration 65, loss = 2.12951960\n",
            "Validation score: 0.230769\n",
            "Iteration 66, loss = 2.12536569\n",
            "Validation score: 0.239316\n",
            "Iteration 67, loss = 2.12246106\n",
            "Validation score: 0.247863\n",
            "Iteration 68, loss = 2.12017425\n",
            "Validation score: 0.239316\n",
            "Iteration 69, loss = 2.11880774\n",
            "Validation score: 0.243590\n",
            "Iteration 70, loss = 2.11363947\n",
            "Validation score: 0.243590\n",
            "Iteration 71, loss = 2.11139925\n",
            "Validation score: 0.243590\n",
            "Iteration 72, loss = 2.10897930\n",
            "Validation score: 0.243590\n",
            "Iteration 73, loss = 2.10688051\n",
            "Validation score: 0.247863\n",
            "Iteration 74, loss = 2.10406576\n",
            "Validation score: 0.256410\n",
            "Iteration 75, loss = 2.10111724\n",
            "Validation score: 0.239316\n",
            "Iteration 76, loss = 2.10188403\n",
            "Validation score: 0.252137\n",
            "Iteration 77, loss = 2.09821522\n",
            "Validation score: 0.243590\n",
            "Iteration 78, loss = 2.09570825\n",
            "Validation score: 0.222222\n",
            "Iteration 79, loss = 2.09448789\n",
            "Validation score: 0.239316\n",
            "Iteration 80, loss = 2.09170879\n",
            "Validation score: 0.239316\n",
            "Iteration 81, loss = 2.09046002\n",
            "Validation score: 0.230769\n",
            "Iteration 82, loss = 2.08881633\n",
            "Validation score: 0.247863\n",
            "Iteration 83, loss = 2.08620826\n",
            "Validation score: 0.243590\n",
            "Iteration 84, loss = 2.08466386\n",
            "Validation score: 0.243590\n",
            "Iteration 85, loss = 2.08385780\n",
            "Validation score: 0.256410\n",
            "Iteration 86, loss = 2.08130122\n",
            "Validation score: 0.243590\n",
            "Iteration 87, loss = 2.08062529\n",
            "Validation score: 0.252137\n",
            "Iteration 88, loss = 2.07846420\n",
            "Validation score: 0.243590\n",
            "Iteration 89, loss = 2.07784450\n",
            "Validation score: 0.239316\n",
            "Iteration 90, loss = 2.07503986\n",
            "Validation score: 0.239316\n",
            "Iteration 91, loss = 2.07355754\n",
            "Validation score: 0.230769\n",
            "Iteration 92, loss = 2.07278378\n",
            "Validation score: 0.235043\n",
            "Iteration 93, loss = 2.07097670\n",
            "Validation score: 0.235043\n",
            "Iteration 94, loss = 2.07038744\n",
            "Validation score: 0.252137\n",
            "Iteration 95, loss = 2.06832482\n",
            "Validation score: 0.277778\n",
            "Iteration 96, loss = 2.06730599\n",
            "Validation score: 0.243590\n",
            "Iteration 97, loss = 2.06591509\n",
            "Validation score: 0.243590\n",
            "Iteration 98, loss = 2.06464986\n",
            "Validation score: 0.269231\n",
            "Iteration 99, loss = 2.06165726\n",
            "Validation score: 0.269231\n",
            "Iteration 100, loss = 2.06139657\n",
            "Validation score: 0.243590\n",
            "Iteration 101, loss = 2.05984986\n",
            "Validation score: 0.252137\n",
            "Iteration 102, loss = 2.05875815\n",
            "Validation score: 0.247863\n",
            "Iteration 103, loss = 2.05610185\n",
            "Validation score: 0.256410\n",
            "Iteration 104, loss = 2.05584432\n",
            "Validation score: 0.252137\n",
            "Iteration 105, loss = 2.05481571\n",
            "Validation score: 0.252137\n",
            "Iteration 106, loss = 2.05366162\n",
            "Validation score: 0.243590\n",
            "Iteration 107, loss = 2.05210725\n",
            "Validation score: 0.247863\n",
            "Iteration 108, loss = 2.05027614\n",
            "Validation score: 0.260684\n",
            "Iteration 109, loss = 2.04848098\n",
            "Validation score: 0.247863\n",
            "Iteration 110, loss = 2.04739704\n",
            "Validation score: 0.256410\n",
            "Iteration 111, loss = 2.04693263\n",
            "Validation score: 0.256410\n",
            "Iteration 112, loss = 2.04480714\n",
            "Validation score: 0.252137\n",
            "Iteration 113, loss = 2.04351042\n",
            "Validation score: 0.269231\n",
            "Iteration 114, loss = 2.04141357\n",
            "Validation score: 0.252137\n",
            "Iteration 115, loss = 2.04119645\n",
            "Validation score: 0.256410\n",
            "Iteration 116, loss = 2.04007628\n",
            "Validation score: 0.243590\n",
            "Iteration 117, loss = 2.03907726\n",
            "Validation score: 0.273504\n",
            "Iteration 118, loss = 2.03656079\n",
            "Validation score: 0.252137\n",
            "Iteration 119, loss = 2.03595480\n",
            "Validation score: 0.269231\n",
            "Iteration 120, loss = 2.03475583\n",
            "Validation score: 0.260684\n",
            "Iteration 121, loss = 2.03488138\n",
            "Validation score: 0.243590\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.23885215\n",
            "Validation score: 0.059829\n",
            "Iteration 2, loss = 3.09980932\n",
            "Validation score: 0.051282\n",
            "Iteration 3, loss = 2.93255580\n",
            "Validation score: 0.085470\n",
            "Iteration 4, loss = 2.70261770\n",
            "Validation score: 0.111111\n",
            "Iteration 5, loss = 2.56791248\n",
            "Validation score: 0.106838\n",
            "Iteration 6, loss = 2.52423727\n",
            "Validation score: 0.141026\n",
            "Iteration 7, loss = 2.50691441\n",
            "Validation score: 0.136752\n",
            "Iteration 8, loss = 2.49614889\n",
            "Validation score: 0.136752\n",
            "Iteration 9, loss = 2.48696917\n",
            "Validation score: 0.136752\n",
            "Iteration 10, loss = 2.47880857\n",
            "Validation score: 0.132479\n",
            "Iteration 11, loss = 2.47052662\n",
            "Validation score: 0.119658\n",
            "Iteration 12, loss = 2.46419253\n",
            "Validation score: 0.136752\n",
            "Iteration 13, loss = 2.45760501\n",
            "Validation score: 0.128205\n",
            "Iteration 14, loss = 2.45107324\n",
            "Validation score: 0.141026\n",
            "Iteration 15, loss = 2.44445738\n",
            "Validation score: 0.141026\n",
            "Iteration 16, loss = 2.43872224\n",
            "Validation score: 0.132479\n",
            "Iteration 17, loss = 2.43203456\n",
            "Validation score: 0.145299\n",
            "Iteration 18, loss = 2.42666294\n",
            "Validation score: 0.145299\n",
            "Iteration 19, loss = 2.42004542\n",
            "Validation score: 0.145299\n",
            "Iteration 20, loss = 2.41334423\n",
            "Validation score: 0.145299\n",
            "Iteration 21, loss = 2.40766352\n",
            "Validation score: 0.145299\n",
            "Iteration 22, loss = 2.40122284\n",
            "Validation score: 0.149573\n",
            "Iteration 23, loss = 2.39451085\n",
            "Validation score: 0.149573\n",
            "Iteration 24, loss = 2.38797954\n",
            "Validation score: 0.175214\n",
            "Iteration 25, loss = 2.38196314\n",
            "Validation score: 0.170940\n",
            "Iteration 26, loss = 2.37520649\n",
            "Validation score: 0.175214\n",
            "Iteration 27, loss = 2.36932943\n",
            "Validation score: 0.179487\n",
            "Iteration 28, loss = 2.36251512\n",
            "Validation score: 0.170940\n",
            "Iteration 29, loss = 2.35592593\n",
            "Validation score: 0.175214\n",
            "Iteration 30, loss = 2.34999145\n",
            "Validation score: 0.175214\n",
            "Iteration 31, loss = 2.34389916\n",
            "Validation score: 0.192308\n",
            "Iteration 32, loss = 2.33801487\n",
            "Validation score: 0.188034\n",
            "Iteration 33, loss = 2.33179604\n",
            "Validation score: 0.183761\n",
            "Iteration 34, loss = 2.32625229\n",
            "Validation score: 0.188034\n",
            "Iteration 35, loss = 2.32085449\n",
            "Validation score: 0.188034\n",
            "Iteration 36, loss = 2.31586642\n",
            "Validation score: 0.192308\n",
            "Iteration 37, loss = 2.30997558\n",
            "Validation score: 0.188034\n",
            "Iteration 38, loss = 2.30524957\n",
            "Validation score: 0.196581\n",
            "Iteration 39, loss = 2.30038454\n",
            "Validation score: 0.200855\n",
            "Iteration 40, loss = 2.29568564\n",
            "Validation score: 0.200855\n",
            "Iteration 41, loss = 2.29153193\n",
            "Validation score: 0.200855\n",
            "Iteration 42, loss = 2.28731931\n",
            "Validation score: 0.200855\n",
            "Iteration 43, loss = 2.28328878\n",
            "Validation score: 0.200855\n",
            "Iteration 44, loss = 2.27950228\n",
            "Validation score: 0.209402\n",
            "Iteration 45, loss = 2.27546475\n",
            "Validation score: 0.205128\n",
            "Iteration 46, loss = 2.27173532\n",
            "Validation score: 0.226496\n",
            "Iteration 47, loss = 2.26828945\n",
            "Validation score: 0.226496\n",
            "Iteration 48, loss = 2.26544343\n",
            "Validation score: 0.222222\n",
            "Iteration 49, loss = 2.26188918\n",
            "Validation score: 0.217949\n",
            "Iteration 50, loss = 2.25862593\n",
            "Validation score: 0.239316\n",
            "Iteration 51, loss = 2.25552435\n",
            "Validation score: 0.226496\n",
            "Iteration 52, loss = 2.25276301\n",
            "Validation score: 0.239316\n",
            "Iteration 53, loss = 2.24998175\n",
            "Validation score: 0.226496\n",
            "Iteration 54, loss = 2.24687862\n",
            "Validation score: 0.222222\n",
            "Iteration 55, loss = 2.24463964\n",
            "Validation score: 0.230769\n",
            "Iteration 56, loss = 2.24205923\n",
            "Validation score: 0.226496\n",
            "Iteration 57, loss = 2.23913597\n",
            "Validation score: 0.222222\n",
            "Iteration 58, loss = 2.23694956\n",
            "Validation score: 0.226496\n",
            "Iteration 59, loss = 2.23477534\n",
            "Validation score: 0.226496\n",
            "Iteration 60, loss = 2.23212633\n",
            "Validation score: 0.226496\n",
            "Iteration 61, loss = 2.23010528\n",
            "Validation score: 0.230769\n",
            "Iteration 62, loss = 2.22845822\n",
            "Validation score: 0.235043\n",
            "Iteration 63, loss = 2.22607215\n",
            "Validation score: 0.230769\n",
            "Iteration 64, loss = 2.22373072\n",
            "Validation score: 0.222222\n",
            "Iteration 65, loss = 2.22185838\n",
            "Validation score: 0.217949\n",
            "Iteration 66, loss = 2.22056334\n",
            "Validation score: 0.230769\n",
            "Iteration 67, loss = 2.21828166\n",
            "Validation score: 0.226496\n",
            "Iteration 68, loss = 2.21693161\n",
            "Validation score: 0.239316\n",
            "Iteration 69, loss = 2.21506602\n",
            "Validation score: 0.226496\n",
            "Iteration 70, loss = 2.21356992\n",
            "Validation score: 0.239316\n",
            "Iteration 71, loss = 2.21269001\n",
            "Validation score: 0.222222\n",
            "Iteration 72, loss = 2.21112656\n",
            "Validation score: 0.235043\n",
            "Iteration 73, loss = 2.20875037\n",
            "Validation score: 0.235043\n",
            "Iteration 74, loss = 2.20692721\n",
            "Validation score: 0.243590\n",
            "Iteration 75, loss = 2.20584353\n",
            "Validation score: 0.230769\n",
            "Iteration 76, loss = 2.20413663\n",
            "Validation score: 0.226496\n",
            "Iteration 77, loss = 2.20319005\n",
            "Validation score: 0.222222\n",
            "Iteration 78, loss = 2.20136323\n",
            "Validation score: 0.235043\n",
            "Iteration 79, loss = 2.20033994\n",
            "Validation score: 0.230769\n",
            "Iteration 80, loss = 2.19911996\n",
            "Validation score: 0.226496\n",
            "Iteration 81, loss = 2.19807592\n",
            "Validation score: 0.230769\n",
            "Iteration 82, loss = 2.19675378\n",
            "Validation score: 0.235043\n",
            "Iteration 83, loss = 2.19545782\n",
            "Validation score: 0.230769\n",
            "Iteration 84, loss = 2.19455788\n",
            "Validation score: 0.222222\n",
            "Iteration 85, loss = 2.19304023\n",
            "Validation score: 0.226496\n",
            "Iteration 86, loss = 2.19242356\n",
            "Validation score: 0.226496\n",
            "Iteration 87, loss = 2.19128677\n",
            "Validation score: 0.235043\n",
            "Iteration 88, loss = 2.19013080\n",
            "Validation score: 0.217949\n",
            "Iteration 89, loss = 2.18918428\n",
            "Validation score: 0.222222\n",
            "Iteration 90, loss = 2.18787964\n",
            "Validation score: 0.217949\n",
            "Iteration 91, loss = 2.18625786\n",
            "Validation score: 0.217949\n",
            "Iteration 92, loss = 2.18484887\n",
            "Validation score: 0.217949\n",
            "Iteration 93, loss = 2.18446143\n",
            "Validation score: 0.222222\n",
            "Iteration 94, loss = 2.18311249\n",
            "Validation score: 0.217949\n",
            "Iteration 95, loss = 2.18285351\n",
            "Validation score: 0.217949\n",
            "Iteration 96, loss = 2.18168370\n",
            "Validation score: 0.226496\n",
            "Iteration 97, loss = 2.18086379\n",
            "Validation score: 0.226496\n",
            "Iteration 98, loss = 2.17948400\n",
            "Validation score: 0.230769\n",
            "Iteration 99, loss = 2.17898440\n",
            "Validation score: 0.226496\n",
            "Iteration 100, loss = 2.17756475\n",
            "Validation score: 0.239316\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.27595518\n",
            "Validation score: 0.136752\n",
            "Iteration 2, loss = 3.11481327\n",
            "Validation score: 0.136752\n",
            "Iteration 3, loss = 2.93668364\n",
            "Validation score: 0.136752\n",
            "Iteration 4, loss = 2.76627253\n",
            "Validation score: 0.136752\n",
            "Iteration 5, loss = 2.64625217\n",
            "Validation score: 0.136752\n",
            "Iteration 6, loss = 2.57845094\n",
            "Validation score: 0.136752\n",
            "Iteration 7, loss = 2.54563536\n",
            "Validation score: 0.136752\n",
            "Iteration 8, loss = 2.52963267\n",
            "Validation score: 0.136752\n",
            "Iteration 9, loss = 2.52154154\n",
            "Validation score: 0.136752\n",
            "Iteration 10, loss = 2.51676250\n",
            "Validation score: 0.141026\n",
            "Iteration 11, loss = 2.51391581\n",
            "Validation score: 0.141026\n",
            "Iteration 12, loss = 2.51172406\n",
            "Validation score: 0.136752\n",
            "Iteration 13, loss = 2.50995845\n",
            "Validation score: 0.141026\n",
            "Iteration 14, loss = 2.50880447\n",
            "Validation score: 0.136752\n",
            "Iteration 15, loss = 2.50765874\n",
            "Validation score: 0.136752\n",
            "Iteration 16, loss = 2.50687632\n",
            "Validation score: 0.136752\n",
            "Iteration 17, loss = 2.50655693\n",
            "Validation score: 0.141026\n",
            "Iteration 18, loss = 2.50573466\n",
            "Validation score: 0.141026\n",
            "Iteration 19, loss = 2.50519887\n",
            "Validation score: 0.141026\n",
            "Iteration 20, loss = 2.50498474\n",
            "Validation score: 0.136752\n",
            "Iteration 21, loss = 2.50447332\n",
            "Validation score: 0.136752\n",
            "Iteration 22, loss = 2.50419035\n",
            "Validation score: 0.136752\n",
            "Iteration 23, loss = 2.50395926\n",
            "Validation score: 0.136752\n",
            "Iteration 24, loss = 2.50408831\n",
            "Validation score: 0.141026\n",
            "Iteration 25, loss = 2.50385916\n",
            "Validation score: 0.141026\n",
            "Iteration 26, loss = 2.50388395\n",
            "Validation score: 0.141026\n",
            "Iteration 27, loss = 2.50345237\n",
            "Validation score: 0.136752\n",
            "Iteration 28, loss = 2.50331960\n",
            "Validation score: 0.136752\n",
            "Iteration 29, loss = 2.50336606\n",
            "Validation score: 0.136752\n",
            "Iteration 30, loss = 2.50317147\n",
            "Validation score: 0.136752\n",
            "Iteration 31, loss = 2.50300429\n",
            "Validation score: 0.136752\n",
            "Iteration 32, loss = 2.50293004\n",
            "Validation score: 0.136752\n",
            "Iteration 33, loss = 2.50291775\n",
            "Validation score: 0.141026\n",
            "Iteration 34, loss = 2.50293452\n",
            "Validation score: 0.136752\n",
            "Iteration 35, loss = 2.50297945\n",
            "Validation score: 0.141026\n",
            "Iteration 36, loss = 2.50289792\n",
            "Validation score: 0.141026\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.31198003\n",
            "Validation score: 0.115385\n",
            "Iteration 2, loss = 3.19996456\n",
            "Validation score: 0.141026\n",
            "Iteration 3, loss = 3.10827808\n",
            "Validation score: 0.141026\n",
            "Iteration 4, loss = 3.02876945\n",
            "Validation score: 0.141026\n",
            "Iteration 5, loss = 2.95930509\n",
            "Validation score: 0.141026\n",
            "Iteration 6, loss = 2.89827161\n",
            "Validation score: 0.141026\n",
            "Iteration 7, loss = 2.84507781\n",
            "Validation score: 0.141026\n",
            "Iteration 8, loss = 2.79910088\n",
            "Validation score: 0.141026\n",
            "Iteration 9, loss = 2.75933021\n",
            "Validation score: 0.141026\n",
            "Iteration 10, loss = 2.72504564\n",
            "Validation score: 0.141026\n",
            "Iteration 11, loss = 2.69539148\n",
            "Validation score: 0.141026\n",
            "Iteration 12, loss = 2.66995709\n",
            "Validation score: 0.141026\n",
            "Iteration 13, loss = 2.64289673\n",
            "Validation score: 0.141026\n",
            "Iteration 14, loss = 2.58380077\n",
            "Validation score: 0.175214\n",
            "Iteration 15, loss = 2.54298449\n",
            "Validation score: 0.136752\n",
            "Iteration 16, loss = 2.52737977\n",
            "Validation score: 0.136752\n",
            "Iteration 17, loss = 2.51672808\n",
            "Validation score: 0.136752\n",
            "Iteration 18, loss = 2.50639348\n",
            "Validation score: 0.145299\n",
            "Iteration 19, loss = 2.49489572\n",
            "Validation score: 0.153846\n",
            "Iteration 20, loss = 2.48366734\n",
            "Validation score: 0.153846\n",
            "Iteration 21, loss = 2.47371258\n",
            "Validation score: 0.153846\n",
            "Iteration 22, loss = 2.46412140\n",
            "Validation score: 0.158120\n",
            "Iteration 23, loss = 2.45439004\n",
            "Validation score: 0.162393\n",
            "Iteration 24, loss = 2.44537562\n",
            "Validation score: 0.170940\n",
            "Iteration 25, loss = 2.43561033\n",
            "Validation score: 0.162393\n",
            "Iteration 26, loss = 2.42676953\n",
            "Validation score: 0.179487\n",
            "Iteration 27, loss = 2.41782997\n",
            "Validation score: 0.183761\n",
            "Iteration 28, loss = 2.40908343\n",
            "Validation score: 0.183761\n",
            "Iteration 29, loss = 2.40066776\n",
            "Validation score: 0.188034\n",
            "Iteration 30, loss = 2.39290974\n",
            "Validation score: 0.188034\n",
            "Iteration 31, loss = 2.38500282\n",
            "Validation score: 0.196581\n",
            "Iteration 32, loss = 2.37753771\n",
            "Validation score: 0.222222\n",
            "Iteration 33, loss = 2.37050430\n",
            "Validation score: 0.239316\n",
            "Iteration 34, loss = 2.36394181\n",
            "Validation score: 0.252137\n",
            "Iteration 35, loss = 2.35743161\n",
            "Validation score: 0.252137\n",
            "Iteration 36, loss = 2.35160019\n",
            "Validation score: 0.252137\n",
            "Iteration 37, loss = 2.34559691\n",
            "Validation score: 0.260684\n",
            "Iteration 38, loss = 2.34054467\n",
            "Validation score: 0.256410\n",
            "Iteration 39, loss = 2.33551006\n",
            "Validation score: 0.256410\n",
            "Iteration 40, loss = 2.33005911\n",
            "Validation score: 0.252137\n",
            "Iteration 41, loss = 2.32504370\n",
            "Validation score: 0.256410\n",
            "Iteration 42, loss = 2.32021790\n",
            "Validation score: 0.264957\n",
            "Iteration 43, loss = 2.31509881\n",
            "Validation score: 0.252137\n",
            "Iteration 44, loss = 2.31009119\n",
            "Validation score: 0.247863\n",
            "Iteration 45, loss = 2.30503131\n",
            "Validation score: 0.247863\n",
            "Iteration 46, loss = 2.30140590\n",
            "Validation score: 0.247863\n",
            "Iteration 47, loss = 2.29701060\n",
            "Validation score: 0.247863\n",
            "Iteration 48, loss = 2.29312211\n",
            "Validation score: 0.243590\n",
            "Iteration 49, loss = 2.28919550\n",
            "Validation score: 0.252137\n",
            "Iteration 50, loss = 2.28540421\n",
            "Validation score: 0.260684\n",
            "Iteration 51, loss = 2.28207266\n",
            "Validation score: 0.260684\n",
            "Iteration 52, loss = 2.27828697\n",
            "Validation score: 0.264957\n",
            "Iteration 53, loss = 2.27478670\n",
            "Validation score: 0.264957\n",
            "Iteration 54, loss = 2.27252397\n",
            "Validation score: 0.273504\n",
            "Iteration 55, loss = 2.26903403\n",
            "Validation score: 0.260684\n",
            "Iteration 56, loss = 2.26580800\n",
            "Validation score: 0.269231\n",
            "Iteration 57, loss = 2.26284003\n",
            "Validation score: 0.264957\n",
            "Iteration 58, loss = 2.26003994\n",
            "Validation score: 0.269231\n",
            "Iteration 59, loss = 2.25751022\n",
            "Validation score: 0.269231\n",
            "Iteration 60, loss = 2.25489581\n",
            "Validation score: 0.269231\n",
            "Iteration 61, loss = 2.25245602\n",
            "Validation score: 0.269231\n",
            "Iteration 62, loss = 2.25071208\n",
            "Validation score: 0.269231\n",
            "Iteration 63, loss = 2.24771531\n",
            "Validation score: 0.282051\n",
            "Iteration 64, loss = 2.24586497\n",
            "Validation score: 0.260684\n",
            "Iteration 65, loss = 2.24355255\n",
            "Validation score: 0.256410\n",
            "Iteration 66, loss = 2.24151088\n",
            "Validation score: 0.264957\n",
            "Iteration 67, loss = 2.24032248\n",
            "Validation score: 0.264957\n",
            "Iteration 68, loss = 2.23749446\n",
            "Validation score: 0.273504\n",
            "Iteration 69, loss = 2.23595465\n",
            "Validation score: 0.260684\n",
            "Iteration 70, loss = 2.23469540\n",
            "Validation score: 0.277778\n",
            "Iteration 71, loss = 2.23200783\n",
            "Validation score: 0.260684\n",
            "Iteration 72, loss = 2.23036319\n",
            "Validation score: 0.260684\n",
            "Iteration 73, loss = 2.22881482\n",
            "Validation score: 0.277778\n",
            "Iteration 74, loss = 2.22741661\n",
            "Validation score: 0.282051\n",
            "Iteration 75, loss = 2.22549669\n",
            "Validation score: 0.273504\n",
            "Iteration 76, loss = 2.22414853\n",
            "Validation score: 0.273504\n",
            "Iteration 77, loss = 2.22306862\n",
            "Validation score: 0.264957\n",
            "Iteration 78, loss = 2.22161686\n",
            "Validation score: 0.273504\n",
            "Iteration 79, loss = 2.21982139\n",
            "Validation score: 0.256410\n",
            "Iteration 80, loss = 2.21829598\n",
            "Validation score: 0.260684\n",
            "Iteration 81, loss = 2.21692835\n",
            "Validation score: 0.264957\n",
            "Iteration 82, loss = 2.21558550\n",
            "Validation score: 0.277778\n",
            "Iteration 83, loss = 2.21444805\n",
            "Validation score: 0.269231\n",
            "Iteration 84, loss = 2.21269756\n",
            "Validation score: 0.264957\n",
            "Iteration 85, loss = 2.21121748\n",
            "Validation score: 0.269231\n",
            "Iteration 86, loss = 2.20970824\n",
            "Validation score: 0.277778\n",
            "Iteration 87, loss = 2.20897761\n",
            "Validation score: 0.277778\n",
            "Iteration 88, loss = 2.20775550\n",
            "Validation score: 0.269231\n",
            "Iteration 89, loss = 2.20622795\n",
            "Validation score: 0.273504\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.21125354\n",
            "Validation score: 0.068376\n",
            "Iteration 2, loss = 2.94851427\n",
            "Validation score: 0.179487\n",
            "Iteration 3, loss = 2.64130566\n",
            "Validation score: 0.183761\n",
            "Iteration 4, loss = 2.53437153\n",
            "Validation score: 0.175214\n",
            "Iteration 5, loss = 2.50293866\n",
            "Validation score: 0.188034\n",
            "Iteration 6, loss = 2.48644353\n",
            "Validation score: 0.175214\n",
            "Iteration 7, loss = 2.47464644\n",
            "Validation score: 0.179487\n",
            "Iteration 8, loss = 2.46588267\n",
            "Validation score: 0.205128\n",
            "Iteration 9, loss = 2.45699665\n",
            "Validation score: 0.196581\n",
            "Iteration 10, loss = 2.44913961\n",
            "Validation score: 0.179487\n",
            "Iteration 11, loss = 2.44182497\n",
            "Validation score: 0.179487\n",
            "Iteration 12, loss = 2.43394706\n",
            "Validation score: 0.179487\n",
            "Iteration 13, loss = 2.42666033\n",
            "Validation score: 0.183761\n",
            "Iteration 14, loss = 2.41857630\n",
            "Validation score: 0.179487\n",
            "Iteration 15, loss = 2.41078312\n",
            "Validation score: 0.179487\n",
            "Iteration 16, loss = 2.40228569\n",
            "Validation score: 0.179487\n",
            "Iteration 17, loss = 2.39459873\n",
            "Validation score: 0.196581\n",
            "Iteration 18, loss = 2.38724295\n",
            "Validation score: 0.179487\n",
            "Iteration 19, loss = 2.37856925\n",
            "Validation score: 0.183761\n",
            "Iteration 20, loss = 2.37184680\n",
            "Validation score: 0.183761\n",
            "Iteration 21, loss = 2.36381871\n",
            "Validation score: 0.183761\n",
            "Iteration 22, loss = 2.35692864\n",
            "Validation score: 0.183761\n",
            "Iteration 23, loss = 2.34941515\n",
            "Validation score: 0.179487\n",
            "Iteration 24, loss = 2.34220360\n",
            "Validation score: 0.183761\n",
            "Iteration 25, loss = 2.33528719\n",
            "Validation score: 0.192308\n",
            "Iteration 26, loss = 2.32858872\n",
            "Validation score: 0.192308\n",
            "Iteration 27, loss = 2.32306619\n",
            "Validation score: 0.213675\n",
            "Iteration 28, loss = 2.31605698\n",
            "Validation score: 0.213675\n",
            "Iteration 29, loss = 2.31027215\n",
            "Validation score: 0.217949\n",
            "Iteration 30, loss = 2.30563450\n",
            "Validation score: 0.209402\n",
            "Iteration 31, loss = 2.29914109\n",
            "Validation score: 0.205128\n",
            "Iteration 32, loss = 2.29452215\n",
            "Validation score: 0.209402\n",
            "Iteration 33, loss = 2.28844059\n",
            "Validation score: 0.209402\n",
            "Iteration 34, loss = 2.28377600\n",
            "Validation score: 0.217949\n",
            "Iteration 35, loss = 2.27893681\n",
            "Validation score: 0.217949\n",
            "Iteration 36, loss = 2.27408772\n",
            "Validation score: 0.226496\n",
            "Iteration 37, loss = 2.26958729\n",
            "Validation score: 0.217949\n",
            "Iteration 38, loss = 2.26590861\n",
            "Validation score: 0.217949\n",
            "Iteration 39, loss = 2.26099136\n",
            "Validation score: 0.209402\n",
            "Iteration 40, loss = 2.25723662\n",
            "Validation score: 0.213675\n",
            "Iteration 41, loss = 2.25294052\n",
            "Validation score: 0.205128\n",
            "Iteration 42, loss = 2.24927466\n",
            "Validation score: 0.200855\n",
            "Iteration 43, loss = 2.24542068\n",
            "Validation score: 0.209402\n",
            "Iteration 44, loss = 2.24235704\n",
            "Validation score: 0.209402\n",
            "Iteration 45, loss = 2.23868115\n",
            "Validation score: 0.205128\n",
            "Iteration 46, loss = 2.23548252\n",
            "Validation score: 0.209402\n",
            "Iteration 47, loss = 2.23207859\n",
            "Validation score: 0.217949\n",
            "Iteration 48, loss = 2.22966761\n",
            "Validation score: 0.217949\n",
            "Iteration 49, loss = 2.22673070\n",
            "Validation score: 0.213675\n",
            "Iteration 50, loss = 2.22437376\n",
            "Validation score: 0.226496\n",
            "Iteration 51, loss = 2.21993794\n",
            "Validation score: 0.209402\n",
            "Iteration 52, loss = 2.21814484\n",
            "Validation score: 0.209402\n",
            "Iteration 53, loss = 2.21479304\n",
            "Validation score: 0.213675\n",
            "Iteration 54, loss = 2.21284146\n",
            "Validation score: 0.200855\n",
            "Iteration 55, loss = 2.21089266\n",
            "Validation score: 0.209402\n",
            "Iteration 56, loss = 2.20813254\n",
            "Validation score: 0.213675\n",
            "Iteration 57, loss = 2.20542671\n",
            "Validation score: 0.213675\n",
            "Iteration 58, loss = 2.20356583\n",
            "Validation score: 0.217949\n",
            "Iteration 59, loss = 2.20139297\n",
            "Validation score: 0.213675\n",
            "Iteration 60, loss = 2.19889709\n",
            "Validation score: 0.222222\n",
            "Iteration 61, loss = 2.19674489\n",
            "Validation score: 0.209402\n",
            "Iteration 62, loss = 2.19526835\n",
            "Validation score: 0.217949\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.15835461\n",
            "Validation score: 0.153846\n",
            "Iteration 2, loss = 2.95097401\n",
            "Validation score: 0.153846\n",
            "Iteration 3, loss = 2.70801561\n",
            "Validation score: 0.123932\n",
            "Iteration 4, loss = 2.58520155\n",
            "Validation score: 0.128205\n",
            "Iteration 5, loss = 2.54471137\n",
            "Validation score: 0.119658\n",
            "Iteration 6, loss = 2.52613258\n",
            "Validation score: 0.111111\n",
            "Iteration 7, loss = 2.51501141\n",
            "Validation score: 0.128205\n",
            "Iteration 8, loss = 2.50819903\n",
            "Validation score: 0.123932\n",
            "Iteration 9, loss = 2.50272286\n",
            "Validation score: 0.128205\n",
            "Iteration 10, loss = 2.49880161\n",
            "Validation score: 0.115385\n",
            "Iteration 11, loss = 2.49566189\n",
            "Validation score: 0.115385\n",
            "Iteration 12, loss = 2.49269831\n",
            "Validation score: 0.123932\n",
            "Iteration 13, loss = 2.48988522\n",
            "Validation score: 0.115385\n",
            "Iteration 14, loss = 2.48794344\n",
            "Validation score: 0.123932\n",
            "Iteration 15, loss = 2.48568713\n",
            "Validation score: 0.119658\n",
            "Iteration 16, loss = 2.48387462\n",
            "Validation score: 0.111111\n",
            "Iteration 17, loss = 2.48188885\n",
            "Validation score: 0.128205\n",
            "Iteration 18, loss = 2.47980622\n",
            "Validation score: 0.119658\n",
            "Iteration 19, loss = 2.47815141\n",
            "Validation score: 0.128205\n",
            "Iteration 20, loss = 2.47613411\n",
            "Validation score: 0.115385\n",
            "Iteration 21, loss = 2.47446418\n",
            "Validation score: 0.123932\n",
            "Iteration 22, loss = 2.47258462\n",
            "Validation score: 0.128205\n",
            "Iteration 23, loss = 2.47031489\n",
            "Validation score: 0.141026\n",
            "Iteration 24, loss = 2.46873147\n",
            "Validation score: 0.119658\n",
            "Iteration 25, loss = 2.46715163\n",
            "Validation score: 0.123932\n",
            "Iteration 26, loss = 2.46422745\n",
            "Validation score: 0.128205\n",
            "Iteration 27, loss = 2.46232908\n",
            "Validation score: 0.132479\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.30064880\n",
            "Validation score: 0.017094\n",
            "Iteration 2, loss = 3.04774045\n",
            "Validation score: 0.162393\n",
            "Iteration 3, loss = 2.67561706\n",
            "Validation score: 0.145299\n",
            "Iteration 4, loss = 2.56330335\n",
            "Validation score: 0.106838\n",
            "Iteration 5, loss = 2.52762055\n",
            "Validation score: 0.106838\n",
            "Iteration 6, loss = 2.51361517\n",
            "Validation score: 0.106838\n",
            "Iteration 7, loss = 2.50129704\n",
            "Validation score: 0.106838\n",
            "Iteration 8, loss = 2.48934210\n",
            "Validation score: 0.175214\n",
            "Iteration 9, loss = 2.47711626\n",
            "Validation score: 0.170940\n",
            "Iteration 10, loss = 2.46123540\n",
            "Validation score: 0.183761\n",
            "Iteration 11, loss = 2.44285116\n",
            "Validation score: 0.166667\n",
            "Iteration 12, loss = 2.42181519\n",
            "Validation score: 0.166667\n",
            "Iteration 13, loss = 2.39826632\n",
            "Validation score: 0.170940\n",
            "Iteration 14, loss = 2.37438039\n",
            "Validation score: 0.183761\n",
            "Iteration 15, loss = 2.35360205\n",
            "Validation score: 0.192308\n",
            "Iteration 16, loss = 2.33397804\n",
            "Validation score: 0.188034\n",
            "Iteration 17, loss = 2.31813153\n",
            "Validation score: 0.179487\n",
            "Iteration 18, loss = 2.30401907\n",
            "Validation score: 0.175214\n",
            "Iteration 19, loss = 2.29156662\n",
            "Validation score: 0.209402\n",
            "Iteration 20, loss = 2.28182393\n",
            "Validation score: 0.200855\n",
            "Iteration 21, loss = 2.27164388\n",
            "Validation score: 0.200855\n",
            "Iteration 22, loss = 2.26444885\n",
            "Validation score: 0.205128\n",
            "Iteration 23, loss = 2.25536561\n",
            "Validation score: 0.213675\n",
            "Iteration 24, loss = 2.24816848\n",
            "Validation score: 0.205128\n",
            "Iteration 25, loss = 2.24114176\n",
            "Validation score: 0.213675\n",
            "Iteration 26, loss = 2.23403892\n",
            "Validation score: 0.205128\n",
            "Iteration 27, loss = 2.22855945\n",
            "Validation score: 0.226496\n",
            "Iteration 28, loss = 2.22164793\n",
            "Validation score: 0.217949\n",
            "Iteration 29, loss = 2.21575082\n",
            "Validation score: 0.217949\n",
            "Iteration 30, loss = 2.20999352\n",
            "Validation score: 0.213675\n",
            "Iteration 31, loss = 2.20522207\n",
            "Validation score: 0.217949\n",
            "Iteration 32, loss = 2.19942043\n",
            "Validation score: 0.213675\n",
            "Iteration 33, loss = 2.19475603\n",
            "Validation score: 0.217949\n",
            "Iteration 34, loss = 2.19029358\n",
            "Validation score: 0.222222\n",
            "Iteration 35, loss = 2.18546504\n",
            "Validation score: 0.235043\n",
            "Iteration 36, loss = 2.18101235\n",
            "Validation score: 0.217949\n",
            "Iteration 37, loss = 2.17763758\n",
            "Validation score: 0.235043\n",
            "Iteration 38, loss = 2.17344114\n",
            "Validation score: 0.239316\n",
            "Iteration 39, loss = 2.16987994\n",
            "Validation score: 0.222222\n",
            "Iteration 40, loss = 2.16598083\n",
            "Validation score: 0.243590\n",
            "Iteration 41, loss = 2.16211160\n",
            "Validation score: 0.243590\n",
            "Iteration 42, loss = 2.15943831\n",
            "Validation score: 0.239316\n",
            "Iteration 43, loss = 2.15574914\n",
            "Validation score: 0.235043\n",
            "Iteration 44, loss = 2.15164335\n",
            "Validation score: 0.243590\n",
            "Iteration 45, loss = 2.14994502\n",
            "Validation score: 0.252137\n",
            "Iteration 46, loss = 2.14668474\n",
            "Validation score: 0.252137\n",
            "Iteration 47, loss = 2.14303522\n",
            "Validation score: 0.243590\n",
            "Iteration 48, loss = 2.14021276\n",
            "Validation score: 0.243590\n",
            "Iteration 49, loss = 2.13725752\n",
            "Validation score: 0.243590\n",
            "Iteration 50, loss = 2.13452929\n",
            "Validation score: 0.243590\n",
            "Iteration 51, loss = 2.13218009\n",
            "Validation score: 0.256410\n",
            "Iteration 52, loss = 2.12874568\n",
            "Validation score: 0.247863\n",
            "Iteration 53, loss = 2.12635049\n",
            "Validation score: 0.260684\n",
            "Iteration 54, loss = 2.12377568\n",
            "Validation score: 0.252137\n",
            "Iteration 55, loss = 2.12157642\n",
            "Validation score: 0.247863\n",
            "Iteration 56, loss = 2.11896839\n",
            "Validation score: 0.247863\n",
            "Iteration 57, loss = 2.11651599\n",
            "Validation score: 0.252137\n",
            "Iteration 58, loss = 2.11368755\n",
            "Validation score: 0.247863\n",
            "Iteration 59, loss = 2.11092763\n",
            "Validation score: 0.247863\n",
            "Iteration 60, loss = 2.10851380\n",
            "Validation score: 0.243590\n",
            "Iteration 61, loss = 2.10676298\n",
            "Validation score: 0.252137\n",
            "Iteration 62, loss = 2.10457661\n",
            "Validation score: 0.235043\n",
            "Iteration 63, loss = 2.10212954\n",
            "Validation score: 0.243590\n",
            "Iteration 64, loss = 2.10025991\n",
            "Validation score: 0.239316\n",
            "Iteration 65, loss = 2.09726001\n",
            "Validation score: 0.239316\n",
            "Iteration 66, loss = 2.09511224\n",
            "Validation score: 0.239316\n",
            "Iteration 67, loss = 2.09309204\n",
            "Validation score: 0.226496\n",
            "Iteration 68, loss = 2.09140632\n",
            "Validation score: 0.239316\n",
            "Iteration 69, loss = 2.08968245\n",
            "Validation score: 0.226496\n",
            "Iteration 70, loss = 2.08743593\n",
            "Validation score: 0.247863\n",
            "Iteration 71, loss = 2.08606956\n",
            "Validation score: 0.235043\n",
            "Iteration 72, loss = 2.08366114\n",
            "Validation score: 0.226496\n",
            "Iteration 73, loss = 2.08129457\n",
            "Validation score: 0.230769\n",
            "Iteration 74, loss = 2.07840884\n",
            "Validation score: 0.235043\n",
            "Iteration 75, loss = 2.07843326\n",
            "Validation score: 0.226496\n",
            "Iteration 76, loss = 2.07513380\n",
            "Validation score: 0.230769\n",
            "Iteration 77, loss = 2.07407873\n",
            "Validation score: 0.239316\n",
            "Iteration 78, loss = 2.07141122\n",
            "Validation score: 0.230769\n",
            "Iteration 79, loss = 2.06966016\n",
            "Validation score: 0.226496\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.11628425\n",
            "Validation score: 0.188034\n",
            "Iteration 2, loss = 2.98442059\n",
            "Validation score: 0.188034\n",
            "Iteration 3, loss = 2.83807420\n",
            "Validation score: 0.188034\n",
            "Iteration 4, loss = 2.70485968\n",
            "Validation score: 0.188034\n",
            "Iteration 5, loss = 2.61975903\n",
            "Validation score: 0.188034\n",
            "Iteration 6, loss = 2.57262799\n",
            "Validation score: 0.188034\n",
            "Iteration 7, loss = 2.54640990\n",
            "Validation score: 0.183761\n",
            "Iteration 8, loss = 2.53140638\n",
            "Validation score: 0.188034\n",
            "Iteration 9, loss = 2.52165450\n",
            "Validation score: 0.188034\n",
            "Iteration 10, loss = 2.51354871\n",
            "Validation score: 0.188034\n",
            "Iteration 11, loss = 2.50639011\n",
            "Validation score: 0.188034\n",
            "Iteration 12, loss = 2.49877071\n",
            "Validation score: 0.188034\n",
            "Iteration 13, loss = 2.49146889\n",
            "Validation score: 0.188034\n",
            "Iteration 14, loss = 2.48356991\n",
            "Validation score: 0.188034\n",
            "Iteration 15, loss = 2.47524468\n",
            "Validation score: 0.188034\n",
            "Iteration 16, loss = 2.46766825\n",
            "Validation score: 0.200855\n",
            "Iteration 17, loss = 2.45973155\n",
            "Validation score: 0.200855\n",
            "Iteration 18, loss = 2.45223033\n",
            "Validation score: 0.209402\n",
            "Iteration 19, loss = 2.44471921\n",
            "Validation score: 0.213675\n",
            "Iteration 20, loss = 2.43732392\n",
            "Validation score: 0.209402\n",
            "Iteration 21, loss = 2.43000821\n",
            "Validation score: 0.213675\n",
            "Iteration 22, loss = 2.42292553\n",
            "Validation score: 0.222222\n",
            "Iteration 23, loss = 2.41541325\n",
            "Validation score: 0.222222\n",
            "Iteration 24, loss = 2.40858166\n",
            "Validation score: 0.222222\n",
            "Iteration 25, loss = 2.40165966\n",
            "Validation score: 0.235043\n",
            "Iteration 26, loss = 2.39470982\n",
            "Validation score: 0.230769\n",
            "Iteration 27, loss = 2.38798324\n",
            "Validation score: 0.226496\n",
            "Iteration 28, loss = 2.38144542\n",
            "Validation score: 0.243590\n",
            "Iteration 29, loss = 2.37499605\n",
            "Validation score: 0.243590\n",
            "Iteration 30, loss = 2.36820009\n",
            "Validation score: 0.239316\n",
            "Iteration 31, loss = 2.36240911\n",
            "Validation score: 0.230769\n",
            "Iteration 32, loss = 2.35634396\n",
            "Validation score: 0.239316\n",
            "Iteration 33, loss = 2.35105567\n",
            "Validation score: 0.235043\n",
            "Iteration 34, loss = 2.34480564\n",
            "Validation score: 0.239316\n",
            "Iteration 35, loss = 2.33955772\n",
            "Validation score: 0.239316\n",
            "Iteration 36, loss = 2.33461158\n",
            "Validation score: 0.243590\n",
            "Iteration 37, loss = 2.32962180\n",
            "Validation score: 0.243590\n",
            "Iteration 38, loss = 2.32500012\n",
            "Validation score: 0.252137\n",
            "Iteration 39, loss = 2.32033699\n",
            "Validation score: 0.256410\n",
            "Iteration 40, loss = 2.31579410\n",
            "Validation score: 0.247863\n",
            "Iteration 41, loss = 2.31162181\n",
            "Validation score: 0.260684\n",
            "Iteration 42, loss = 2.30748849\n",
            "Validation score: 0.256410\n",
            "Iteration 43, loss = 2.30396275\n",
            "Validation score: 0.252137\n",
            "Iteration 44, loss = 2.30003020\n",
            "Validation score: 0.260684\n",
            "Iteration 45, loss = 2.29682551\n",
            "Validation score: 0.256410\n",
            "Iteration 46, loss = 2.29342593\n",
            "Validation score: 0.256410\n",
            "Iteration 47, loss = 2.29030385\n",
            "Validation score: 0.256410\n",
            "Iteration 48, loss = 2.28694627\n",
            "Validation score: 0.256410\n",
            "Iteration 49, loss = 2.28437530\n",
            "Validation score: 0.256410\n",
            "Iteration 50, loss = 2.28117525\n",
            "Validation score: 0.252137\n",
            "Iteration 51, loss = 2.27851836\n",
            "Validation score: 0.260684\n",
            "Iteration 52, loss = 2.27578146\n",
            "Validation score: 0.260684\n",
            "Iteration 53, loss = 2.27327945\n",
            "Validation score: 0.256410\n",
            "Iteration 54, loss = 2.27080726\n",
            "Validation score: 0.260684\n",
            "Iteration 55, loss = 2.26858644\n",
            "Validation score: 0.256410\n",
            "Iteration 56, loss = 2.26636278\n",
            "Validation score: 0.252137\n",
            "Iteration 57, loss = 2.26393409\n",
            "Validation score: 0.264957\n",
            "Iteration 58, loss = 2.26174200\n",
            "Validation score: 0.252137\n",
            "Iteration 59, loss = 2.25960926\n",
            "Validation score: 0.273504\n",
            "Iteration 60, loss = 2.25785705\n",
            "Validation score: 0.260684\n",
            "Iteration 61, loss = 2.25556352\n",
            "Validation score: 0.264957\n",
            "Iteration 62, loss = 2.25416385\n",
            "Validation score: 0.264957\n",
            "Iteration 63, loss = 2.25199803\n",
            "Validation score: 0.264957\n",
            "Iteration 64, loss = 2.25016545\n",
            "Validation score: 0.273504\n",
            "Iteration 65, loss = 2.24873797\n",
            "Validation score: 0.264957\n",
            "Iteration 66, loss = 2.24666331\n",
            "Validation score: 0.269231\n",
            "Iteration 67, loss = 2.24517221\n",
            "Validation score: 0.273504\n",
            "Iteration 68, loss = 2.24341189\n",
            "Validation score: 0.273504\n",
            "Iteration 69, loss = 2.24176283\n",
            "Validation score: 0.264957\n",
            "Iteration 70, loss = 2.24073918\n",
            "Validation score: 0.269231\n",
            "Iteration 71, loss = 2.23871353\n",
            "Validation score: 0.264957\n",
            "Iteration 72, loss = 2.23756183\n",
            "Validation score: 0.260684\n",
            "Iteration 73, loss = 2.23611735\n",
            "Validation score: 0.269231\n",
            "Iteration 74, loss = 2.23453198\n",
            "Validation score: 0.269231\n",
            "Iteration 75, loss = 2.23314172\n",
            "Validation score: 0.269231\n",
            "Iteration 76, loss = 2.23197585\n",
            "Validation score: 0.273504\n",
            "Iteration 77, loss = 2.23044201\n",
            "Validation score: 0.286325\n",
            "Iteration 78, loss = 2.22914664\n",
            "Validation score: 0.282051\n",
            "Iteration 79, loss = 2.22780036\n",
            "Validation score: 0.282051\n",
            "Iteration 80, loss = 2.22635909\n",
            "Validation score: 0.273504\n",
            "Iteration 81, loss = 2.22490505\n",
            "Validation score: 0.273504\n",
            "Iteration 82, loss = 2.22348914\n",
            "Validation score: 0.286325\n",
            "Iteration 83, loss = 2.22218148\n",
            "Validation score: 0.299145\n",
            "Iteration 84, loss = 2.22037090\n",
            "Validation score: 0.294872\n",
            "Iteration 85, loss = 2.21931220\n",
            "Validation score: 0.299145\n",
            "Iteration 86, loss = 2.21821962\n",
            "Validation score: 0.294872\n",
            "Iteration 87, loss = 2.21670190\n",
            "Validation score: 0.290598\n",
            "Iteration 88, loss = 2.21518846\n",
            "Validation score: 0.286325\n",
            "Iteration 89, loss = 2.21370663\n",
            "Validation score: 0.290598\n",
            "Iteration 90, loss = 2.21314944\n",
            "Validation score: 0.294872\n",
            "Iteration 91, loss = 2.21104571\n",
            "Validation score: 0.299145\n",
            "Iteration 92, loss = 2.21016408\n",
            "Validation score: 0.299145\n",
            "Iteration 93, loss = 2.20847116\n",
            "Validation score: 0.294872\n",
            "Iteration 94, loss = 2.20702376\n",
            "Validation score: 0.303419\n",
            "Iteration 95, loss = 2.20606389\n",
            "Validation score: 0.303419\n",
            "Iteration 96, loss = 2.20527789\n",
            "Validation score: 0.303419\n",
            "Iteration 97, loss = 2.20358942\n",
            "Validation score: 0.299145\n",
            "Iteration 98, loss = 2.20242543\n",
            "Validation score: 0.307692\n",
            "Iteration 99, loss = 2.20183238\n",
            "Validation score: 0.307692\n",
            "Iteration 100, loss = 2.20055648\n",
            "Validation score: 0.307692\n",
            "Iteration 101, loss = 2.19976540\n",
            "Validation score: 0.303419\n",
            "Iteration 102, loss = 2.19861615\n",
            "Validation score: 0.299145\n",
            "Iteration 103, loss = 2.19735578\n",
            "Validation score: 0.290598\n",
            "Iteration 104, loss = 2.19530133\n",
            "Validation score: 0.294872\n",
            "Iteration 105, loss = 2.19463718\n",
            "Validation score: 0.299145\n",
            "Iteration 106, loss = 2.19311487\n",
            "Validation score: 0.299145\n",
            "Iteration 107, loss = 2.19160557\n",
            "Validation score: 0.299145\n",
            "Iteration 108, loss = 2.18906231\n",
            "Validation score: 0.290598\n",
            "Iteration 109, loss = 2.18745193\n",
            "Validation score: 0.290598\n",
            "Iteration 110, loss = 2.18642288\n",
            "Validation score: 0.290598\n",
            "Iteration 111, loss = 2.18448441\n",
            "Validation score: 0.282051\n",
            "Iteration 112, loss = 2.18325037\n",
            "Validation score: 0.286325\n",
            "Iteration 113, loss = 2.18167341\n",
            "Validation score: 0.286325\n",
            "Iteration 114, loss = 2.18089026\n",
            "Validation score: 0.286325\n",
            "Iteration 115, loss = 2.17972333\n",
            "Validation score: 0.290598\n",
            "Iteration 116, loss = 2.17880148\n",
            "Validation score: 0.286325\n",
            "Iteration 117, loss = 2.17840100\n",
            "Validation score: 0.290598\n",
            "Iteration 118, loss = 2.17700842\n",
            "Validation score: 0.286325\n",
            "Iteration 119, loss = 2.17595735\n",
            "Validation score: 0.286325\n",
            "Iteration 120, loss = 2.17461995\n",
            "Validation score: 0.282051\n",
            "Iteration 121, loss = 2.17406745\n",
            "Validation score: 0.277778\n",
            "Iteration 122, loss = 2.17253936\n",
            "Validation score: 0.277778\n",
            "Iteration 123, loss = 2.17183789\n",
            "Validation score: 0.303419\n",
            "Iteration 124, loss = 2.17106394\n",
            "Validation score: 0.316239\n",
            "Iteration 125, loss = 2.16965313\n",
            "Validation score: 0.303419\n",
            "Iteration 126, loss = 2.16901726\n",
            "Validation score: 0.303419\n",
            "Iteration 127, loss = 2.16843178\n",
            "Validation score: 0.299145\n",
            "Iteration 128, loss = 2.16756219\n",
            "Validation score: 0.294872\n",
            "Iteration 129, loss = 2.16640243\n",
            "Validation score: 0.316239\n",
            "Iteration 130, loss = 2.16593699\n",
            "Validation score: 0.294872\n",
            "Iteration 131, loss = 2.16486467\n",
            "Validation score: 0.316239\n",
            "Iteration 132, loss = 2.16392463\n",
            "Validation score: 0.307692\n",
            "Iteration 133, loss = 2.16317120\n",
            "Validation score: 0.303419\n",
            "Iteration 134, loss = 2.16259045\n",
            "Validation score: 0.294872\n",
            "Iteration 135, loss = 2.16162354\n",
            "Validation score: 0.307692\n",
            "Iteration 136, loss = 2.16120733\n",
            "Validation score: 0.307692\n",
            "Iteration 137, loss = 2.16027317\n",
            "Validation score: 0.307692\n",
            "Iteration 138, loss = 2.15946095\n",
            "Validation score: 0.290598\n",
            "Iteration 139, loss = 2.15901553\n",
            "Validation score: 0.320513\n",
            "Iteration 140, loss = 2.15845822\n",
            "Validation score: 0.320513\n",
            "Iteration 141, loss = 2.15671022\n",
            "Validation score: 0.311966\n",
            "Iteration 142, loss = 2.15595528\n",
            "Validation score: 0.299145\n",
            "Iteration 143, loss = 2.15578857\n",
            "Validation score: 0.303419\n",
            "Iteration 144, loss = 2.15526938\n",
            "Validation score: 0.303419\n",
            "Iteration 145, loss = 2.15418833\n",
            "Validation score: 0.311966\n",
            "Iteration 146, loss = 2.15357700\n",
            "Validation score: 0.307692\n",
            "Iteration 147, loss = 2.15234455\n",
            "Validation score: 0.303419\n",
            "Iteration 148, loss = 2.15214412\n",
            "Validation score: 0.307692\n",
            "Iteration 149, loss = 2.15144133\n",
            "Validation score: 0.307692\n",
            "Iteration 150, loss = 2.15040242\n",
            "Validation score: 0.307692\n",
            "Iteration 151, loss = 2.14957640\n",
            "Validation score: 0.307692\n",
            "Iteration 152, loss = 2.14844037\n",
            "Validation score: 0.303419\n",
            "Iteration 153, loss = 2.14791020\n",
            "Validation score: 0.307692\n",
            "Iteration 154, loss = 2.14761401\n",
            "Validation score: 0.316239\n",
            "Iteration 155, loss = 2.14702496\n",
            "Validation score: 0.316239\n",
            "Iteration 156, loss = 2.14620929\n",
            "Validation score: 0.316239\n",
            "Iteration 157, loss = 2.14526484\n",
            "Validation score: 0.311966\n",
            "Iteration 158, loss = 2.14479900\n",
            "Validation score: 0.307692\n",
            "Iteration 159, loss = 2.14436583\n",
            "Validation score: 0.307692\n",
            "Iteration 160, loss = 2.14352162\n",
            "Validation score: 0.311966\n",
            "Iteration 161, loss = 2.14275276\n",
            "Validation score: 0.307692\n",
            "Iteration 162, loss = 2.14193412\n",
            "Validation score: 0.316239\n",
            "Iteration 163, loss = 2.14112122\n",
            "Validation score: 0.307692\n",
            "Iteration 164, loss = 2.14107921\n",
            "Validation score: 0.311966\n",
            "Iteration 165, loss = 2.14058207\n",
            "Validation score: 0.311966\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.15996132\n",
            "Validation score: 0.145299\n",
            "Iteration 2, loss = 2.97754715\n",
            "Validation score: 0.145299\n",
            "Iteration 3, loss = 2.82602494\n",
            "Validation score: 0.145299\n",
            "Iteration 4, loss = 2.71360182\n",
            "Validation score: 0.145299\n",
            "Iteration 5, loss = 2.63893737\n",
            "Validation score: 0.145299\n",
            "Iteration 6, loss = 2.59213395\n",
            "Validation score: 0.141026\n",
            "Iteration 7, loss = 2.56405330\n",
            "Validation score: 0.141026\n",
            "Iteration 8, loss = 2.54688464\n",
            "Validation score: 0.141026\n",
            "Iteration 9, loss = 2.53589510\n",
            "Validation score: 0.141026\n",
            "Iteration 10, loss = 2.52777534\n",
            "Validation score: 0.141026\n",
            "Iteration 11, loss = 2.52047774\n",
            "Validation score: 0.166667\n",
            "Iteration 12, loss = 2.51148158\n",
            "Validation score: 0.175214\n",
            "Iteration 13, loss = 2.50560378\n",
            "Validation score: 0.179487\n",
            "Iteration 14, loss = 2.50082525\n",
            "Validation score: 0.209402\n",
            "Iteration 15, loss = 2.49644682\n",
            "Validation score: 0.213675\n",
            "Iteration 16, loss = 2.49258822\n",
            "Validation score: 0.209402\n",
            "Iteration 17, loss = 2.48833786\n",
            "Validation score: 0.217949\n",
            "Iteration 18, loss = 2.48438254\n",
            "Validation score: 0.213675\n",
            "Iteration 19, loss = 2.47992497\n",
            "Validation score: 0.222222\n",
            "Iteration 20, loss = 2.47621635\n",
            "Validation score: 0.217949\n",
            "Iteration 21, loss = 2.47272161\n",
            "Validation score: 0.222222\n",
            "Iteration 22, loss = 2.46861438\n",
            "Validation score: 0.222222\n",
            "Iteration 23, loss = 2.46494068\n",
            "Validation score: 0.226496\n",
            "Iteration 24, loss = 2.46123385\n",
            "Validation score: 0.222222\n",
            "Iteration 25, loss = 2.45731749\n",
            "Validation score: 0.217949\n",
            "Iteration 26, loss = 2.45341616\n",
            "Validation score: 0.222222\n",
            "Iteration 27, loss = 2.44875153\n",
            "Validation score: 0.217949\n",
            "Iteration 28, loss = 2.44469856\n",
            "Validation score: 0.239316\n",
            "Iteration 29, loss = 2.44026257\n",
            "Validation score: 0.222222\n",
            "Iteration 30, loss = 2.43566308\n",
            "Validation score: 0.213675\n",
            "Iteration 31, loss = 2.43145094\n",
            "Validation score: 0.230769\n",
            "Iteration 32, loss = 2.42647785\n",
            "Validation score: 0.235043\n",
            "Iteration 33, loss = 2.42194458\n",
            "Validation score: 0.217949\n",
            "Iteration 34, loss = 2.41731046\n",
            "Validation score: 0.213675\n",
            "Iteration 35, loss = 2.41190726\n",
            "Validation score: 0.217949\n",
            "Iteration 36, loss = 2.40728083\n",
            "Validation score: 0.243590\n",
            "Iteration 37, loss = 2.40176170\n",
            "Validation score: 0.247863\n",
            "Iteration 38, loss = 2.39652846\n",
            "Validation score: 0.222222\n",
            "Iteration 39, loss = 2.39127892\n",
            "Validation score: 0.247863\n",
            "Iteration 40, loss = 2.38552644\n",
            "Validation score: 0.256410\n",
            "Iteration 41, loss = 2.37986803\n",
            "Validation score: 0.247863\n",
            "Iteration 42, loss = 2.37423101\n",
            "Validation score: 0.264957\n",
            "Iteration 43, loss = 2.36871670\n",
            "Validation score: 0.260684\n",
            "Iteration 44, loss = 2.36265401\n",
            "Validation score: 0.264957\n",
            "Iteration 45, loss = 2.35732504\n",
            "Validation score: 0.264957\n",
            "Iteration 46, loss = 2.35220261\n",
            "Validation score: 0.256410\n",
            "Iteration 47, loss = 2.34693611\n",
            "Validation score: 0.264957\n",
            "Iteration 48, loss = 2.34087307\n",
            "Validation score: 0.260684\n",
            "Iteration 49, loss = 2.33558185\n",
            "Validation score: 0.252137\n",
            "Iteration 50, loss = 2.33062981\n",
            "Validation score: 0.294872\n",
            "Iteration 51, loss = 2.32546021\n",
            "Validation score: 0.303419\n",
            "Iteration 52, loss = 2.32076503\n",
            "Validation score: 0.307692\n",
            "Iteration 53, loss = 2.31546680\n",
            "Validation score: 0.303419\n",
            "Iteration 54, loss = 2.31118033\n",
            "Validation score: 0.299145\n",
            "Iteration 55, loss = 2.30660846\n",
            "Validation score: 0.294872\n",
            "Iteration 56, loss = 2.30163930\n",
            "Validation score: 0.286325\n",
            "Iteration 57, loss = 2.29710338\n",
            "Validation score: 0.303419\n",
            "Iteration 58, loss = 2.29296251\n",
            "Validation score: 0.290598\n",
            "Iteration 59, loss = 2.28865157\n",
            "Validation score: 0.303419\n",
            "Iteration 60, loss = 2.28432845\n",
            "Validation score: 0.294872\n",
            "Iteration 61, loss = 2.28057255\n",
            "Validation score: 0.303419\n",
            "Iteration 62, loss = 2.27643508\n",
            "Validation score: 0.299145\n",
            "Iteration 63, loss = 2.27256067\n",
            "Validation score: 0.290598\n",
            "Iteration 64, loss = 2.26826294\n",
            "Validation score: 0.299145\n",
            "Iteration 65, loss = 2.26464761\n",
            "Validation score: 0.311966\n",
            "Iteration 66, loss = 2.26155317\n",
            "Validation score: 0.299145\n",
            "Iteration 67, loss = 2.25786789\n",
            "Validation score: 0.299145\n",
            "Iteration 68, loss = 2.25471171\n",
            "Validation score: 0.303419\n",
            "Iteration 69, loss = 2.25121468\n",
            "Validation score: 0.303419\n",
            "Iteration 70, loss = 2.24752597\n",
            "Validation score: 0.303419\n",
            "Iteration 71, loss = 2.24480572\n",
            "Validation score: 0.303419\n",
            "Iteration 72, loss = 2.24176113\n",
            "Validation score: 0.307692\n",
            "Iteration 73, loss = 2.23895635\n",
            "Validation score: 0.303419\n",
            "Iteration 74, loss = 2.23642264\n",
            "Validation score: 0.307692\n",
            "Iteration 75, loss = 2.23330471\n",
            "Validation score: 0.294872\n",
            "Iteration 76, loss = 2.23045280\n",
            "Validation score: 0.307692\n",
            "Iteration 77, loss = 2.22803592\n",
            "Validation score: 0.303419\n",
            "Iteration 78, loss = 2.22583412\n",
            "Validation score: 0.307692\n",
            "Iteration 79, loss = 2.22320992\n",
            "Validation score: 0.307692\n",
            "Iteration 80, loss = 2.22127238\n",
            "Validation score: 0.303419\n",
            "Iteration 81, loss = 2.21855260\n",
            "Validation score: 0.303419\n",
            "Iteration 82, loss = 2.21643109\n",
            "Validation score: 0.307692\n",
            "Iteration 83, loss = 2.21479476\n",
            "Validation score: 0.307692\n",
            "Iteration 84, loss = 2.21237797\n",
            "Validation score: 0.311966\n",
            "Iteration 85, loss = 2.21029201\n",
            "Validation score: 0.307692\n",
            "Iteration 86, loss = 2.20812853\n",
            "Validation score: 0.303419\n",
            "Iteration 87, loss = 2.20680159\n",
            "Validation score: 0.303419\n",
            "Iteration 88, loss = 2.20471832\n",
            "Validation score: 0.307692\n",
            "Iteration 89, loss = 2.20292809\n",
            "Validation score: 0.307692\n",
            "Iteration 90, loss = 2.20254228\n",
            "Validation score: 0.303419\n",
            "Iteration 91, loss = 2.19930803\n",
            "Validation score: 0.299145\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.09013900\n",
            "Validation score: 0.149573\n",
            "Iteration 2, loss = 2.91031478\n",
            "Validation score: 0.149573\n",
            "Iteration 3, loss = 2.72899439\n",
            "Validation score: 0.149573\n",
            "Iteration 4, loss = 2.57863378\n",
            "Validation score: 0.149573\n",
            "Iteration 5, loss = 2.46814136\n",
            "Validation score: 0.217949\n",
            "Iteration 6, loss = 2.39052528\n",
            "Validation score: 0.209402\n",
            "Iteration 7, loss = 2.34921182\n",
            "Validation score: 0.209402\n",
            "Iteration 8, loss = 2.31497303\n",
            "Validation score: 0.209402\n",
            "Iteration 9, loss = 2.28940178\n",
            "Validation score: 0.213675\n",
            "Iteration 10, loss = 2.26734709\n",
            "Validation score: 0.205128\n",
            "Iteration 11, loss = 2.24986166\n",
            "Validation score: 0.205128\n",
            "Iteration 12, loss = 2.23257950\n",
            "Validation score: 0.205128\n",
            "Iteration 13, loss = 2.21997916\n",
            "Validation score: 0.217949\n",
            "Iteration 14, loss = 2.20869483\n",
            "Validation score: 0.209402\n",
            "Iteration 15, loss = 2.19910802\n",
            "Validation score: 0.217949\n",
            "Iteration 16, loss = 2.19013530\n",
            "Validation score: 0.217949\n",
            "Iteration 17, loss = 2.18276375\n",
            "Validation score: 0.217949\n",
            "Iteration 18, loss = 2.17578159\n",
            "Validation score: 0.217949\n",
            "Iteration 19, loss = 2.16995628\n",
            "Validation score: 0.230769\n",
            "Iteration 20, loss = 2.16482011\n",
            "Validation score: 0.213675\n",
            "Iteration 21, loss = 2.15976017\n",
            "Validation score: 0.213675\n",
            "Iteration 22, loss = 2.15583780\n",
            "Validation score: 0.222222\n",
            "Iteration 23, loss = 2.15202904\n",
            "Validation score: 0.222222\n",
            "Iteration 24, loss = 2.14823804\n",
            "Validation score: 0.239316\n",
            "Iteration 25, loss = 2.14551600\n",
            "Validation score: 0.222222\n",
            "Iteration 26, loss = 2.14163749\n",
            "Validation score: 0.235043\n",
            "Iteration 27, loss = 2.13871063\n",
            "Validation score: 0.226496\n",
            "Iteration 28, loss = 2.13630739\n",
            "Validation score: 0.226496\n",
            "Iteration 29, loss = 2.13383659\n",
            "Validation score: 0.235043\n",
            "Iteration 30, loss = 2.13232333\n",
            "Validation score: 0.252137\n",
            "Iteration 31, loss = 2.12945096\n",
            "Validation score: 0.239316\n",
            "Iteration 32, loss = 2.12698309\n",
            "Validation score: 0.239316\n",
            "Iteration 33, loss = 2.12583148\n",
            "Validation score: 0.239316\n",
            "Iteration 34, loss = 2.12440392\n",
            "Validation score: 0.230769\n",
            "Iteration 35, loss = 2.12159124\n",
            "Validation score: 0.230769\n",
            "Iteration 36, loss = 2.12050341\n",
            "Validation score: 0.226496\n",
            "Iteration 37, loss = 2.11887953\n",
            "Validation score: 0.239316\n",
            "Iteration 38, loss = 2.11585606\n",
            "Validation score: 0.235043\n",
            "Iteration 39, loss = 2.11443144\n",
            "Validation score: 0.230769\n",
            "Iteration 40, loss = 2.11274913\n",
            "Validation score: 0.235043\n",
            "Iteration 41, loss = 2.11135749\n",
            "Validation score: 0.247863\n",
            "Iteration 42, loss = 2.11090228\n",
            "Validation score: 0.239316\n",
            "Iteration 43, loss = 2.10868799\n",
            "Validation score: 0.230769\n",
            "Iteration 44, loss = 2.10711769\n",
            "Validation score: 0.247863\n",
            "Iteration 45, loss = 2.10545019\n",
            "Validation score: 0.247863\n",
            "Iteration 46, loss = 2.10403829\n",
            "Validation score: 0.235043\n",
            "Iteration 47, loss = 2.10254348\n",
            "Validation score: 0.239316\n",
            "Iteration 48, loss = 2.09998072\n",
            "Validation score: 0.239316\n",
            "Iteration 49, loss = 2.09991375\n",
            "Validation score: 0.247863\n",
            "Iteration 50, loss = 2.09876653\n",
            "Validation score: 0.247863\n",
            "Iteration 51, loss = 2.09675314\n",
            "Validation score: 0.235043\n",
            "Iteration 52, loss = 2.09612182\n",
            "Validation score: 0.247863\n",
            "Iteration 53, loss = 2.09464974\n",
            "Validation score: 0.239316\n",
            "Iteration 54, loss = 2.09371586\n",
            "Validation score: 0.239316\n",
            "Iteration 55, loss = 2.09226681\n",
            "Validation score: 0.239316\n",
            "Iteration 56, loss = 2.09175675\n",
            "Validation score: 0.239316\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.09413894\n",
            "Validation score: 0.115385\n",
            "Iteration 2, loss = 2.92577972\n",
            "Validation score: 0.115385\n",
            "Iteration 3, loss = 2.79063830\n",
            "Validation score: 0.115385\n",
            "Iteration 4, loss = 2.69052785\n",
            "Validation score: 0.115385\n",
            "Iteration 5, loss = 2.62378193\n",
            "Validation score: 0.115385\n",
            "Iteration 6, loss = 2.58230842\n",
            "Validation score: 0.183761\n",
            "Iteration 7, loss = 2.55758018\n",
            "Validation score: 0.179487\n",
            "Iteration 8, loss = 2.54239503\n",
            "Validation score: 0.179487\n",
            "Iteration 9, loss = 2.53285208\n",
            "Validation score: 0.179487\n",
            "Iteration 10, loss = 2.52636105\n",
            "Validation score: 0.179487\n",
            "Iteration 11, loss = 2.52219647\n",
            "Validation score: 0.179487\n",
            "Iteration 12, loss = 2.51911945\n",
            "Validation score: 0.166667\n",
            "Iteration 13, loss = 2.51694697\n",
            "Validation score: 0.179487\n",
            "Iteration 14, loss = 2.51505619\n",
            "Validation score: 0.179487\n",
            "Iteration 15, loss = 2.51393638\n",
            "Validation score: 0.166667\n",
            "Iteration 16, loss = 2.51290226\n",
            "Validation score: 0.166667\n",
            "Iteration 17, loss = 2.51220323\n",
            "Validation score: 0.179487\n",
            "Iteration 18, loss = 2.51153212\n",
            "Validation score: 0.179487\n",
            "Iteration 19, loss = 2.51097619\n",
            "Validation score: 0.166667\n",
            "Iteration 20, loss = 2.51078196\n",
            "Validation score: 0.166667\n",
            "Iteration 21, loss = 2.51041219\n",
            "Validation score: 0.166667\n",
            "Iteration 22, loss = 2.51009665\n",
            "Validation score: 0.166667\n",
            "Iteration 23, loss = 2.50966391\n",
            "Validation score: 0.179487\n",
            "Iteration 24, loss = 2.50950959\n",
            "Validation score: 0.166667\n",
            "Iteration 25, loss = 2.50949255\n",
            "Validation score: 0.166667\n",
            "Iteration 26, loss = 2.50941916\n",
            "Validation score: 0.166667\n",
            "Iteration 27, loss = 2.50915144\n",
            "Validation score: 0.166667\n",
            "Iteration 28, loss = 2.50908813\n",
            "Validation score: 0.166667\n",
            "Iteration 29, loss = 2.50892297\n",
            "Validation score: 0.166667\n",
            "Iteration 30, loss = 2.50894828\n",
            "Validation score: 0.166667\n",
            "Iteration 31, loss = 2.50871565\n",
            "Validation score: 0.166667\n",
            "Iteration 32, loss = 2.50867750\n",
            "Validation score: 0.166667\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.19590678\n",
            "Validation score: 0.162393\n",
            "Iteration 2, loss = 2.84528786\n",
            "Validation score: 0.162393\n",
            "Iteration 3, loss = 2.64308958\n",
            "Validation score: 0.166667\n",
            "Iteration 4, loss = 2.56188561\n",
            "Validation score: 0.170940\n",
            "Iteration 5, loss = 2.52806777\n",
            "Validation score: 0.145299\n",
            "Iteration 6, loss = 2.51033262\n",
            "Validation score: 0.153846\n",
            "Iteration 7, loss = 2.49314718\n",
            "Validation score: 0.141026\n",
            "Iteration 8, loss = 2.47105689\n",
            "Validation score: 0.205128\n",
            "Iteration 9, loss = 2.44335194\n",
            "Validation score: 0.200855\n",
            "Iteration 10, loss = 2.41441643\n",
            "Validation score: 0.213675\n",
            "Iteration 11, loss = 2.38447748\n",
            "Validation score: 0.213675\n",
            "Iteration 12, loss = 2.35789509\n",
            "Validation score: 0.209402\n",
            "Iteration 13, loss = 2.33379332\n",
            "Validation score: 0.205128\n",
            "Iteration 14, loss = 2.31234180\n",
            "Validation score: 0.209402\n",
            "Iteration 15, loss = 2.29381535\n",
            "Validation score: 0.196581\n",
            "Iteration 16, loss = 2.27782493\n",
            "Validation score: 0.205128\n",
            "Iteration 17, loss = 2.26191873\n",
            "Validation score: 0.209402\n",
            "Iteration 18, loss = 2.24984808\n",
            "Validation score: 0.213675\n",
            "Iteration 19, loss = 2.23802293\n",
            "Validation score: 0.209402\n",
            "Iteration 20, loss = 2.22748919\n",
            "Validation score: 0.222222\n",
            "Iteration 21, loss = 2.21775780\n",
            "Validation score: 0.217949\n",
            "Iteration 22, loss = 2.20883600\n",
            "Validation score: 0.209402\n",
            "Iteration 23, loss = 2.20050792\n",
            "Validation score: 0.217949\n",
            "Iteration 24, loss = 2.19349546\n",
            "Validation score: 0.213675\n",
            "Iteration 25, loss = 2.18676900\n",
            "Validation score: 0.209402\n",
            "Iteration 26, loss = 2.17965185\n",
            "Validation score: 0.222222\n",
            "Iteration 27, loss = 2.17431556\n",
            "Validation score: 0.213675\n",
            "Iteration 28, loss = 2.16851357\n",
            "Validation score: 0.235043\n",
            "Iteration 29, loss = 2.16321343\n",
            "Validation score: 0.226496\n",
            "Iteration 30, loss = 2.15849217\n",
            "Validation score: 0.205128\n",
            "Iteration 31, loss = 2.15310582\n",
            "Validation score: 0.230769\n",
            "Iteration 32, loss = 2.15038081\n",
            "Validation score: 0.226496\n",
            "Iteration 33, loss = 2.14598699\n",
            "Validation score: 0.226496\n",
            "Iteration 34, loss = 2.14109446\n",
            "Validation score: 0.222222\n",
            "Iteration 35, loss = 2.13716030\n",
            "Validation score: 0.226496\n",
            "Iteration 36, loss = 2.13426815\n",
            "Validation score: 0.226496\n",
            "Iteration 37, loss = 2.13073022\n",
            "Validation score: 0.239316\n",
            "Iteration 38, loss = 2.12747479\n",
            "Validation score: 0.235043\n",
            "Iteration 39, loss = 2.12492900\n",
            "Validation score: 0.230769\n",
            "Iteration 40, loss = 2.12171895\n",
            "Validation score: 0.243590\n",
            "Iteration 41, loss = 2.11979894\n",
            "Validation score: 0.226496\n",
            "Iteration 42, loss = 2.11627765\n",
            "Validation score: 0.239316\n",
            "Iteration 43, loss = 2.11386780\n",
            "Validation score: 0.235043\n",
            "Iteration 44, loss = 2.11160986\n",
            "Validation score: 0.226496\n",
            "Iteration 45, loss = 2.10920911\n",
            "Validation score: 0.226496\n",
            "Iteration 46, loss = 2.10690098\n",
            "Validation score: 0.217949\n",
            "Iteration 47, loss = 2.10362298\n",
            "Validation score: 0.239316\n",
            "Iteration 48, loss = 2.10227792\n",
            "Validation score: 0.235043\n",
            "Iteration 49, loss = 2.09987313\n",
            "Validation score: 0.239316\n",
            "Iteration 50, loss = 2.09748328\n",
            "Validation score: 0.235043\n",
            "Iteration 51, loss = 2.09629635\n",
            "Validation score: 0.235043\n",
            "Iteration 52, loss = 2.09445873\n",
            "Validation score: 0.230769\n",
            "Iteration 53, loss = 2.09218739\n",
            "Validation score: 0.209402\n",
            "Iteration 54, loss = 2.09070975\n",
            "Validation score: 0.239316\n",
            "Iteration 55, loss = 2.08850962\n",
            "Validation score: 0.230769\n",
            "Iteration 56, loss = 2.08587566\n",
            "Validation score: 0.205128\n",
            "Iteration 57, loss = 2.08409164\n",
            "Validation score: 0.243590\n",
            "Iteration 58, loss = 2.08314995\n",
            "Validation score: 0.235043\n",
            "Iteration 59, loss = 2.08141486\n",
            "Validation score: 0.239316\n",
            "Iteration 60, loss = 2.07889034\n",
            "Validation score: 0.243590\n",
            "Iteration 61, loss = 2.07682437\n",
            "Validation score: 0.230769\n",
            "Iteration 62, loss = 2.07631585\n",
            "Validation score: 0.230769\n",
            "Iteration 63, loss = 2.07390449\n",
            "Validation score: 0.226496\n",
            "Iteration 64, loss = 2.07232297\n",
            "Validation score: 0.247863\n",
            "Iteration 65, loss = 2.07105611\n",
            "Validation score: 0.235043\n",
            "Iteration 66, loss = 2.06998844\n",
            "Validation score: 0.247863\n",
            "Iteration 67, loss = 2.06859824\n",
            "Validation score: 0.239316\n",
            "Iteration 68, loss = 2.06654828\n",
            "Validation score: 0.230769\n",
            "Iteration 69, loss = 2.06432679\n",
            "Validation score: 0.239316\n",
            "Iteration 70, loss = 2.06300308\n",
            "Validation score: 0.230769\n",
            "Iteration 71, loss = 2.06277125\n",
            "Validation score: 0.247863\n",
            "Iteration 72, loss = 2.06189705\n",
            "Validation score: 0.239316\n",
            "Iteration 73, loss = 2.05886532\n",
            "Validation score: 0.235043\n",
            "Iteration 74, loss = 2.05686096\n",
            "Validation score: 0.239316\n",
            "Iteration 75, loss = 2.05554017\n",
            "Validation score: 0.222222\n",
            "Iteration 76, loss = 2.05363893\n",
            "Validation score: 0.239316\n",
            "Iteration 77, loss = 2.05340680\n",
            "Validation score: 0.230769\n",
            "Iteration 78, loss = 2.05102220\n",
            "Validation score: 0.235043\n",
            "Iteration 79, loss = 2.04995360\n",
            "Validation score: 0.260684\n",
            "Iteration 80, loss = 2.04860525\n",
            "Validation score: 0.239316\n",
            "Iteration 81, loss = 2.04691908\n",
            "Validation score: 0.260684\n",
            "Iteration 82, loss = 2.04567108\n",
            "Validation score: 0.247863\n",
            "Iteration 83, loss = 2.04389202\n",
            "Validation score: 0.256410\n",
            "Iteration 84, loss = 2.04331147\n",
            "Validation score: 0.247863\n",
            "Iteration 85, loss = 2.04179197\n",
            "Validation score: 0.252137\n",
            "Iteration 86, loss = 2.04142147\n",
            "Validation score: 0.252137\n",
            "Iteration 87, loss = 2.03898063\n",
            "Validation score: 0.264957\n",
            "Iteration 88, loss = 2.03720084\n",
            "Validation score: 0.252137\n",
            "Iteration 89, loss = 2.03621995\n",
            "Validation score: 0.243590\n",
            "Iteration 90, loss = 2.03432361\n",
            "Validation score: 0.256410\n",
            "Iteration 91, loss = 2.03204521\n",
            "Validation score: 0.243590\n",
            "Iteration 92, loss = 2.03238208\n",
            "Validation score: 0.247863\n",
            "Iteration 93, loss = 2.03041716\n",
            "Validation score: 0.235043\n",
            "Iteration 94, loss = 2.03020082\n",
            "Validation score: 0.256410\n",
            "Iteration 95, loss = 2.02804570\n",
            "Validation score: 0.243590\n",
            "Iteration 96, loss = 2.02643280\n",
            "Validation score: 0.239316\n",
            "Iteration 97, loss = 2.02559258\n",
            "Validation score: 0.235043\n",
            "Iteration 98, loss = 2.02479935\n",
            "Validation score: 0.260684\n",
            "Iteration 99, loss = 2.02393826\n",
            "Validation score: 0.252137\n",
            "Iteration 100, loss = 2.02147808\n",
            "Validation score: 0.243590\n",
            "Iteration 101, loss = 2.02140704\n",
            "Validation score: 0.243590\n",
            "Iteration 102, loss = 2.01948901\n",
            "Validation score: 0.273504\n",
            "Iteration 103, loss = 2.01911408\n",
            "Validation score: 0.256410\n",
            "Iteration 104, loss = 2.01869204\n",
            "Validation score: 0.247863\n",
            "Iteration 105, loss = 2.01662427\n",
            "Validation score: 0.260684\n",
            "Iteration 106, loss = 2.01455131\n",
            "Validation score: 0.264957\n",
            "Iteration 107, loss = 2.01489369\n",
            "Validation score: 0.230769\n",
            "Iteration 108, loss = 2.01359655\n",
            "Validation score: 0.273504\n",
            "Iteration 109, loss = 2.01321838\n",
            "Validation score: 0.269231\n",
            "Iteration 110, loss = 2.01056464\n",
            "Validation score: 0.243590\n",
            "Iteration 111, loss = 2.01066925\n",
            "Validation score: 0.239316\n",
            "Iteration 112, loss = 2.00938982\n",
            "Validation score: 0.277778\n",
            "Iteration 113, loss = 2.00824795\n",
            "Validation score: 0.264957\n",
            "Iteration 114, loss = 2.00798951\n",
            "Validation score: 0.269231\n",
            "Iteration 115, loss = 2.00693311\n",
            "Validation score: 0.260684\n",
            "Iteration 116, loss = 2.00622369\n",
            "Validation score: 0.247863\n",
            "Iteration 117, loss = 2.00539585\n",
            "Validation score: 0.269231\n",
            "Iteration 118, loss = 2.00325461\n",
            "Validation score: 0.264957\n",
            "Iteration 119, loss = 2.00229087\n",
            "Validation score: 0.277778\n",
            "Iteration 120, loss = 2.00119235\n",
            "Validation score: 0.264957\n",
            "Iteration 121, loss = 2.00126253\n",
            "Validation score: 0.269231\n",
            "Iteration 122, loss = 2.00042571\n",
            "Validation score: 0.264957\n",
            "Iteration 123, loss = 1.99842367\n",
            "Validation score: 0.264957\n",
            "Iteration 124, loss = 1.99775646\n",
            "Validation score: 0.252137\n",
            "Iteration 125, loss = 1.99724474\n",
            "Validation score: 0.273504\n",
            "Iteration 126, loss = 1.99648977\n",
            "Validation score: 0.269231\n",
            "Iteration 127, loss = 1.99609806\n",
            "Validation score: 0.264957\n",
            "Iteration 128, loss = 1.99483297\n",
            "Validation score: 0.269231\n",
            "Iteration 129, loss = 1.99367542\n",
            "Validation score: 0.269231\n",
            "Iteration 130, loss = 1.99260804\n",
            "Validation score: 0.247863\n",
            "Iteration 131, loss = 1.99168641\n",
            "Validation score: 0.260684\n",
            "Iteration 132, loss = 1.99196346\n",
            "Validation score: 0.264957\n",
            "Iteration 133, loss = 1.99084316\n",
            "Validation score: 0.256410\n",
            "Iteration 134, loss = 1.98969097\n",
            "Validation score: 0.252137\n",
            "Iteration 135, loss = 1.98911456\n",
            "Validation score: 0.269231\n",
            "Iteration 136, loss = 1.98933976\n",
            "Validation score: 0.260684\n",
            "Iteration 137, loss = 1.98859552\n",
            "Validation score: 0.256410\n",
            "Iteration 138, loss = 1.98702090\n",
            "Validation score: 0.252137\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.12720833\n",
            "Validation score: 0.170940\n",
            "Iteration 2, loss = 2.89591796\n",
            "Validation score: 0.170940\n",
            "Iteration 3, loss = 2.61065279\n",
            "Validation score: 0.170940\n",
            "Iteration 4, loss = 2.51690379\n",
            "Validation score: 0.179487\n",
            "Iteration 5, loss = 2.49270352\n",
            "Validation score: 0.175214\n",
            "Iteration 6, loss = 2.47920005\n",
            "Validation score: 0.183761\n",
            "Iteration 7, loss = 2.46832635\n",
            "Validation score: 0.188034\n",
            "Iteration 8, loss = 2.45649444\n",
            "Validation score: 0.188034\n",
            "Iteration 9, loss = 2.44492407\n",
            "Validation score: 0.188034\n",
            "Iteration 10, loss = 2.43337262\n",
            "Validation score: 0.183761\n",
            "Iteration 11, loss = 2.42262975\n",
            "Validation score: 0.192308\n",
            "Iteration 12, loss = 2.41136245\n",
            "Validation score: 0.192308\n",
            "Iteration 13, loss = 2.40101524\n",
            "Validation score: 0.209402\n",
            "Iteration 14, loss = 2.38968462\n",
            "Validation score: 0.213675\n",
            "Iteration 15, loss = 2.37805865\n",
            "Validation score: 0.213675\n",
            "Iteration 16, loss = 2.36666598\n",
            "Validation score: 0.226496\n",
            "Iteration 17, loss = 2.35577702\n",
            "Validation score: 0.243590\n",
            "Iteration 18, loss = 2.34533973\n",
            "Validation score: 0.264957\n",
            "Iteration 19, loss = 2.33431979\n",
            "Validation score: 0.260684\n",
            "Iteration 20, loss = 2.32457852\n",
            "Validation score: 0.247863\n",
            "Iteration 21, loss = 2.31509809\n",
            "Validation score: 0.260684\n",
            "Iteration 22, loss = 2.30632004\n",
            "Validation score: 0.260684\n",
            "Iteration 23, loss = 2.29714431\n",
            "Validation score: 0.264957\n",
            "Iteration 24, loss = 2.28944321\n",
            "Validation score: 0.269231\n",
            "Iteration 25, loss = 2.28187099\n",
            "Validation score: 0.286325\n",
            "Iteration 26, loss = 2.27469554\n",
            "Validation score: 0.294872\n",
            "Iteration 27, loss = 2.26837342\n",
            "Validation score: 0.282051\n",
            "Iteration 28, loss = 2.26150032\n",
            "Validation score: 0.290598\n",
            "Iteration 29, loss = 2.25559515\n",
            "Validation score: 0.290598\n",
            "Iteration 30, loss = 2.25024204\n",
            "Validation score: 0.294872\n",
            "Iteration 31, loss = 2.24539754\n",
            "Validation score: 0.290598\n",
            "Iteration 32, loss = 2.24001899\n",
            "Validation score: 0.290598\n",
            "Iteration 33, loss = 2.23557583\n",
            "Validation score: 0.290598\n",
            "Iteration 34, loss = 2.23149302\n",
            "Validation score: 0.286325\n",
            "Iteration 35, loss = 2.22697825\n",
            "Validation score: 0.290598\n",
            "Iteration 36, loss = 2.22350227\n",
            "Validation score: 0.282051\n",
            "Iteration 37, loss = 2.21908487\n",
            "Validation score: 0.282051\n",
            "Iteration 38, loss = 2.21640875\n",
            "Validation score: 0.282051\n",
            "Iteration 39, loss = 2.21171735\n",
            "Validation score: 0.286325\n",
            "Iteration 40, loss = 2.20891368\n",
            "Validation score: 0.290598\n",
            "Iteration 41, loss = 2.20566944\n",
            "Validation score: 0.277778\n",
            "Iteration 42, loss = 2.20276239\n",
            "Validation score: 0.303419\n",
            "Iteration 43, loss = 2.19967521\n",
            "Validation score: 0.286325\n",
            "Iteration 44, loss = 2.19694703\n",
            "Validation score: 0.282051\n",
            "Iteration 45, loss = 2.19446673\n",
            "Validation score: 0.282051\n",
            "Iteration 46, loss = 2.19195652\n",
            "Validation score: 0.273504\n",
            "Iteration 47, loss = 2.18998623\n",
            "Validation score: 0.286325\n",
            "Iteration 48, loss = 2.18553726\n",
            "Validation score: 0.282051\n",
            "Iteration 49, loss = 2.18482395\n",
            "Validation score: 0.282051\n",
            "Iteration 50, loss = 2.18276038\n",
            "Validation score: 0.282051\n",
            "Iteration 51, loss = 2.18021864\n",
            "Validation score: 0.282051\n",
            "Iteration 52, loss = 2.17728241\n",
            "Validation score: 0.277778\n",
            "Iteration 53, loss = 2.17475585\n",
            "Validation score: 0.282051\n",
            "Iteration 54, loss = 2.17398073\n",
            "Validation score: 0.294872\n",
            "Iteration 55, loss = 2.17082874\n",
            "Validation score: 0.277778\n",
            "Iteration 56, loss = 2.16898549\n",
            "Validation score: 0.273504\n",
            "Iteration 57, loss = 2.16746368\n",
            "Validation score: 0.282051\n",
            "Iteration 58, loss = 2.16548623\n",
            "Validation score: 0.277778\n",
            "Iteration 59, loss = 2.16235224\n",
            "Validation score: 0.290598\n",
            "Iteration 60, loss = 2.16108474\n",
            "Validation score: 0.294872\n",
            "Iteration 61, loss = 2.16002284\n",
            "Validation score: 0.273504\n",
            "Iteration 62, loss = 2.15793746\n",
            "Validation score: 0.282051\n",
            "Iteration 63, loss = 2.15539309\n",
            "Validation score: 0.282051\n",
            "Iteration 64, loss = 2.15251069\n",
            "Validation score: 0.286325\n",
            "Iteration 65, loss = 2.15208098\n",
            "Validation score: 0.277778\n",
            "Iteration 66, loss = 2.14950937\n",
            "Validation score: 0.294872\n",
            "Iteration 67, loss = 2.14855533\n",
            "Validation score: 0.303419\n",
            "Iteration 68, loss = 2.14533330\n",
            "Validation score: 0.286325\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.17570223\n",
            "Validation score: 0.094017\n",
            "Iteration 2, loss = 2.97844715\n",
            "Validation score: 0.166667\n",
            "Iteration 3, loss = 2.77426081\n",
            "Validation score: 0.166667\n",
            "Iteration 4, loss = 2.65150242\n",
            "Validation score: 0.183761\n",
            "Iteration 5, loss = 2.58556355\n",
            "Validation score: 0.183761\n",
            "Iteration 6, loss = 2.55317508\n",
            "Validation score: 0.188034\n",
            "Iteration 7, loss = 2.53577738\n",
            "Validation score: 0.170940\n",
            "Iteration 8, loss = 2.52629964\n",
            "Validation score: 0.170940\n",
            "Iteration 9, loss = 2.51940656\n",
            "Validation score: 0.170940\n",
            "Iteration 10, loss = 2.51409000\n",
            "Validation score: 0.179487\n",
            "Iteration 11, loss = 2.50845506\n",
            "Validation score: 0.188034\n",
            "Iteration 12, loss = 2.50338094\n",
            "Validation score: 0.175214\n",
            "Iteration 13, loss = 2.49809659\n",
            "Validation score: 0.179487\n",
            "Iteration 14, loss = 2.49251477\n",
            "Validation score: 0.179487\n",
            "Iteration 15, loss = 2.48693543\n",
            "Validation score: 0.175214\n",
            "Iteration 16, loss = 2.48065469\n",
            "Validation score: 0.192308\n",
            "Iteration 17, loss = 2.47395234\n",
            "Validation score: 0.179487\n",
            "Iteration 18, loss = 2.46698727\n",
            "Validation score: 0.188034\n",
            "Iteration 19, loss = 2.45974623\n",
            "Validation score: 0.183761\n",
            "Iteration 20, loss = 2.45287065\n",
            "Validation score: 0.200855\n",
            "Iteration 21, loss = 2.44625104\n",
            "Validation score: 0.188034\n",
            "Iteration 22, loss = 2.43946537\n",
            "Validation score: 0.183761\n",
            "Iteration 23, loss = 2.43376769\n",
            "Validation score: 0.209402\n",
            "Iteration 24, loss = 2.42704696\n",
            "Validation score: 0.183761\n",
            "Iteration 25, loss = 2.42113762\n",
            "Validation score: 0.188034\n",
            "Iteration 26, loss = 2.41530989\n",
            "Validation score: 0.188034\n",
            "Iteration 27, loss = 2.40670479\n",
            "Validation score: 0.192308\n",
            "Iteration 28, loss = 2.39798483\n",
            "Validation score: 0.213675\n",
            "Iteration 29, loss = 2.39146127\n",
            "Validation score: 0.205128\n",
            "Iteration 30, loss = 2.38518966\n",
            "Validation score: 0.222222\n",
            "Iteration 31, loss = 2.38058423\n",
            "Validation score: 0.226496\n",
            "Iteration 32, loss = 2.37357278\n",
            "Validation score: 0.205128\n",
            "Iteration 33, loss = 2.36861890\n",
            "Validation score: 0.166667\n",
            "Iteration 34, loss = 2.36320173\n",
            "Validation score: 0.222222\n",
            "Iteration 35, loss = 2.35887123\n",
            "Validation score: 0.205128\n",
            "Iteration 36, loss = 2.35422646\n",
            "Validation score: 0.213675\n",
            "Iteration 37, loss = 2.34885880\n",
            "Validation score: 0.200855\n",
            "Iteration 38, loss = 2.34514820\n",
            "Validation score: 0.209402\n",
            "Iteration 39, loss = 2.34074667\n",
            "Validation score: 0.213675\n",
            "Iteration 40, loss = 2.33606757\n",
            "Validation score: 0.192308\n",
            "Iteration 41, loss = 2.33241980\n",
            "Validation score: 0.209402\n",
            "Iteration 42, loss = 2.32885177\n",
            "Validation score: 0.209402\n",
            "Iteration 43, loss = 2.32496223\n",
            "Validation score: 0.213675\n",
            "Iteration 44, loss = 2.32165271\n",
            "Validation score: 0.213675\n",
            "Iteration 45, loss = 2.31824146\n",
            "Validation score: 0.213675\n",
            "Iteration 46, loss = 2.31483288\n",
            "Validation score: 0.192308\n",
            "Iteration 47, loss = 2.31156729\n",
            "Validation score: 0.213675\n",
            "Iteration 48, loss = 2.30884826\n",
            "Validation score: 0.209402\n",
            "Iteration 49, loss = 2.30641422\n",
            "Validation score: 0.217949\n",
            "Iteration 50, loss = 2.30323262\n",
            "Validation score: 0.217949\n",
            "Iteration 51, loss = 2.30059811\n",
            "Validation score: 0.205128\n",
            "Iteration 52, loss = 2.29800436\n",
            "Validation score: 0.209402\n",
            "Iteration 53, loss = 2.29564643\n",
            "Validation score: 0.209402\n",
            "Iteration 54, loss = 2.29308091\n",
            "Validation score: 0.213675\n",
            "Iteration 55, loss = 2.29114840\n",
            "Validation score: 0.226496\n",
            "Iteration 56, loss = 2.28852569\n",
            "Validation score: 0.213675\n",
            "Iteration 57, loss = 2.28665450\n",
            "Validation score: 0.217949\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.10582441\n",
            "Validation score: 0.132479\n",
            "Iteration 2, loss = 2.81859391\n",
            "Validation score: 0.128205\n",
            "Iteration 3, loss = 2.61966683\n",
            "Validation score: 0.128205\n",
            "Iteration 4, loss = 2.53894624\n",
            "Validation score: 0.162393\n",
            "Iteration 5, loss = 2.50808868\n",
            "Validation score: 0.162393\n",
            "Iteration 6, loss = 2.48940903\n",
            "Validation score: 0.153846\n",
            "Iteration 7, loss = 2.47109352\n",
            "Validation score: 0.166667\n",
            "Iteration 8, loss = 2.44865923\n",
            "Validation score: 0.175214\n",
            "Iteration 9, loss = 2.42272856\n",
            "Validation score: 0.213675\n",
            "Iteration 10, loss = 2.39305655\n",
            "Validation score: 0.239316\n",
            "Iteration 11, loss = 2.36066632\n",
            "Validation score: 0.235043\n",
            "Iteration 12, loss = 2.32789205\n",
            "Validation score: 0.235043\n",
            "Iteration 13, loss = 2.29895366\n",
            "Validation score: 0.235043\n",
            "Iteration 14, loss = 2.27337302\n",
            "Validation score: 0.235043\n",
            "Iteration 15, loss = 2.25210882\n",
            "Validation score: 0.226496\n",
            "Iteration 16, loss = 2.23397747\n",
            "Validation score: 0.230769\n",
            "Iteration 17, loss = 2.21822445\n",
            "Validation score: 0.226496\n",
            "Iteration 18, loss = 2.20460385\n",
            "Validation score: 0.235043\n",
            "Iteration 19, loss = 2.19300546\n",
            "Validation score: 0.230769\n",
            "Iteration 20, loss = 2.18237407\n",
            "Validation score: 0.235043\n",
            "Iteration 21, loss = 2.17444917\n",
            "Validation score: 0.235043\n",
            "Iteration 22, loss = 2.16613979\n",
            "Validation score: 0.239316\n",
            "Iteration 23, loss = 2.15879988\n",
            "Validation score: 0.230769\n",
            "Iteration 24, loss = 2.15363350\n",
            "Validation score: 0.235043\n",
            "Iteration 25, loss = 2.14766890\n",
            "Validation score: 0.243590\n",
            "Iteration 26, loss = 2.14254047\n",
            "Validation score: 0.235043\n",
            "Iteration 27, loss = 2.13854473\n",
            "Validation score: 0.239316\n",
            "Iteration 28, loss = 2.13426022\n",
            "Validation score: 0.230769\n",
            "Iteration 29, loss = 2.13054464\n",
            "Validation score: 0.230769\n",
            "Iteration 30, loss = 2.12580452\n",
            "Validation score: 0.243590\n",
            "Iteration 31, loss = 2.12425738\n",
            "Validation score: 0.243590\n",
            "Iteration 32, loss = 2.12004710\n",
            "Validation score: 0.243590\n",
            "Iteration 33, loss = 2.11646598\n",
            "Validation score: 0.230769\n",
            "Iteration 34, loss = 2.11381819\n",
            "Validation score: 0.247863\n",
            "Iteration 35, loss = 2.11129535\n",
            "Validation score: 0.243590\n",
            "Iteration 36, loss = 2.10859371\n",
            "Validation score: 0.239316\n",
            "Iteration 37, loss = 2.10624776\n",
            "Validation score: 0.247863\n",
            "Iteration 38, loss = 2.10322441\n",
            "Validation score: 0.243590\n",
            "Iteration 39, loss = 2.10165020\n",
            "Validation score: 0.247863\n",
            "Iteration 40, loss = 2.09814060\n",
            "Validation score: 0.252137\n",
            "Iteration 41, loss = 2.09705179\n",
            "Validation score: 0.256410\n",
            "Iteration 42, loss = 2.09444501\n",
            "Validation score: 0.260684\n",
            "Iteration 43, loss = 2.09220381\n",
            "Validation score: 0.252137\n",
            "Iteration 44, loss = 2.09074402\n",
            "Validation score: 0.260684\n",
            "Iteration 45, loss = 2.08772444\n",
            "Validation score: 0.252137\n",
            "Iteration 46, loss = 2.08638190\n",
            "Validation score: 0.247863\n",
            "Iteration 47, loss = 2.08524549\n",
            "Validation score: 0.252137\n",
            "Iteration 48, loss = 2.08204265\n",
            "Validation score: 0.256410\n",
            "Iteration 49, loss = 2.08031093\n",
            "Validation score: 0.252137\n",
            "Iteration 50, loss = 2.07958290\n",
            "Validation score: 0.247863\n",
            "Iteration 51, loss = 2.07674871\n",
            "Validation score: 0.247863\n",
            "Iteration 52, loss = 2.07519359\n",
            "Validation score: 0.252137\n",
            "Iteration 53, loss = 2.07229672\n",
            "Validation score: 0.256410\n",
            "Iteration 54, loss = 2.07038465\n",
            "Validation score: 0.239316\n",
            "Iteration 55, loss = 2.06921358\n",
            "Validation score: 0.256410\n",
            "Iteration 56, loss = 2.06576455\n",
            "Validation score: 0.260684\n",
            "Iteration 57, loss = 2.06478750\n",
            "Validation score: 0.252137\n",
            "Iteration 58, loss = 2.06188656\n",
            "Validation score: 0.256410\n",
            "Iteration 59, loss = 2.06109274\n",
            "Validation score: 0.252137\n",
            "Iteration 60, loss = 2.05837153\n",
            "Validation score: 0.260684\n",
            "Iteration 61, loss = 2.05610684\n",
            "Validation score: 0.247863\n",
            "Iteration 62, loss = 2.05402479\n",
            "Validation score: 0.260684\n",
            "Iteration 63, loss = 2.05179281\n",
            "Validation score: 0.256410\n",
            "Iteration 64, loss = 2.04992668\n",
            "Validation score: 0.252137\n",
            "Iteration 65, loss = 2.04758309\n",
            "Validation score: 0.252137\n",
            "Iteration 66, loss = 2.04467005\n",
            "Validation score: 0.260684\n",
            "Iteration 67, loss = 2.04240122\n",
            "Validation score: 0.252137\n",
            "Iteration 68, loss = 2.03971720\n",
            "Validation score: 0.269231\n",
            "Iteration 69, loss = 2.03680264\n",
            "Validation score: 0.256410\n",
            "Iteration 70, loss = 2.03572923\n",
            "Validation score: 0.260684\n",
            "Iteration 71, loss = 2.03280618\n",
            "Validation score: 0.277778\n",
            "Iteration 72, loss = 2.03134200\n",
            "Validation score: 0.252137\n",
            "Iteration 73, loss = 2.02868097\n",
            "Validation score: 0.273504\n",
            "Iteration 74, loss = 2.02677263\n",
            "Validation score: 0.256410\n",
            "Iteration 75, loss = 2.02511115\n",
            "Validation score: 0.247863\n",
            "Iteration 76, loss = 2.02341566\n",
            "Validation score: 0.273504\n",
            "Iteration 77, loss = 2.02150377\n",
            "Validation score: 0.264957\n",
            "Iteration 78, loss = 2.01865130\n",
            "Validation score: 0.256410\n",
            "Iteration 79, loss = 2.01727081\n",
            "Validation score: 0.260684\n",
            "Iteration 80, loss = 2.01564142\n",
            "Validation score: 0.252137\n",
            "Iteration 81, loss = 2.01400490\n",
            "Validation score: 0.260684\n",
            "Iteration 82, loss = 2.01194862\n",
            "Validation score: 0.260684\n",
            "Iteration 83, loss = 2.01129590\n",
            "Validation score: 0.247863\n",
            "Iteration 84, loss = 2.00951653\n",
            "Validation score: 0.252137\n",
            "Iteration 85, loss = 2.00765000\n",
            "Validation score: 0.252137\n",
            "Iteration 86, loss = 2.00578328\n",
            "Validation score: 0.252137\n",
            "Iteration 87, loss = 2.00516185\n",
            "Validation score: 0.256410\n",
            "Iteration 88, loss = 2.00496015\n",
            "Validation score: 0.260684\n",
            "Iteration 89, loss = 2.00260805\n",
            "Validation score: 0.260684\n",
            "Iteration 90, loss = 2.00141023\n",
            "Validation score: 0.252137\n",
            "Iteration 91, loss = 1.99925837\n",
            "Validation score: 0.256410\n",
            "Iteration 92, loss = 1.99901182\n",
            "Validation score: 0.247863\n",
            "Iteration 93, loss = 1.99677436\n",
            "Validation score: 0.260684\n",
            "Iteration 94, loss = 1.99633267\n",
            "Validation score: 0.256410\n",
            "Iteration 95, loss = 1.99675943\n",
            "Validation score: 0.256410\n",
            "Iteration 96, loss = 1.99408845\n",
            "Validation score: 0.247863\n",
            "Iteration 97, loss = 1.99317480\n",
            "Validation score: 0.243590\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.22516564\n",
            "Validation score: 0.072650\n",
            "Iteration 2, loss = 3.13161617\n",
            "Validation score: 0.162393\n",
            "Iteration 3, loss = 3.04895083\n",
            "Validation score: 0.162393\n",
            "Iteration 4, loss = 2.97629482\n",
            "Validation score: 0.162393\n",
            "Iteration 5, loss = 2.86794825\n",
            "Validation score: 0.162393\n",
            "Iteration 6, loss = 2.58803116\n",
            "Validation score: 0.111111\n",
            "Iteration 7, loss = 2.52671190\n",
            "Validation score: 0.111111\n",
            "Iteration 8, loss = 2.51431029\n",
            "Validation score: 0.111111\n",
            "Iteration 9, loss = 2.50842488\n",
            "Validation score: 0.111111\n",
            "Iteration 10, loss = 2.50259645\n",
            "Validation score: 0.111111\n",
            "Iteration 11, loss = 2.49704581\n",
            "Validation score: 0.111111\n",
            "Iteration 12, loss = 2.49183343\n",
            "Validation score: 0.119658\n",
            "Iteration 13, loss = 2.48638103\n",
            "Validation score: 0.119658\n",
            "Iteration 14, loss = 2.48080129\n",
            "Validation score: 0.123932\n",
            "Iteration 15, loss = 2.47529956\n",
            "Validation score: 0.132479\n",
            "Iteration 16, loss = 2.46933587\n",
            "Validation score: 0.123932\n",
            "Iteration 17, loss = 2.46358160\n",
            "Validation score: 0.123932\n",
            "Iteration 18, loss = 2.45785212\n",
            "Validation score: 0.145299\n",
            "Iteration 19, loss = 2.45280486\n",
            "Validation score: 0.132479\n",
            "Iteration 20, loss = 2.44761213\n",
            "Validation score: 0.145299\n",
            "Iteration 21, loss = 2.44289823\n",
            "Validation score: 0.145299\n",
            "Iteration 22, loss = 2.43802934\n",
            "Validation score: 0.132479\n",
            "Iteration 23, loss = 2.43355832\n",
            "Validation score: 0.145299\n",
            "Iteration 24, loss = 2.42898092\n",
            "Validation score: 0.145299\n",
            "Iteration 25, loss = 2.42439865\n",
            "Validation score: 0.145299\n",
            "Iteration 26, loss = 2.41972951\n",
            "Validation score: 0.145299\n",
            "Iteration 27, loss = 2.41633398\n",
            "Validation score: 0.145299\n",
            "Iteration 28, loss = 2.41128795\n",
            "Validation score: 0.153846\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.10857544\n",
            "Validation score: 0.166667\n",
            "Iteration 2, loss = 2.86320491\n",
            "Validation score: 0.166667\n",
            "Iteration 3, loss = 2.68655390\n",
            "Validation score: 0.166667\n",
            "Iteration 4, loss = 2.60411447\n",
            "Validation score: 0.162393\n",
            "Iteration 5, loss = 2.56427808\n",
            "Validation score: 0.170940\n",
            "Iteration 6, loss = 2.54422059\n",
            "Validation score: 0.175214\n",
            "Iteration 7, loss = 2.53321630\n",
            "Validation score: 0.162393\n",
            "Iteration 8, loss = 2.52684310\n",
            "Validation score: 0.166667\n",
            "Iteration 9, loss = 2.52271852\n",
            "Validation score: 0.166667\n",
            "Iteration 10, loss = 2.51968090\n",
            "Validation score: 0.166667\n",
            "Iteration 11, loss = 2.51770811\n",
            "Validation score: 0.162393\n",
            "Iteration 12, loss = 2.51573479\n",
            "Validation score: 0.175214\n",
            "Iteration 13, loss = 2.51473807\n",
            "Validation score: 0.162393\n",
            "Iteration 14, loss = 2.51348516\n",
            "Validation score: 0.192308\n",
            "Iteration 15, loss = 2.51260501\n",
            "Validation score: 0.158120\n",
            "Iteration 16, loss = 2.51096118\n",
            "Validation score: 0.188034\n",
            "Iteration 17, loss = 2.51046083\n",
            "Validation score: 0.183761\n",
            "Iteration 18, loss = 2.50933480\n",
            "Validation score: 0.166667\n",
            "Iteration 19, loss = 2.50792130\n",
            "Validation score: 0.166667\n",
            "Iteration 20, loss = 2.50761821\n",
            "Validation score: 0.170940\n",
            "Iteration 21, loss = 2.50655505\n",
            "Validation score: 0.170940\n",
            "Iteration 22, loss = 2.50550304\n",
            "Validation score: 0.175214\n",
            "Iteration 23, loss = 2.50457385\n",
            "Validation score: 0.175214\n",
            "Iteration 24, loss = 2.50295737\n",
            "Validation score: 0.209402\n",
            "Iteration 25, loss = 2.50175172\n",
            "Validation score: 0.213675\n",
            "Iteration 26, loss = 2.49945332\n",
            "Validation score: 0.175214\n",
            "Iteration 27, loss = 2.49634955\n",
            "Validation score: 0.179487\n",
            "Iteration 28, loss = 2.49336413\n",
            "Validation score: 0.217949\n",
            "Iteration 29, loss = 2.49080891\n",
            "Validation score: 0.166667\n",
            "Iteration 30, loss = 2.48702914\n",
            "Validation score: 0.166667\n",
            "Iteration 31, loss = 2.48397647\n",
            "Validation score: 0.141026\n",
            "Iteration 32, loss = 2.48017547\n",
            "Validation score: 0.153846\n",
            "Iteration 33, loss = 2.47641764\n",
            "Validation score: 0.153846\n",
            "Iteration 34, loss = 2.47251135\n",
            "Validation score: 0.175214\n",
            "Iteration 35, loss = 2.46808164\n",
            "Validation score: 0.192308\n",
            "Iteration 36, loss = 2.46299626\n",
            "Validation score: 0.115385\n",
            "Iteration 37, loss = 2.45840035\n",
            "Validation score: 0.153846\n",
            "Iteration 38, loss = 2.45335879\n",
            "Validation score: 0.192308\n",
            "Iteration 39, loss = 2.44737468\n",
            "Validation score: 0.222222\n",
            "Iteration 40, loss = 2.44226456\n",
            "Validation score: 0.217949\n",
            "Iteration 41, loss = 2.43610462\n",
            "Validation score: 0.222222\n",
            "Iteration 42, loss = 2.43006079\n",
            "Validation score: 0.226496\n",
            "Iteration 43, loss = 2.42357673\n",
            "Validation score: 0.222222\n",
            "Iteration 44, loss = 2.41723057\n",
            "Validation score: 0.226496\n",
            "Iteration 45, loss = 2.41066721\n",
            "Validation score: 0.217949\n",
            "Iteration 46, loss = 2.40367361\n",
            "Validation score: 0.239316\n",
            "Iteration 47, loss = 2.39655692\n",
            "Validation score: 0.239316\n",
            "Iteration 48, loss = 2.39082943\n",
            "Validation score: 0.239316\n",
            "Iteration 49, loss = 2.38274169\n",
            "Validation score: 0.247863\n",
            "Iteration 50, loss = 2.37664370\n",
            "Validation score: 0.247863\n",
            "Iteration 51, loss = 2.36940512\n",
            "Validation score: 0.252137\n",
            "Iteration 52, loss = 2.36292657\n",
            "Validation score: 0.247863\n",
            "Iteration 53, loss = 2.35624553\n",
            "Validation score: 0.256410\n",
            "Iteration 54, loss = 2.34981951\n",
            "Validation score: 0.256410\n",
            "Iteration 55, loss = 2.34299841\n",
            "Validation score: 0.252137\n",
            "Iteration 56, loss = 2.33747590\n",
            "Validation score: 0.252137\n",
            "Iteration 57, loss = 2.33155530\n",
            "Validation score: 0.235043\n",
            "Iteration 58, loss = 2.32538424\n",
            "Validation score: 0.230769\n",
            "Iteration 59, loss = 2.31976624\n",
            "Validation score: 0.230769\n",
            "Iteration 60, loss = 2.31389313\n",
            "Validation score: 0.235043\n",
            "Iteration 61, loss = 2.30900343\n",
            "Validation score: 0.222222\n",
            "Iteration 62, loss = 2.30346958\n",
            "Validation score: 0.230769\n",
            "Iteration 63, loss = 2.29811672\n",
            "Validation score: 0.226496\n",
            "Iteration 64, loss = 2.29329564\n",
            "Validation score: 0.230769\n",
            "Iteration 65, loss = 2.28799726\n",
            "Validation score: 0.230769\n",
            "Iteration 66, loss = 2.28417798\n",
            "Validation score: 0.230769\n",
            "Iteration 67, loss = 2.27913339\n",
            "Validation score: 0.230769\n",
            "Iteration 68, loss = 2.27460207\n",
            "Validation score: 0.239316\n",
            "Iteration 69, loss = 2.27006860\n",
            "Validation score: 0.243590\n",
            "Iteration 70, loss = 2.26682582\n",
            "Validation score: 0.239316\n",
            "Iteration 71, loss = 2.26197311\n",
            "Validation score: 0.235043\n",
            "Iteration 72, loss = 2.25830647\n",
            "Validation score: 0.235043\n",
            "Iteration 73, loss = 2.25443108\n",
            "Validation score: 0.235043\n",
            "Iteration 74, loss = 2.25016039\n",
            "Validation score: 0.239316\n",
            "Iteration 75, loss = 2.24707764\n",
            "Validation score: 0.243590\n",
            "Iteration 76, loss = 2.24322507\n",
            "Validation score: 0.243590\n",
            "Iteration 77, loss = 2.24078789\n",
            "Validation score: 0.239316\n",
            "Iteration 78, loss = 2.23687586\n",
            "Validation score: 0.247863\n",
            "Iteration 79, loss = 2.23380549\n",
            "Validation score: 0.256410\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.08539353\n",
            "Validation score: 0.153846\n",
            "Iteration 2, loss = 2.83716135\n",
            "Validation score: 0.153846\n",
            "Iteration 3, loss = 2.64691817\n",
            "Validation score: 0.119658\n",
            "Iteration 4, loss = 2.54225246\n",
            "Validation score: 0.115385\n",
            "Iteration 5, loss = 2.50320649\n",
            "Validation score: 0.115385\n",
            "Iteration 6, loss = 2.48728840\n",
            "Validation score: 0.094017\n",
            "Iteration 7, loss = 2.47547615\n",
            "Validation score: 0.119658\n",
            "Iteration 8, loss = 2.46248899\n",
            "Validation score: 0.128205\n",
            "Iteration 9, loss = 2.44667432\n",
            "Validation score: 0.149573\n",
            "Iteration 10, loss = 2.42977548\n",
            "Validation score: 0.158120\n",
            "Iteration 11, loss = 2.41142192\n",
            "Validation score: 0.170940\n",
            "Iteration 12, loss = 2.39181836\n",
            "Validation score: 0.196581\n",
            "Iteration 13, loss = 2.37231863\n",
            "Validation score: 0.205128\n",
            "Iteration 14, loss = 2.35287566\n",
            "Validation score: 0.175214\n",
            "Iteration 15, loss = 2.33317758\n",
            "Validation score: 0.188034\n",
            "Iteration 16, loss = 2.31445070\n",
            "Validation score: 0.222222\n",
            "Iteration 17, loss = 2.29624031\n",
            "Validation score: 0.239316\n",
            "Iteration 18, loss = 2.27927807\n",
            "Validation score: 0.243590\n",
            "Iteration 19, loss = 2.26235298\n",
            "Validation score: 0.235043\n",
            "Iteration 20, loss = 2.24753837\n",
            "Validation score: 0.239316\n",
            "Iteration 21, loss = 2.23431308\n",
            "Validation score: 0.239316\n",
            "Iteration 22, loss = 2.22146597\n",
            "Validation score: 0.226496\n",
            "Iteration 23, loss = 2.21072190\n",
            "Validation score: 0.230769\n",
            "Iteration 24, loss = 2.20052891\n",
            "Validation score: 0.226496\n",
            "Iteration 25, loss = 2.19149502\n",
            "Validation score: 0.217949\n",
            "Iteration 26, loss = 2.18333325\n",
            "Validation score: 0.239316\n",
            "Iteration 27, loss = 2.17585244\n",
            "Validation score: 0.222222\n",
            "Iteration 28, loss = 2.16932623\n",
            "Validation score: 0.243590\n",
            "Iteration 29, loss = 2.16266791\n",
            "Validation score: 0.222222\n",
            "Iteration 30, loss = 2.15860249\n",
            "Validation score: 0.239316\n",
            "Iteration 31, loss = 2.15088490\n",
            "Validation score: 0.222222\n",
            "Iteration 32, loss = 2.14808571\n",
            "Validation score: 0.226496\n",
            "Iteration 33, loss = 2.14332145\n",
            "Validation score: 0.230769\n",
            "Iteration 34, loss = 2.13803871\n",
            "Validation score: 0.217949\n",
            "Iteration 35, loss = 2.13525810\n",
            "Validation score: 0.230769\n",
            "Iteration 36, loss = 2.13094993\n",
            "Validation score: 0.222222\n",
            "Iteration 37, loss = 2.12801677\n",
            "Validation score: 0.243590\n",
            "Iteration 38, loss = 2.12407782\n",
            "Validation score: 0.243590\n",
            "Iteration 39, loss = 2.12092906\n",
            "Validation score: 0.230769\n",
            "Iteration 40, loss = 2.11873847\n",
            "Validation score: 0.260684\n",
            "Iteration 41, loss = 2.11498231\n",
            "Validation score: 0.256410\n",
            "Iteration 42, loss = 2.11152429\n",
            "Validation score: 0.256410\n",
            "Iteration 43, loss = 2.11025899\n",
            "Validation score: 0.243590\n",
            "Iteration 44, loss = 2.10684389\n",
            "Validation score: 0.239316\n",
            "Iteration 45, loss = 2.10534715\n",
            "Validation score: 0.247863\n",
            "Iteration 46, loss = 2.10185118\n",
            "Validation score: 0.256410\n",
            "Iteration 47, loss = 2.09876545\n",
            "Validation score: 0.252137\n",
            "Iteration 48, loss = 2.09692264\n",
            "Validation score: 0.235043\n",
            "Iteration 49, loss = 2.09397529\n",
            "Validation score: 0.239316\n",
            "Iteration 50, loss = 2.09157843\n",
            "Validation score: 0.226496\n",
            "Iteration 51, loss = 2.08931776\n",
            "Validation score: 0.243590\n",
            "Iteration 52, loss = 2.08834163\n",
            "Validation score: 0.264957\n",
            "Iteration 53, loss = 2.08583141\n",
            "Validation score: 0.230769\n",
            "Iteration 54, loss = 2.08308106\n",
            "Validation score: 0.243590\n",
            "Iteration 55, loss = 2.08169760\n",
            "Validation score: 0.230769\n",
            "Iteration 56, loss = 2.07955532\n",
            "Validation score: 0.260684\n",
            "Iteration 57, loss = 2.07660941\n",
            "Validation score: 0.256410\n",
            "Iteration 58, loss = 2.07471210\n",
            "Validation score: 0.247863\n",
            "Iteration 59, loss = 2.07323054\n",
            "Validation score: 0.247863\n",
            "Iteration 60, loss = 2.07090631\n",
            "Validation score: 0.247863\n",
            "Iteration 61, loss = 2.06906791\n",
            "Validation score: 0.239316\n",
            "Iteration 62, loss = 2.06781916\n",
            "Validation score: 0.264957\n",
            "Iteration 63, loss = 2.06582986\n",
            "Validation score: 0.239316\n",
            "Iteration 64, loss = 2.06328730\n",
            "Validation score: 0.269231\n",
            "Iteration 65, loss = 2.06100134\n",
            "Validation score: 0.247863\n",
            "Iteration 66, loss = 2.06058861\n",
            "Validation score: 0.269231\n",
            "Iteration 67, loss = 2.05841760\n",
            "Validation score: 0.256410\n",
            "Iteration 68, loss = 2.05519960\n",
            "Validation score: 0.264957\n",
            "Iteration 69, loss = 2.05485002\n",
            "Validation score: 0.260684\n",
            "Iteration 70, loss = 2.05241145\n",
            "Validation score: 0.256410\n",
            "Iteration 71, loss = 2.05070241\n",
            "Validation score: 0.239316\n",
            "Iteration 72, loss = 2.04692348\n",
            "Validation score: 0.256410\n",
            "Iteration 73, loss = 2.04453667\n",
            "Validation score: 0.264957\n",
            "Iteration 74, loss = 2.04291911\n",
            "Validation score: 0.277778\n",
            "Iteration 75, loss = 2.04223442\n",
            "Validation score: 0.260684\n",
            "Iteration 76, loss = 2.04003864\n",
            "Validation score: 0.264957\n",
            "Iteration 77, loss = 2.03750974\n",
            "Validation score: 0.256410\n",
            "Iteration 78, loss = 2.03476182\n",
            "Validation score: 0.282051\n",
            "Iteration 79, loss = 2.03287344\n",
            "Validation score: 0.277778\n",
            "Iteration 80, loss = 2.03094924\n",
            "Validation score: 0.277778\n",
            "Iteration 81, loss = 2.02956146\n",
            "Validation score: 0.269231\n",
            "Iteration 82, loss = 2.02624767\n",
            "Validation score: 0.273504\n",
            "Iteration 83, loss = 2.02585490\n",
            "Validation score: 0.273504\n",
            "Iteration 84, loss = 2.02380878\n",
            "Validation score: 0.264957\n",
            "Iteration 85, loss = 2.02168695\n",
            "Validation score: 0.256410\n",
            "Iteration 86, loss = 2.02173036\n",
            "Validation score: 0.286325\n",
            "Iteration 87, loss = 2.01985965\n",
            "Validation score: 0.273504\n",
            "Iteration 88, loss = 2.01570243\n",
            "Validation score: 0.286325\n",
            "Iteration 89, loss = 2.01491720\n",
            "Validation score: 0.269231\n",
            "Iteration 90, loss = 2.01279250\n",
            "Validation score: 0.273504\n",
            "Iteration 91, loss = 2.01058366\n",
            "Validation score: 0.264957\n",
            "Iteration 92, loss = 2.01032970\n",
            "Validation score: 0.269231\n",
            "Iteration 93, loss = 2.00915635\n",
            "Validation score: 0.273504\n",
            "Iteration 94, loss = 2.00614511\n",
            "Validation score: 0.260684\n",
            "Iteration 95, loss = 2.00486717\n",
            "Validation score: 0.252137\n",
            "Iteration 96, loss = 2.00322071\n",
            "Validation score: 0.277778\n",
            "Iteration 97, loss = 2.00267971\n",
            "Validation score: 0.273504\n",
            "Iteration 98, loss = 2.00114250\n",
            "Validation score: 0.252137\n",
            "Iteration 99, loss = 1.99879110\n",
            "Validation score: 0.273504\n",
            "Iteration 100, loss = 1.99759093\n",
            "Validation score: 0.264957\n",
            "Iteration 101, loss = 1.99744609\n",
            "Validation score: 0.256410\n",
            "Iteration 102, loss = 1.99529746\n",
            "Validation score: 0.269231\n",
            "Iteration 103, loss = 1.99418854\n",
            "Validation score: 0.282051\n",
            "Iteration 104, loss = 1.99241912\n",
            "Validation score: 0.282051\n",
            "Iteration 105, loss = 1.99066193\n",
            "Validation score: 0.269231\n",
            "Iteration 106, loss = 1.99145853\n",
            "Validation score: 0.256410\n",
            "Iteration 107, loss = 1.99041804\n",
            "Validation score: 0.286325\n",
            "Iteration 108, loss = 1.98842342\n",
            "Validation score: 0.282051\n",
            "Iteration 109, loss = 1.98827520\n",
            "Validation score: 0.273504\n",
            "Iteration 110, loss = 1.98719298\n",
            "Validation score: 0.277778\n",
            "Iteration 111, loss = 1.98785942\n",
            "Validation score: 0.282051\n",
            "Iteration 112, loss = 1.98567874\n",
            "Validation score: 0.260684\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.18356745\n",
            "Validation score: 0.102564\n",
            "Iteration 2, loss = 2.95831241\n",
            "Validation score: 0.115385\n",
            "Iteration 3, loss = 2.74192960\n",
            "Validation score: 0.115385\n",
            "Iteration 4, loss = 2.60753442\n",
            "Validation score: 0.136752\n",
            "Iteration 5, loss = 2.53884960\n",
            "Validation score: 0.136752\n",
            "Iteration 6, loss = 2.49179682\n",
            "Validation score: 0.162393\n",
            "Iteration 7, loss = 2.42642066\n",
            "Validation score: 0.166667\n",
            "Iteration 8, loss = 2.38465146\n",
            "Validation score: 0.149573\n",
            "Iteration 9, loss = 2.35357409\n",
            "Validation score: 0.188034\n",
            "Iteration 10, loss = 2.32757859\n",
            "Validation score: 0.213675\n",
            "Iteration 11, loss = 2.30763335\n",
            "Validation score: 0.247863\n",
            "Iteration 12, loss = 2.29020552\n",
            "Validation score: 0.235043\n",
            "Iteration 13, loss = 2.27550242\n",
            "Validation score: 0.239316\n",
            "Iteration 14, loss = 2.26287603\n",
            "Validation score: 0.230769\n",
            "Iteration 15, loss = 2.25198494\n",
            "Validation score: 0.226496\n",
            "Iteration 16, loss = 2.24233653\n",
            "Validation score: 0.235043\n",
            "Iteration 17, loss = 2.23452111\n",
            "Validation score: 0.226496\n",
            "Iteration 18, loss = 2.22627133\n",
            "Validation score: 0.243590\n",
            "Iteration 19, loss = 2.21941010\n",
            "Validation score: 0.230769\n",
            "Iteration 20, loss = 2.21357302\n",
            "Validation score: 0.235043\n",
            "Iteration 21, loss = 2.20736630\n",
            "Validation score: 0.235043\n",
            "Iteration 22, loss = 2.20199961\n",
            "Validation score: 0.247863\n",
            "Iteration 23, loss = 2.19758312\n",
            "Validation score: 0.264957\n",
            "Iteration 24, loss = 2.19322448\n",
            "Validation score: 0.256410\n",
            "Iteration 25, loss = 2.18931889\n",
            "Validation score: 0.260684\n",
            "Iteration 26, loss = 2.18533048\n",
            "Validation score: 0.269231\n",
            "Iteration 27, loss = 2.18259587\n",
            "Validation score: 0.260684\n",
            "Iteration 28, loss = 2.17833542\n",
            "Validation score: 0.264957\n",
            "Iteration 29, loss = 2.17591421\n",
            "Validation score: 0.264957\n",
            "Iteration 30, loss = 2.17315568\n",
            "Validation score: 0.282051\n",
            "Iteration 31, loss = 2.17045766\n",
            "Validation score: 0.264957\n",
            "Iteration 32, loss = 2.16838393\n",
            "Validation score: 0.264957\n",
            "Iteration 33, loss = 2.16538158\n",
            "Validation score: 0.277778\n",
            "Iteration 34, loss = 2.16347546\n",
            "Validation score: 0.273504\n",
            "Iteration 35, loss = 2.16179930\n",
            "Validation score: 0.252137\n",
            "Iteration 36, loss = 2.15951540\n",
            "Validation score: 0.286325\n",
            "Iteration 37, loss = 2.15758693\n",
            "Validation score: 0.282051\n",
            "Iteration 38, loss = 2.15607535\n",
            "Validation score: 0.256410\n",
            "Iteration 39, loss = 2.15371560\n",
            "Validation score: 0.294872\n",
            "Iteration 40, loss = 2.15294887\n",
            "Validation score: 0.277778\n",
            "Iteration 41, loss = 2.15173063\n",
            "Validation score: 0.282051\n",
            "Iteration 42, loss = 2.14936991\n",
            "Validation score: 0.290598\n",
            "Iteration 43, loss = 2.14840363\n",
            "Validation score: 0.286325\n",
            "Iteration 44, loss = 2.14646160\n",
            "Validation score: 0.282051\n",
            "Iteration 45, loss = 2.14555206\n",
            "Validation score: 0.294872\n",
            "Iteration 46, loss = 2.14394097\n",
            "Validation score: 0.282051\n",
            "Iteration 47, loss = 2.14298374\n",
            "Validation score: 0.282051\n",
            "Iteration 48, loss = 2.14220175\n",
            "Validation score: 0.269231\n",
            "Iteration 49, loss = 2.14045217\n",
            "Validation score: 0.277778\n",
            "Iteration 50, loss = 2.13980253\n",
            "Validation score: 0.282051\n",
            "Iteration 51, loss = 2.13868924\n",
            "Validation score: 0.282051\n",
            "Iteration 52, loss = 2.13695672\n",
            "Validation score: 0.290598\n",
            "Iteration 53, loss = 2.13613501\n",
            "Validation score: 0.286325\n",
            "Iteration 54, loss = 2.13495814\n",
            "Validation score: 0.290598\n",
            "Iteration 55, loss = 2.13363891\n",
            "Validation score: 0.269231\n",
            "Iteration 56, loss = 2.13301118\n",
            "Validation score: 0.282051\n",
            "Iteration 57, loss = 2.13195759\n",
            "Validation score: 0.277778\n",
            "Iteration 58, loss = 2.13114691\n",
            "Validation score: 0.269231\n",
            "Iteration 59, loss = 2.13043637\n",
            "Validation score: 0.286325\n",
            "Iteration 60, loss = 2.12970388\n",
            "Validation score: 0.282051\n",
            "Iteration 61, loss = 2.12846181\n",
            "Validation score: 0.294872\n",
            "Iteration 62, loss = 2.12707894\n",
            "Validation score: 0.290598\n",
            "Iteration 63, loss = 2.12696878\n",
            "Validation score: 0.282051\n",
            "Iteration 64, loss = 2.12638909\n",
            "Validation score: 0.269231\n",
            "Iteration 65, loss = 2.12535583\n",
            "Validation score: 0.282051\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.12797491\n",
            "Validation score: 0.145299\n",
            "Iteration 2, loss = 2.76547316\n",
            "Validation score: 0.188034\n",
            "Iteration 3, loss = 2.54099819\n",
            "Validation score: 0.230769\n",
            "Iteration 4, loss = 2.48258409\n",
            "Validation score: 0.200855\n",
            "Iteration 5, loss = 2.45850959\n",
            "Validation score: 0.222222\n",
            "Iteration 6, loss = 2.43614039\n",
            "Validation score: 0.222222\n",
            "Iteration 7, loss = 2.41280929\n",
            "Validation score: 0.256410\n",
            "Iteration 8, loss = 2.38881411\n",
            "Validation score: 0.239316\n",
            "Iteration 9, loss = 2.36543756\n",
            "Validation score: 0.247863\n",
            "Iteration 10, loss = 2.34322074\n",
            "Validation score: 0.256410\n",
            "Iteration 11, loss = 2.32260425\n",
            "Validation score: 0.243590\n",
            "Iteration 12, loss = 2.30700867\n",
            "Validation score: 0.243590\n",
            "Iteration 13, loss = 2.29223704\n",
            "Validation score: 0.252137\n",
            "Iteration 14, loss = 2.28128435\n",
            "Validation score: 0.239316\n",
            "Iteration 15, loss = 2.27081363\n",
            "Validation score: 0.247863\n",
            "Iteration 16, loss = 2.26245507\n",
            "Validation score: 0.252137\n",
            "Iteration 17, loss = 2.25423705\n",
            "Validation score: 0.260684\n",
            "Iteration 18, loss = 2.24749799\n",
            "Validation score: 0.277778\n",
            "Iteration 19, loss = 2.24106283\n",
            "Validation score: 0.243590\n",
            "Iteration 20, loss = 2.23534657\n",
            "Validation score: 0.247863\n",
            "Iteration 21, loss = 2.22992269\n",
            "Validation score: 0.230769\n",
            "Iteration 22, loss = 2.22509909\n",
            "Validation score: 0.256410\n",
            "Iteration 23, loss = 2.21981431\n",
            "Validation score: 0.256410\n",
            "Iteration 24, loss = 2.21661060\n",
            "Validation score: 0.256410\n",
            "Iteration 25, loss = 2.21173979\n",
            "Validation score: 0.277778\n",
            "Iteration 26, loss = 2.20717439\n",
            "Validation score: 0.264957\n",
            "Iteration 27, loss = 2.20384091\n",
            "Validation score: 0.269231\n",
            "Iteration 28, loss = 2.19973467\n",
            "Validation score: 0.252137\n",
            "Iteration 29, loss = 2.19705766\n",
            "Validation score: 0.264957\n",
            "Iteration 30, loss = 2.19372958\n",
            "Validation score: 0.260684\n",
            "Iteration 31, loss = 2.19090003\n",
            "Validation score: 0.247863\n",
            "Iteration 32, loss = 2.18806831\n",
            "Validation score: 0.282051\n",
            "Iteration 33, loss = 2.18524739\n",
            "Validation score: 0.260684\n",
            "Iteration 34, loss = 2.18349779\n",
            "Validation score: 0.286325\n",
            "Iteration 35, loss = 2.18073038\n",
            "Validation score: 0.282051\n",
            "Iteration 36, loss = 2.17770217\n",
            "Validation score: 0.277778\n",
            "Iteration 37, loss = 2.17534319\n",
            "Validation score: 0.264957\n",
            "Iteration 38, loss = 2.17360612\n",
            "Validation score: 0.277778\n",
            "Iteration 39, loss = 2.17054124\n",
            "Validation score: 0.277778\n",
            "Iteration 40, loss = 2.16863975\n",
            "Validation score: 0.264957\n",
            "Iteration 41, loss = 2.16700613\n",
            "Validation score: 0.269231\n",
            "Iteration 42, loss = 2.16584359\n",
            "Validation score: 0.269231\n",
            "Iteration 43, loss = 2.16394249\n",
            "Validation score: 0.282051\n",
            "Iteration 44, loss = 2.16248209\n",
            "Validation score: 0.277778\n",
            "Iteration 45, loss = 2.16030321\n",
            "Validation score: 0.277778\n",
            "Iteration 46, loss = 2.15838625\n",
            "Validation score: 0.294872\n",
            "Iteration 47, loss = 2.15656096\n",
            "Validation score: 0.290598\n",
            "Iteration 48, loss = 2.15580964\n",
            "Validation score: 0.277778\n",
            "Iteration 49, loss = 2.15503153\n",
            "Validation score: 0.282051\n",
            "Iteration 50, loss = 2.15235296\n",
            "Validation score: 0.294872\n",
            "Iteration 51, loss = 2.15144756\n",
            "Validation score: 0.286325\n",
            "Iteration 52, loss = 2.14987536\n",
            "Validation score: 0.282051\n",
            "Iteration 53, loss = 2.14846887\n",
            "Validation score: 0.273504\n",
            "Iteration 54, loss = 2.14711238\n",
            "Validation score: 0.260684\n",
            "Iteration 55, loss = 2.14574574\n",
            "Validation score: 0.282051\n",
            "Iteration 56, loss = 2.14479953\n",
            "Validation score: 0.290598\n",
            "Iteration 57, loss = 2.14370917\n",
            "Validation score: 0.282051\n",
            "Iteration 58, loss = 2.14333184\n",
            "Validation score: 0.286325\n",
            "Iteration 59, loss = 2.14108517\n",
            "Validation score: 0.290598\n",
            "Iteration 60, loss = 2.14027544\n",
            "Validation score: 0.286325\n",
            "Iteration 61, loss = 2.13848281\n",
            "Validation score: 0.282051\n",
            "Iteration 62, loss = 2.13885025\n",
            "Validation score: 0.294872\n",
            "Iteration 63, loss = 2.13730915\n",
            "Validation score: 0.286325\n",
            "Iteration 64, loss = 2.13550989\n",
            "Validation score: 0.294872\n",
            "Iteration 65, loss = 2.13498580\n",
            "Validation score: 0.294872\n",
            "Iteration 66, loss = 2.13372747\n",
            "Validation score: 0.294872\n",
            "Iteration 67, loss = 2.13255302\n",
            "Validation score: 0.290598\n",
            "Iteration 68, loss = 2.13187318\n",
            "Validation score: 0.299145\n",
            "Iteration 69, loss = 2.13101329\n",
            "Validation score: 0.286325\n",
            "Iteration 70, loss = 2.13056937\n",
            "Validation score: 0.282051\n",
            "Iteration 71, loss = 2.13033152\n",
            "Validation score: 0.277778\n",
            "Iteration 72, loss = 2.12990020\n",
            "Validation score: 0.273504\n",
            "Iteration 73, loss = 2.12847944\n",
            "Validation score: 0.303419\n",
            "Iteration 74, loss = 2.12671598\n",
            "Validation score: 0.260684\n",
            "Iteration 75, loss = 2.12714424\n",
            "Validation score: 0.269231\n",
            "Iteration 76, loss = 2.12624272\n",
            "Validation score: 0.286325\n",
            "Iteration 77, loss = 2.12537008\n",
            "Validation score: 0.256410\n",
            "Iteration 78, loss = 2.12364086\n",
            "Validation score: 0.282051\n",
            "Iteration 79, loss = 2.12359299\n",
            "Validation score: 0.290598\n",
            "Iteration 80, loss = 2.12346895\n",
            "Validation score: 0.294872\n",
            "Iteration 81, loss = 2.12209212\n",
            "Validation score: 0.277778\n",
            "Iteration 82, loss = 2.12103170\n",
            "Validation score: 0.307692\n",
            "Iteration 83, loss = 2.12127368\n",
            "Validation score: 0.286325\n",
            "Iteration 84, loss = 2.11948745\n",
            "Validation score: 0.290598\n",
            "Iteration 85, loss = 2.12043256\n",
            "Validation score: 0.303419\n",
            "Iteration 86, loss = 2.11895688\n",
            "Validation score: 0.273504\n",
            "Iteration 87, loss = 2.11746579\n",
            "Validation score: 0.277778\n",
            "Iteration 88, loss = 2.11674901\n",
            "Validation score: 0.290598\n",
            "Iteration 89, loss = 2.11700679\n",
            "Validation score: 0.282051\n",
            "Iteration 90, loss = 2.11586111\n",
            "Validation score: 0.307692\n",
            "Iteration 91, loss = 2.11509331\n",
            "Validation score: 0.294872\n",
            "Iteration 92, loss = 2.11468328\n",
            "Validation score: 0.294872\n",
            "Iteration 93, loss = 2.11420368\n",
            "Validation score: 0.294872\n",
            "Iteration 94, loss = 2.11386868\n",
            "Validation score: 0.299145\n",
            "Iteration 95, loss = 2.11188433\n",
            "Validation score: 0.307692\n",
            "Iteration 96, loss = 2.11138618\n",
            "Validation score: 0.299145\n",
            "Iteration 97, loss = 2.11042510\n",
            "Validation score: 0.286325\n",
            "Iteration 98, loss = 2.11053206\n",
            "Validation score: 0.294872\n",
            "Iteration 99, loss = 2.10990409\n",
            "Validation score: 0.294872\n",
            "Iteration 100, loss = 2.10927886\n",
            "Validation score: 0.303419\n",
            "Iteration 101, loss = 2.10706829\n",
            "Validation score: 0.269231\n",
            "Iteration 102, loss = 2.10780356\n",
            "Validation score: 0.303419\n",
            "Iteration 103, loss = 2.10710279\n",
            "Validation score: 0.311966\n",
            "Iteration 104, loss = 2.10619879\n",
            "Validation score: 0.299145\n",
            "Iteration 105, loss = 2.10431500\n",
            "Validation score: 0.277778\n",
            "Iteration 106, loss = 2.10454732\n",
            "Validation score: 0.269231\n",
            "Iteration 107, loss = 2.10413742\n",
            "Validation score: 0.294872\n",
            "Iteration 108, loss = 2.10407044\n",
            "Validation score: 0.290598\n",
            "Iteration 109, loss = 2.10240005\n",
            "Validation score: 0.324786\n",
            "Iteration 110, loss = 2.10151997\n",
            "Validation score: 0.273504\n",
            "Iteration 111, loss = 2.10059700\n",
            "Validation score: 0.290598\n",
            "Iteration 112, loss = 2.10055630\n",
            "Validation score: 0.316239\n",
            "Iteration 113, loss = 2.10030029\n",
            "Validation score: 0.282051\n",
            "Iteration 114, loss = 2.09961104\n",
            "Validation score: 0.311966\n",
            "Iteration 115, loss = 2.09837612\n",
            "Validation score: 0.290598\n",
            "Iteration 116, loss = 2.09742221\n",
            "Validation score: 0.299145\n",
            "Iteration 117, loss = 2.09692204\n",
            "Validation score: 0.286325\n",
            "Iteration 118, loss = 2.09570412\n",
            "Validation score: 0.282051\n",
            "Iteration 119, loss = 2.09483266\n",
            "Validation score: 0.286325\n",
            "Iteration 120, loss = 2.09424793\n",
            "Validation score: 0.303419\n",
            "Iteration 121, loss = 2.09392562\n",
            "Validation score: 0.277778\n",
            "Iteration 122, loss = 2.09306800\n",
            "Validation score: 0.294872\n",
            "Iteration 123, loss = 2.09179981\n",
            "Validation score: 0.273504\n",
            "Iteration 124, loss = 2.09147390\n",
            "Validation score: 0.282051\n",
            "Iteration 125, loss = 2.09069467\n",
            "Validation score: 0.307692\n",
            "Iteration 126, loss = 2.09022271\n",
            "Validation score: 0.290598\n",
            "Iteration 127, loss = 2.08987191\n",
            "Validation score: 0.299145\n",
            "Iteration 128, loss = 2.08822178\n",
            "Validation score: 0.316239\n",
            "Iteration 129, loss = 2.08747659\n",
            "Validation score: 0.316239\n",
            "Iteration 130, loss = 2.08662715\n",
            "Validation score: 0.307692\n",
            "Iteration 131, loss = 2.08627690\n",
            "Validation score: 0.303419\n",
            "Iteration 132, loss = 2.08506003\n",
            "Validation score: 0.286325\n",
            "Iteration 133, loss = 2.08479884\n",
            "Validation score: 0.294872\n",
            "Iteration 134, loss = 2.08365837\n",
            "Validation score: 0.277778\n",
            "Iteration 135, loss = 2.08306944\n",
            "Validation score: 0.307692\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.21941575\n",
            "Validation score: 0.162393\n",
            "Iteration 2, loss = 3.03911154\n",
            "Validation score: 0.162393\n",
            "Iteration 3, loss = 2.88774314\n",
            "Validation score: 0.162393\n",
            "Iteration 4, loss = 2.74595797\n",
            "Validation score: 0.162393\n",
            "Iteration 5, loss = 2.63747100\n",
            "Validation score: 0.162393\n",
            "Iteration 6, loss = 2.57316814\n",
            "Validation score: 0.162393\n",
            "Iteration 7, loss = 2.54086941\n",
            "Validation score: 0.162393\n",
            "Iteration 8, loss = 2.52546533\n",
            "Validation score: 0.132479\n",
            "Iteration 9, loss = 2.51741228\n",
            "Validation score: 0.132479\n",
            "Iteration 10, loss = 2.51263950\n",
            "Validation score: 0.132479\n",
            "Iteration 11, loss = 2.50966183\n",
            "Validation score: 0.132479\n",
            "Iteration 12, loss = 2.50756789\n",
            "Validation score: 0.132479\n",
            "Iteration 13, loss = 2.50619124\n",
            "Validation score: 0.132479\n",
            "Iteration 14, loss = 2.50531379\n",
            "Validation score: 0.132479\n",
            "Iteration 15, loss = 2.50426920\n",
            "Validation score: 0.132479\n",
            "Iteration 16, loss = 2.50354473\n",
            "Validation score: 0.132479\n",
            "Iteration 17, loss = 2.50336970\n",
            "Validation score: 0.132479\n",
            "Iteration 18, loss = 2.50299144\n",
            "Validation score: 0.132479\n",
            "Iteration 19, loss = 2.50269054\n",
            "Validation score: 0.132479\n",
            "Iteration 20, loss = 2.50245026\n",
            "Validation score: 0.162393\n",
            "Iteration 21, loss = 2.50207549\n",
            "Validation score: 0.132479\n",
            "Iteration 22, loss = 2.50194782\n",
            "Validation score: 0.132479\n",
            "Iteration 23, loss = 2.50221329\n",
            "Validation score: 0.132479\n",
            "Iteration 24, loss = 2.50178535\n",
            "Validation score: 0.132479\n",
            "Iteration 25, loss = 2.50184086\n",
            "Validation score: 0.132479\n",
            "Iteration 26, loss = 2.50160001\n",
            "Validation score: 0.132479\n",
            "Iteration 27, loss = 2.50170767\n",
            "Validation score: 0.132479\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.45006648\n",
            "Validation score: 0.004274\n",
            "Iteration 2, loss = 3.15521390\n",
            "Validation score: 0.158120\n",
            "Iteration 3, loss = 2.88240720\n",
            "Validation score: 0.136752\n",
            "Iteration 4, loss = 2.69236512\n",
            "Validation score: 0.145299\n",
            "Iteration 5, loss = 2.59654233\n",
            "Validation score: 0.153846\n",
            "Iteration 6, loss = 2.55615853\n",
            "Validation score: 0.153846\n",
            "Iteration 7, loss = 2.53894656\n",
            "Validation score: 0.153846\n",
            "Iteration 8, loss = 2.53064060\n",
            "Validation score: 0.153846\n",
            "Iteration 9, loss = 2.52581515\n",
            "Validation score: 0.175214\n",
            "Iteration 10, loss = 2.52258932\n",
            "Validation score: 0.149573\n",
            "Iteration 11, loss = 2.52012809\n",
            "Validation score: 0.149573\n",
            "Iteration 12, loss = 2.51875415\n",
            "Validation score: 0.149573\n",
            "Iteration 13, loss = 2.51733186\n",
            "Validation score: 0.153846\n",
            "Iteration 14, loss = 2.51656869\n",
            "Validation score: 0.153846\n",
            "Iteration 15, loss = 2.51568736\n",
            "Validation score: 0.153846\n",
            "Iteration 16, loss = 2.51535984\n",
            "Validation score: 0.153846\n",
            "Iteration 17, loss = 2.51506891\n",
            "Validation score: 0.153846\n",
            "Iteration 18, loss = 2.51455635\n",
            "Validation score: 0.153846\n",
            "Iteration 19, loss = 2.51406894\n",
            "Validation score: 0.153846\n",
            "Iteration 20, loss = 2.51413722\n",
            "Validation score: 0.175214\n",
            "Iteration 21, loss = 2.51384465\n",
            "Validation score: 0.153846\n",
            "Iteration 22, loss = 2.51373593\n",
            "Validation score: 0.153846\n",
            "Iteration 23, loss = 2.51324190\n",
            "Validation score: 0.153846\n",
            "Iteration 24, loss = 2.51356993\n",
            "Validation score: 0.175214\n",
            "Iteration 25, loss = 2.51353619\n",
            "Validation score: 0.153846\n",
            "Iteration 26, loss = 2.51328934\n",
            "Validation score: 0.153846\n",
            "Iteration 27, loss = 2.51308680\n",
            "Validation score: 0.149573\n",
            "Iteration 28, loss = 2.51361574\n",
            "Validation score: 0.153846\n",
            "Iteration 29, loss = 2.51331909\n",
            "Validation score: 0.149573\n",
            "Iteration 30, loss = 2.51327070\n",
            "Validation score: 0.153846\n",
            "Iteration 31, loss = 2.51310779\n",
            "Validation score: 0.153846\n",
            "Iteration 32, loss = 2.51307589\n",
            "Validation score: 0.153846\n",
            "Iteration 33, loss = 2.51341770\n",
            "Validation score: 0.153846\n",
            "Iteration 34, loss = 2.51293593\n",
            "Validation score: 0.153846\n",
            "Iteration 35, loss = 2.51305581\n",
            "Validation score: 0.153846\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.24176904\n",
            "Validation score: 0.175214\n",
            "Iteration 2, loss = 2.95477928\n",
            "Validation score: 0.175214\n",
            "Iteration 3, loss = 2.70336283\n",
            "Validation score: 0.175214\n",
            "Iteration 4, loss = 2.58232565\n",
            "Validation score: 0.175214\n",
            "Iteration 5, loss = 2.51728095\n",
            "Validation score: 0.264957\n",
            "Iteration 6, loss = 2.47130528\n",
            "Validation score: 0.269231\n",
            "Iteration 7, loss = 2.43081823\n",
            "Validation score: 0.264957\n",
            "Iteration 8, loss = 2.40014772\n",
            "Validation score: 0.273504\n",
            "Iteration 9, loss = 2.37593802\n",
            "Validation score: 0.273504\n",
            "Iteration 10, loss = 2.35580877\n",
            "Validation score: 0.260684\n",
            "Iteration 11, loss = 2.33951627\n",
            "Validation score: 0.282051\n",
            "Iteration 12, loss = 2.32533732\n",
            "Validation score: 0.294872\n",
            "Iteration 13, loss = 2.31359543\n",
            "Validation score: 0.294872\n",
            "Iteration 14, loss = 2.30282159\n",
            "Validation score: 0.290598\n",
            "Iteration 15, loss = 2.29333840\n",
            "Validation score: 0.290598\n",
            "Iteration 16, loss = 2.28439471\n",
            "Validation score: 0.282051\n",
            "Iteration 17, loss = 2.27644714\n",
            "Validation score: 0.282051\n",
            "Iteration 18, loss = 2.26918165\n",
            "Validation score: 0.286325\n",
            "Iteration 19, loss = 2.26202083\n",
            "Validation score: 0.290598\n",
            "Iteration 20, loss = 2.25527375\n",
            "Validation score: 0.303419\n",
            "Iteration 21, loss = 2.24923399\n",
            "Validation score: 0.294872\n",
            "Iteration 22, loss = 2.24408418\n",
            "Validation score: 0.290598\n",
            "Iteration 23, loss = 2.23803344\n",
            "Validation score: 0.286325\n",
            "Iteration 24, loss = 2.23333475\n",
            "Validation score: 0.290598\n",
            "Iteration 25, loss = 2.22802780\n",
            "Validation score: 0.282051\n",
            "Iteration 26, loss = 2.22313879\n",
            "Validation score: 0.286325\n",
            "Iteration 27, loss = 2.21828867\n",
            "Validation score: 0.286325\n",
            "Iteration 28, loss = 2.21392159\n",
            "Validation score: 0.286325\n",
            "Iteration 29, loss = 2.20977163\n",
            "Validation score: 0.307692\n",
            "Iteration 30, loss = 2.20544564\n",
            "Validation score: 0.290598\n",
            "Iteration 31, loss = 2.20176999\n",
            "Validation score: 0.294872\n",
            "Iteration 32, loss = 2.19823681\n",
            "Validation score: 0.299145\n",
            "Iteration 33, loss = 2.19452555\n",
            "Validation score: 0.290598\n",
            "Iteration 34, loss = 2.19152099\n",
            "Validation score: 0.299145\n",
            "Iteration 35, loss = 2.18818084\n",
            "Validation score: 0.307692\n",
            "Iteration 36, loss = 2.18541692\n",
            "Validation score: 0.307692\n",
            "Iteration 37, loss = 2.18214206\n",
            "Validation score: 0.311966\n",
            "Iteration 38, loss = 2.17935648\n",
            "Validation score: 0.316239\n",
            "Iteration 39, loss = 2.17691561\n",
            "Validation score: 0.324786\n",
            "Iteration 40, loss = 2.17433776\n",
            "Validation score: 0.316239\n",
            "Iteration 41, loss = 2.17207663\n",
            "Validation score: 0.307692\n",
            "Iteration 42, loss = 2.16986574\n",
            "Validation score: 0.311966\n",
            "Iteration 43, loss = 2.16759295\n",
            "Validation score: 0.303419\n",
            "Iteration 44, loss = 2.16482904\n",
            "Validation score: 0.320513\n",
            "Iteration 45, loss = 2.16338933\n",
            "Validation score: 0.303419\n",
            "Iteration 46, loss = 2.16176113\n",
            "Validation score: 0.311966\n",
            "Iteration 47, loss = 2.15932607\n",
            "Validation score: 0.324786\n",
            "Iteration 48, loss = 2.15722767\n",
            "Validation score: 0.311966\n",
            "Iteration 49, loss = 2.15501463\n",
            "Validation score: 0.320513\n",
            "Iteration 50, loss = 2.15426511\n",
            "Validation score: 0.324786\n",
            "Iteration 51, loss = 2.15231294\n",
            "Validation score: 0.311966\n",
            "Iteration 52, loss = 2.15014075\n",
            "Validation score: 0.324786\n",
            "Iteration 53, loss = 2.14871405\n",
            "Validation score: 0.329060\n",
            "Iteration 54, loss = 2.14704542\n",
            "Validation score: 0.337607\n",
            "Iteration 55, loss = 2.14567292\n",
            "Validation score: 0.316239\n",
            "Iteration 56, loss = 2.14407825\n",
            "Validation score: 0.329060\n",
            "Iteration 57, loss = 2.14289869\n",
            "Validation score: 0.324786\n",
            "Iteration 58, loss = 2.14208879\n",
            "Validation score: 0.333333\n",
            "Iteration 59, loss = 2.14062602\n",
            "Validation score: 0.320513\n",
            "Iteration 60, loss = 2.13890794\n",
            "Validation score: 0.320513\n",
            "Iteration 61, loss = 2.13814899\n",
            "Validation score: 0.311966\n",
            "Iteration 62, loss = 2.13663289\n",
            "Validation score: 0.333333\n",
            "Iteration 63, loss = 2.13533990\n",
            "Validation score: 0.311966\n",
            "Iteration 64, loss = 2.13454960\n",
            "Validation score: 0.329060\n",
            "Iteration 65, loss = 2.13291516\n",
            "Validation score: 0.329060\n",
            "Iteration 66, loss = 2.13249188\n",
            "Validation score: 0.316239\n",
            "Iteration 67, loss = 2.13138988\n",
            "Validation score: 0.333333\n",
            "Iteration 68, loss = 2.13012402\n",
            "Validation score: 0.324786\n",
            "Iteration 69, loss = 2.12831274\n",
            "Validation score: 0.320513\n",
            "Iteration 70, loss = 2.12861554\n",
            "Validation score: 0.341880\n",
            "Iteration 71, loss = 2.12738745\n",
            "Validation score: 0.311966\n",
            "Iteration 72, loss = 2.12607802\n",
            "Validation score: 0.320513\n",
            "Iteration 73, loss = 2.12508000\n",
            "Validation score: 0.324786\n",
            "Iteration 74, loss = 2.12386798\n",
            "Validation score: 0.329060\n",
            "Iteration 75, loss = 2.12275291\n",
            "Validation score: 0.316239\n",
            "Iteration 76, loss = 2.12252807\n",
            "Validation score: 0.316239\n",
            "Iteration 77, loss = 2.12126137\n",
            "Validation score: 0.333333\n",
            "Iteration 78, loss = 2.12072638\n",
            "Validation score: 0.333333\n",
            "Iteration 79, loss = 2.11986466\n",
            "Validation score: 0.324786\n",
            "Iteration 80, loss = 2.11834879\n",
            "Validation score: 0.329060\n",
            "Iteration 81, loss = 2.11839049\n",
            "Validation score: 0.333333\n",
            "Iteration 82, loss = 2.11746082\n",
            "Validation score: 0.324786\n",
            "Iteration 83, loss = 2.11644956\n",
            "Validation score: 0.333333\n",
            "Iteration 84, loss = 2.11625104\n",
            "Validation score: 0.329060\n",
            "Iteration 85, loss = 2.11458735\n",
            "Validation score: 0.316239\n",
            "Iteration 86, loss = 2.11374630\n",
            "Validation score: 0.307692\n",
            "Iteration 87, loss = 2.11395922\n",
            "Validation score: 0.324786\n",
            "Iteration 88, loss = 2.11281751\n",
            "Validation score: 0.316239\n",
            "Iteration 89, loss = 2.11233841\n",
            "Validation score: 0.324786\n",
            "Iteration 90, loss = 2.11154904\n",
            "Validation score: 0.346154\n",
            "Iteration 91, loss = 2.11130043\n",
            "Validation score: 0.333333\n",
            "Iteration 92, loss = 2.10956848\n",
            "Validation score: 0.337607\n",
            "Iteration 93, loss = 2.10917672\n",
            "Validation score: 0.316239\n",
            "Iteration 94, loss = 2.10779563\n",
            "Validation score: 0.329060\n",
            "Iteration 95, loss = 2.10716553\n",
            "Validation score: 0.329060\n",
            "Iteration 96, loss = 2.10706345\n",
            "Validation score: 0.316239\n",
            "Iteration 97, loss = 2.10621038\n",
            "Validation score: 0.324786\n",
            "Iteration 98, loss = 2.10453422\n",
            "Validation score: 0.341880\n",
            "Iteration 99, loss = 2.10477533\n",
            "Validation score: 0.337607\n",
            "Iteration 100, loss = 2.10357534\n",
            "Validation score: 0.329060\n",
            "Iteration 101, loss = 2.10246782\n",
            "Validation score: 0.341880\n",
            "Iteration 102, loss = 2.10194341\n",
            "Validation score: 0.329060\n",
            "Iteration 103, loss = 2.10117381\n",
            "Validation score: 0.341880\n",
            "Iteration 104, loss = 2.10150921\n",
            "Validation score: 0.333333\n",
            "Iteration 105, loss = 2.10053337\n",
            "Validation score: 0.337607\n",
            "Iteration 106, loss = 2.09885456\n",
            "Validation score: 0.333333\n",
            "Iteration 107, loss = 2.09853231\n",
            "Validation score: 0.341880\n",
            "Iteration 108, loss = 2.09829007\n",
            "Validation score: 0.346154\n",
            "Iteration 109, loss = 2.09735446\n",
            "Validation score: 0.341880\n",
            "Iteration 110, loss = 2.09731255\n",
            "Validation score: 0.363248\n",
            "Iteration 111, loss = 2.09635276\n",
            "Validation score: 0.329060\n",
            "Iteration 112, loss = 2.09578911\n",
            "Validation score: 0.311966\n",
            "Iteration 113, loss = 2.09421731\n",
            "Validation score: 0.324786\n",
            "Iteration 114, loss = 2.09332236\n",
            "Validation score: 0.329060\n",
            "Iteration 115, loss = 2.09282495\n",
            "Validation score: 0.337607\n",
            "Iteration 116, loss = 2.09236572\n",
            "Validation score: 0.333333\n",
            "Iteration 117, loss = 2.09081803\n",
            "Validation score: 0.329060\n",
            "Iteration 118, loss = 2.09036519\n",
            "Validation score: 0.329060\n",
            "Iteration 119, loss = 2.08919694\n",
            "Validation score: 0.324786\n",
            "Iteration 120, loss = 2.08891977\n",
            "Validation score: 0.341880\n",
            "Iteration 121, loss = 2.08793592\n",
            "Validation score: 0.333333\n",
            "Iteration 122, loss = 2.08701839\n",
            "Validation score: 0.329060\n",
            "Iteration 123, loss = 2.08649527\n",
            "Validation score: 0.329060\n",
            "Iteration 124, loss = 2.08582985\n",
            "Validation score: 0.333333\n",
            "Iteration 125, loss = 2.08468326\n",
            "Validation score: 0.316239\n",
            "Iteration 126, loss = 2.08404365\n",
            "Validation score: 0.333333\n",
            "Iteration 127, loss = 2.08327975\n",
            "Validation score: 0.354701\n",
            "Iteration 128, loss = 2.08241180\n",
            "Validation score: 0.324786\n",
            "Iteration 129, loss = 2.08154697\n",
            "Validation score: 0.316239\n",
            "Iteration 130, loss = 2.08160423\n",
            "Validation score: 0.324786\n",
            "Iteration 131, loss = 2.07977322\n",
            "Validation score: 0.337607\n",
            "Iteration 132, loss = 2.07948145\n",
            "Validation score: 0.329060\n",
            "Iteration 133, loss = 2.07888557\n",
            "Validation score: 0.329060\n",
            "Iteration 134, loss = 2.07772283\n",
            "Validation score: 0.329060\n",
            "Iteration 135, loss = 2.07607863\n",
            "Validation score: 0.329060\n",
            "Iteration 136, loss = 2.07617919\n",
            "Validation score: 0.324786\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.11288021\n",
            "Validation score: 0.102564\n",
            "Iteration 2, loss = 2.80870285\n",
            "Validation score: 0.098291\n",
            "Iteration 3, loss = 2.57414680\n",
            "Validation score: 0.119658\n",
            "Iteration 4, loss = 2.47192763\n",
            "Validation score: 0.158120\n",
            "Iteration 5, loss = 2.42396689\n",
            "Validation score: 0.166667\n",
            "Iteration 6, loss = 2.38879937\n",
            "Validation score: 0.217949\n",
            "Iteration 7, loss = 2.35865506\n",
            "Validation score: 0.213675\n",
            "Iteration 8, loss = 2.33221303\n",
            "Validation score: 0.226496\n",
            "Iteration 9, loss = 2.30874553\n",
            "Validation score: 0.230769\n",
            "Iteration 10, loss = 2.28726214\n",
            "Validation score: 0.209402\n",
            "Iteration 11, loss = 2.26789318\n",
            "Validation score: 0.217949\n",
            "Iteration 12, loss = 2.25216886\n",
            "Validation score: 0.235043\n",
            "Iteration 13, loss = 2.23846342\n",
            "Validation score: 0.230769\n",
            "Iteration 14, loss = 2.22652456\n",
            "Validation score: 0.226496\n",
            "Iteration 15, loss = 2.21661305\n",
            "Validation score: 0.239316\n",
            "Iteration 16, loss = 2.20651839\n",
            "Validation score: 0.222222\n",
            "Iteration 17, loss = 2.19912698\n",
            "Validation score: 0.222222\n",
            "Iteration 18, loss = 2.19240139\n",
            "Validation score: 0.230769\n",
            "Iteration 19, loss = 2.18548663\n",
            "Validation score: 0.230769\n",
            "Iteration 20, loss = 2.17912768\n",
            "Validation score: 0.226496\n",
            "Iteration 21, loss = 2.17313550\n",
            "Validation score: 0.235043\n",
            "Iteration 22, loss = 2.16729269\n",
            "Validation score: 0.239316\n",
            "Iteration 23, loss = 2.16468339\n",
            "Validation score: 0.247863\n",
            "Iteration 24, loss = 2.15887450\n",
            "Validation score: 0.243590\n",
            "Iteration 25, loss = 2.15380828\n",
            "Validation score: 0.226496\n",
            "Iteration 26, loss = 2.14946161\n",
            "Validation score: 0.252137\n",
            "Iteration 27, loss = 2.14531095\n",
            "Validation score: 0.243590\n",
            "Iteration 28, loss = 2.14054458\n",
            "Validation score: 0.252137\n",
            "Iteration 29, loss = 2.13740269\n",
            "Validation score: 0.243590\n",
            "Iteration 30, loss = 2.13273745\n",
            "Validation score: 0.243590\n",
            "Iteration 31, loss = 2.13011195\n",
            "Validation score: 0.252137\n",
            "Iteration 32, loss = 2.12812726\n",
            "Validation score: 0.247863\n",
            "Iteration 33, loss = 2.12552616\n",
            "Validation score: 0.243590\n",
            "Iteration 34, loss = 2.12216454\n",
            "Validation score: 0.247863\n",
            "Iteration 35, loss = 2.11967180\n",
            "Validation score: 0.243590\n",
            "Iteration 36, loss = 2.11623106\n",
            "Validation score: 0.252137\n",
            "Iteration 37, loss = 2.11476236\n",
            "Validation score: 0.260684\n",
            "Iteration 38, loss = 2.11126715\n",
            "Validation score: 0.239316\n",
            "Iteration 39, loss = 2.10966714\n",
            "Validation score: 0.264957\n",
            "Iteration 40, loss = 2.10755481\n",
            "Validation score: 0.256410\n",
            "Iteration 41, loss = 2.10555156\n",
            "Validation score: 0.256410\n",
            "Iteration 42, loss = 2.10381255\n",
            "Validation score: 0.252137\n",
            "Iteration 43, loss = 2.10114296\n",
            "Validation score: 0.252137\n",
            "Iteration 44, loss = 2.09866925\n",
            "Validation score: 0.260684\n",
            "Iteration 45, loss = 2.09741092\n",
            "Validation score: 0.264957\n",
            "Iteration 46, loss = 2.09457071\n",
            "Validation score: 0.243590\n",
            "Iteration 47, loss = 2.09382840\n",
            "Validation score: 0.239316\n",
            "Iteration 48, loss = 2.09203251\n",
            "Validation score: 0.252137\n",
            "Iteration 49, loss = 2.09042579\n",
            "Validation score: 0.235043\n",
            "Iteration 50, loss = 2.08991503\n",
            "Validation score: 0.252137\n",
            "Iteration 51, loss = 2.08735329\n",
            "Validation score: 0.252137\n",
            "Iteration 52, loss = 2.08656092\n",
            "Validation score: 0.264957\n",
            "Iteration 53, loss = 2.08350692\n",
            "Validation score: 0.247863\n",
            "Iteration 54, loss = 2.08287490\n",
            "Validation score: 0.264957\n",
            "Iteration 55, loss = 2.08009138\n",
            "Validation score: 0.260684\n",
            "Iteration 56, loss = 2.07978362\n",
            "Validation score: 0.247863\n",
            "Iteration 57, loss = 2.07925987\n",
            "Validation score: 0.260684\n",
            "Iteration 58, loss = 2.07741241\n",
            "Validation score: 0.235043\n",
            "Iteration 59, loss = 2.07486951\n",
            "Validation score: 0.252137\n",
            "Iteration 60, loss = 2.07310652\n",
            "Validation score: 0.256410\n",
            "Iteration 61, loss = 2.07258048\n",
            "Validation score: 0.252137\n",
            "Iteration 62, loss = 2.07116593\n",
            "Validation score: 0.256410\n",
            "Iteration 63, loss = 2.06996315\n",
            "Validation score: 0.260684\n",
            "Iteration 64, loss = 2.06770817\n",
            "Validation score: 0.252137\n",
            "Iteration 65, loss = 2.06577398\n",
            "Validation score: 0.247863\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.04836302\n",
            "Validation score: 0.136752\n",
            "Iteration 2, loss = 2.67544320\n",
            "Validation score: 0.136752\n",
            "Iteration 3, loss = 2.50009375\n",
            "Validation score: 0.115385\n",
            "Iteration 4, loss = 2.45182066\n",
            "Validation score: 0.166667\n",
            "Iteration 5, loss = 2.40939271\n",
            "Validation score: 0.170940\n",
            "Iteration 6, loss = 2.36672465\n",
            "Validation score: 0.192308\n",
            "Iteration 7, loss = 2.32909023\n",
            "Validation score: 0.196581\n",
            "Iteration 8, loss = 2.30214245\n",
            "Validation score: 0.192308\n",
            "Iteration 9, loss = 2.28064055\n",
            "Validation score: 0.205128\n",
            "Iteration 10, loss = 2.26180814\n",
            "Validation score: 0.196581\n",
            "Iteration 11, loss = 2.24820849\n",
            "Validation score: 0.200855\n",
            "Iteration 12, loss = 2.23244030\n",
            "Validation score: 0.196581\n",
            "Iteration 13, loss = 2.21929565\n",
            "Validation score: 0.183761\n",
            "Iteration 14, loss = 2.20856501\n",
            "Validation score: 0.183761\n",
            "Iteration 15, loss = 2.19822182\n",
            "Validation score: 0.188034\n",
            "Iteration 16, loss = 2.18802882\n",
            "Validation score: 0.192308\n",
            "Iteration 17, loss = 2.17996479\n",
            "Validation score: 0.183761\n",
            "Iteration 18, loss = 2.17323275\n",
            "Validation score: 0.205128\n",
            "Iteration 19, loss = 2.16554277\n",
            "Validation score: 0.196581\n",
            "Iteration 20, loss = 2.15984822\n",
            "Validation score: 0.205128\n",
            "Iteration 21, loss = 2.15374307\n",
            "Validation score: 0.222222\n",
            "Iteration 22, loss = 2.14960819\n",
            "Validation score: 0.217949\n",
            "Iteration 23, loss = 2.14339622\n",
            "Validation score: 0.230769\n",
            "Iteration 24, loss = 2.13913416\n",
            "Validation score: 0.209402\n",
            "Iteration 25, loss = 2.13550081\n",
            "Validation score: 0.217949\n",
            "Iteration 26, loss = 2.13059784\n",
            "Validation score: 0.252137\n",
            "Iteration 27, loss = 2.12725452\n",
            "Validation score: 0.230769\n",
            "Iteration 28, loss = 2.12351755\n",
            "Validation score: 0.247863\n",
            "Iteration 29, loss = 2.12070762\n",
            "Validation score: 0.230769\n",
            "Iteration 30, loss = 2.11833223\n",
            "Validation score: 0.243590\n",
            "Iteration 31, loss = 2.11402564\n",
            "Validation score: 0.243590\n",
            "Iteration 32, loss = 2.11190191\n",
            "Validation score: 0.235043\n",
            "Iteration 33, loss = 2.10952000\n",
            "Validation score: 0.235043\n",
            "Iteration 34, loss = 2.10603827\n",
            "Validation score: 0.247863\n",
            "Iteration 35, loss = 2.10216718\n",
            "Validation score: 0.230769\n",
            "Iteration 36, loss = 2.10017520\n",
            "Validation score: 0.243590\n",
            "Iteration 37, loss = 2.09881756\n",
            "Validation score: 0.226496\n",
            "Iteration 38, loss = 2.09606840\n",
            "Validation score: 0.235043\n",
            "Iteration 39, loss = 2.09277825\n",
            "Validation score: 0.235043\n",
            "Iteration 40, loss = 2.09069550\n",
            "Validation score: 0.239316\n",
            "Iteration 41, loss = 2.08899452\n",
            "Validation score: 0.247863\n",
            "Iteration 42, loss = 2.08549750\n",
            "Validation score: 0.226496\n",
            "Iteration 43, loss = 2.08376205\n",
            "Validation score: 0.252137\n",
            "Iteration 44, loss = 2.08202216\n",
            "Validation score: 0.230769\n",
            "Iteration 45, loss = 2.08096081\n",
            "Validation score: 0.239316\n",
            "Iteration 46, loss = 2.07737846\n",
            "Validation score: 0.239316\n",
            "Iteration 47, loss = 2.07637253\n",
            "Validation score: 0.239316\n",
            "Iteration 48, loss = 2.07341206\n",
            "Validation score: 0.243590\n",
            "Iteration 49, loss = 2.07207033\n",
            "Validation score: 0.247863\n",
            "Iteration 50, loss = 2.06870491\n",
            "Validation score: 0.213675\n",
            "Iteration 51, loss = 2.06699141\n",
            "Validation score: 0.222222\n",
            "Iteration 52, loss = 2.06619578\n",
            "Validation score: 0.226496\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.10309140\n",
            "Validation score: 0.153846\n",
            "Iteration 2, loss = 2.92371388\n",
            "Validation score: 0.153846\n",
            "Iteration 3, loss = 2.78843487\n",
            "Validation score: 0.153846\n",
            "Iteration 4, loss = 2.68095200\n",
            "Validation score: 0.153846\n",
            "Iteration 5, loss = 2.60650874\n",
            "Validation score: 0.153846\n",
            "Iteration 6, loss = 2.55868462\n",
            "Validation score: 0.153846\n",
            "Iteration 7, loss = 2.52630465\n",
            "Validation score: 0.153846\n",
            "Iteration 8, loss = 2.49647077\n",
            "Validation score: 0.162393\n",
            "Iteration 9, loss = 2.46242396\n",
            "Validation score: 0.183761\n",
            "Iteration 10, loss = 2.43167152\n",
            "Validation score: 0.192308\n",
            "Iteration 11, loss = 2.40827507\n",
            "Validation score: 0.192308\n",
            "Iteration 12, loss = 2.38778075\n",
            "Validation score: 0.192308\n",
            "Iteration 13, loss = 2.36524606\n",
            "Validation score: 0.192308\n",
            "Iteration 14, loss = 2.34627796\n",
            "Validation score: 0.196581\n",
            "Iteration 15, loss = 2.32844325\n",
            "Validation score: 0.192308\n",
            "Iteration 16, loss = 2.31275372\n",
            "Validation score: 0.192308\n",
            "Iteration 17, loss = 2.29827236\n",
            "Validation score: 0.217949\n",
            "Iteration 18, loss = 2.28488695\n",
            "Validation score: 0.213675\n",
            "Iteration 19, loss = 2.27302810\n",
            "Validation score: 0.213675\n",
            "Iteration 20, loss = 2.26159180\n",
            "Validation score: 0.217949\n",
            "Iteration 21, loss = 2.25231387\n",
            "Validation score: 0.209402\n",
            "Iteration 22, loss = 2.24234806\n",
            "Validation score: 0.209402\n",
            "Iteration 23, loss = 2.23441431\n",
            "Validation score: 0.213675\n",
            "Iteration 24, loss = 2.22616671\n",
            "Validation score: 0.209402\n",
            "Iteration 25, loss = 2.21868660\n",
            "Validation score: 0.209402\n",
            "Iteration 26, loss = 2.21215375\n",
            "Validation score: 0.213675\n",
            "Iteration 27, loss = 2.20546551\n",
            "Validation score: 0.217949\n",
            "Iteration 28, loss = 2.19959430\n",
            "Validation score: 0.209402\n",
            "Iteration 29, loss = 2.19441118\n",
            "Validation score: 0.222222\n",
            "Iteration 30, loss = 2.18925565\n",
            "Validation score: 0.222222\n",
            "Iteration 31, loss = 2.18401978\n",
            "Validation score: 0.226496\n",
            "Iteration 32, loss = 2.17992466\n",
            "Validation score: 0.217949\n",
            "Iteration 33, loss = 2.17486832\n",
            "Validation score: 0.217949\n",
            "Iteration 34, loss = 2.17114844\n",
            "Validation score: 0.217949\n",
            "Iteration 35, loss = 2.16779733\n",
            "Validation score: 0.217949\n",
            "Iteration 36, loss = 2.16387588\n",
            "Validation score: 0.222222\n",
            "Iteration 37, loss = 2.16026401\n",
            "Validation score: 0.213675\n",
            "Iteration 38, loss = 2.15732978\n",
            "Validation score: 0.213675\n",
            "Iteration 39, loss = 2.15498549\n",
            "Validation score: 0.213675\n",
            "Iteration 40, loss = 2.15019216\n",
            "Validation score: 0.217949\n",
            "Iteration 41, loss = 2.14775641\n",
            "Validation score: 0.213675\n",
            "Iteration 42, loss = 2.14517670\n",
            "Validation score: 0.217949\n",
            "Iteration 43, loss = 2.14199319\n",
            "Validation score: 0.226496\n",
            "Iteration 44, loss = 2.13895185\n",
            "Validation score: 0.222222\n",
            "Iteration 45, loss = 2.13654386\n",
            "Validation score: 0.226496\n",
            "Iteration 46, loss = 2.13411912\n",
            "Validation score: 0.213675\n",
            "Iteration 47, loss = 2.13149783\n",
            "Validation score: 0.213675\n",
            "Iteration 48, loss = 2.12866918\n",
            "Validation score: 0.213675\n",
            "Iteration 49, loss = 2.12704480\n",
            "Validation score: 0.213675\n",
            "Iteration 50, loss = 2.12428783\n",
            "Validation score: 0.217949\n",
            "Iteration 51, loss = 2.12285989\n",
            "Validation score: 0.217949\n",
            "Iteration 52, loss = 2.12031478\n",
            "Validation score: 0.222222\n",
            "Iteration 53, loss = 2.11788261\n",
            "Validation score: 0.222222\n",
            "Iteration 54, loss = 2.11588823\n",
            "Validation score: 0.239316\n",
            "Iteration 55, loss = 2.11456318\n",
            "Validation score: 0.217949\n",
            "Iteration 56, loss = 2.11169265\n",
            "Validation score: 0.213675\n",
            "Iteration 57, loss = 2.10991020\n",
            "Validation score: 0.235043\n",
            "Iteration 58, loss = 2.10776877\n",
            "Validation score: 0.226496\n",
            "Iteration 59, loss = 2.10627799\n",
            "Validation score: 0.222222\n",
            "Iteration 60, loss = 2.10426752\n",
            "Validation score: 0.235043\n",
            "Iteration 61, loss = 2.10245470\n",
            "Validation score: 0.222222\n",
            "Iteration 62, loss = 2.10107867\n",
            "Validation score: 0.230769\n",
            "Iteration 63, loss = 2.09891201\n",
            "Validation score: 0.239316\n",
            "Iteration 64, loss = 2.09717907\n",
            "Validation score: 0.230769\n",
            "Iteration 65, loss = 2.09561720\n",
            "Validation score: 0.226496\n",
            "Iteration 66, loss = 2.09421147\n",
            "Validation score: 0.239316\n",
            "Iteration 67, loss = 2.09208646\n",
            "Validation score: 0.230769\n",
            "Iteration 68, loss = 2.09057259\n",
            "Validation score: 0.226496\n",
            "Iteration 69, loss = 2.08942448\n",
            "Validation score: 0.230769\n",
            "Iteration 70, loss = 2.08713826\n",
            "Validation score: 0.235043\n",
            "Iteration 71, loss = 2.08575225\n",
            "Validation score: 0.239316\n",
            "Iteration 72, loss = 2.08357819\n",
            "Validation score: 0.222222\n",
            "Iteration 73, loss = 2.08292520\n",
            "Validation score: 0.230769\n",
            "Iteration 74, loss = 2.08146000\n",
            "Validation score: 0.239316\n",
            "Iteration 75, loss = 2.08002043\n",
            "Validation score: 0.230769\n",
            "Iteration 76, loss = 2.07859165\n",
            "Validation score: 0.235043\n",
            "Iteration 77, loss = 2.07626473\n",
            "Validation score: 0.230769\n",
            "Iteration 78, loss = 2.07567016\n",
            "Validation score: 0.230769\n",
            "Iteration 79, loss = 2.07398574\n",
            "Validation score: 0.235043\n",
            "Iteration 80, loss = 2.07211628\n",
            "Validation score: 0.226496\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.11116379\n",
            "Validation score: 0.162393\n",
            "Iteration 2, loss = 2.89654160\n",
            "Validation score: 0.162393\n",
            "Iteration 3, loss = 2.66966644\n",
            "Validation score: 0.166667\n",
            "Iteration 4, loss = 2.54523113\n",
            "Validation score: 0.141026\n",
            "Iteration 5, loss = 2.52436321\n",
            "Validation score: 0.166667\n",
            "Iteration 6, loss = 2.51674383\n",
            "Validation score: 0.179487\n",
            "Iteration 7, loss = 2.51141327\n",
            "Validation score: 0.145299\n",
            "Iteration 8, loss = 2.50755271\n",
            "Validation score: 0.145299\n",
            "Iteration 9, loss = 2.50251001\n",
            "Validation score: 0.145299\n",
            "Iteration 10, loss = 2.49746093\n",
            "Validation score: 0.145299\n",
            "Iteration 11, loss = 2.49156303\n",
            "Validation score: 0.145299\n",
            "Iteration 12, loss = 2.48417887\n",
            "Validation score: 0.170940\n",
            "Iteration 13, loss = 2.47628078\n",
            "Validation score: 0.166667\n",
            "Iteration 14, loss = 2.46679388\n",
            "Validation score: 0.170940\n",
            "Iteration 15, loss = 2.45424868\n",
            "Validation score: 0.175214\n",
            "Iteration 16, loss = 2.44170941\n",
            "Validation score: 0.141026\n",
            "Iteration 17, loss = 2.42765446\n",
            "Validation score: 0.149573\n",
            "Iteration 18, loss = 2.41300932\n",
            "Validation score: 0.153846\n",
            "Iteration 19, loss = 2.39903065\n",
            "Validation score: 0.153846\n",
            "Iteration 20, loss = 2.38542207\n",
            "Validation score: 0.162393\n",
            "Iteration 21, loss = 2.36975992\n",
            "Validation score: 0.166667\n",
            "Iteration 22, loss = 2.35617271\n",
            "Validation score: 0.179487\n",
            "Iteration 23, loss = 2.34143074\n",
            "Validation score: 0.175214\n",
            "Iteration 24, loss = 2.32785270\n",
            "Validation score: 0.175214\n",
            "Iteration 25, loss = 2.31580014\n",
            "Validation score: 0.170940\n",
            "Iteration 26, loss = 2.30241023\n",
            "Validation score: 0.192308\n",
            "Iteration 27, loss = 2.28966805\n",
            "Validation score: 0.188034\n",
            "Iteration 28, loss = 2.27784709\n",
            "Validation score: 0.205128\n",
            "Iteration 29, loss = 2.26786633\n",
            "Validation score: 0.213675\n",
            "Iteration 30, loss = 2.25806656\n",
            "Validation score: 0.179487\n",
            "Iteration 31, loss = 2.24778541\n",
            "Validation score: 0.183761\n",
            "Iteration 32, loss = 2.23918637\n",
            "Validation score: 0.200855\n",
            "Iteration 33, loss = 2.23098187\n",
            "Validation score: 0.205128\n",
            "Iteration 34, loss = 2.22406865\n",
            "Validation score: 0.213675\n",
            "Iteration 35, loss = 2.21560053\n",
            "Validation score: 0.222222\n",
            "Iteration 36, loss = 2.20928488\n",
            "Validation score: 0.222222\n",
            "Iteration 37, loss = 2.20305492\n",
            "Validation score: 0.235043\n",
            "Iteration 38, loss = 2.19716335\n",
            "Validation score: 0.256410\n",
            "Iteration 39, loss = 2.19041101\n",
            "Validation score: 0.226496\n",
            "Iteration 40, loss = 2.18531553\n",
            "Validation score: 0.213675\n",
            "Iteration 41, loss = 2.17949047\n",
            "Validation score: 0.260684\n",
            "Iteration 42, loss = 2.17492359\n",
            "Validation score: 0.252137\n",
            "Iteration 43, loss = 2.17050791\n",
            "Validation score: 0.226496\n",
            "Iteration 44, loss = 2.16633776\n",
            "Validation score: 0.243590\n",
            "Iteration 45, loss = 2.16141888\n",
            "Validation score: 0.239316\n",
            "Iteration 46, loss = 2.15867165\n",
            "Validation score: 0.217949\n",
            "Iteration 47, loss = 2.15367301\n",
            "Validation score: 0.235043\n",
            "Iteration 48, loss = 2.14935992\n",
            "Validation score: 0.260684\n",
            "Iteration 49, loss = 2.14548447\n",
            "Validation score: 0.247863\n",
            "Iteration 50, loss = 2.14258140\n",
            "Validation score: 0.230769\n",
            "Iteration 51, loss = 2.13976993\n",
            "Validation score: 0.256410\n",
            "Iteration 52, loss = 2.13543431\n",
            "Validation score: 0.256410\n",
            "Iteration 53, loss = 2.13336065\n",
            "Validation score: 0.260684\n",
            "Iteration 54, loss = 2.12977806\n",
            "Validation score: 0.239316\n",
            "Iteration 55, loss = 2.12502291\n",
            "Validation score: 0.264957\n",
            "Iteration 56, loss = 2.12377125\n",
            "Validation score: 0.252137\n",
            "Iteration 57, loss = 2.12016573\n",
            "Validation score: 0.260684\n",
            "Iteration 58, loss = 2.11732632\n",
            "Validation score: 0.239316\n",
            "Iteration 59, loss = 2.11318884\n",
            "Validation score: 0.260684\n",
            "Iteration 60, loss = 2.11168802\n",
            "Validation score: 0.269231\n",
            "Iteration 61, loss = 2.10872761\n",
            "Validation score: 0.264957\n",
            "Iteration 62, loss = 2.10575698\n",
            "Validation score: 0.247863\n",
            "Iteration 63, loss = 2.10334585\n",
            "Validation score: 0.239316\n",
            "Iteration 64, loss = 2.10082448\n",
            "Validation score: 0.269231\n",
            "Iteration 65, loss = 2.09875079\n",
            "Validation score: 0.247863\n",
            "Iteration 66, loss = 2.09626289\n",
            "Validation score: 0.256410\n",
            "Iteration 67, loss = 2.09374373\n",
            "Validation score: 0.247863\n",
            "Iteration 68, loss = 2.09104453\n",
            "Validation score: 0.243590\n",
            "Iteration 69, loss = 2.08781645\n",
            "Validation score: 0.260684\n",
            "Iteration 70, loss = 2.08553046\n",
            "Validation score: 0.260684\n",
            "Iteration 71, loss = 2.08314986\n",
            "Validation score: 0.282051\n",
            "Iteration 72, loss = 2.08164962\n",
            "Validation score: 0.252137\n",
            "Iteration 73, loss = 2.07873665\n",
            "Validation score: 0.256410\n",
            "Iteration 74, loss = 2.07691502\n",
            "Validation score: 0.264957\n",
            "Iteration 75, loss = 2.07355040\n",
            "Validation score: 0.264957\n",
            "Iteration 76, loss = 2.07230984\n",
            "Validation score: 0.260684\n",
            "Iteration 77, loss = 2.07041666\n",
            "Validation score: 0.264957\n",
            "Iteration 78, loss = 2.06773139\n",
            "Validation score: 0.256410\n",
            "Iteration 79, loss = 2.06569269\n",
            "Validation score: 0.282051\n",
            "Iteration 80, loss = 2.06339061\n",
            "Validation score: 0.256410\n",
            "Iteration 81, loss = 2.06193842\n",
            "Validation score: 0.269231\n",
            "Iteration 82, loss = 2.05995337\n",
            "Validation score: 0.269231\n",
            "Iteration 83, loss = 2.05705219\n",
            "Validation score: 0.273504\n",
            "Iteration 84, loss = 2.05589015\n",
            "Validation score: 0.269231\n",
            "Iteration 85, loss = 2.05401435\n",
            "Validation score: 0.277778\n",
            "Iteration 86, loss = 2.05086548\n",
            "Validation score: 0.273504\n",
            "Iteration 87, loss = 2.04959634\n",
            "Validation score: 0.273504\n",
            "Iteration 88, loss = 2.04743602\n",
            "Validation score: 0.260684\n",
            "Iteration 89, loss = 2.04509521\n",
            "Validation score: 0.260684\n",
            "Iteration 90, loss = 2.04237263\n",
            "Validation score: 0.282051\n",
            "Iteration 91, loss = 2.04115193\n",
            "Validation score: 0.269231\n",
            "Iteration 92, loss = 2.03918412\n",
            "Validation score: 0.286325\n",
            "Iteration 93, loss = 2.03836780\n",
            "Validation score: 0.269231\n",
            "Iteration 94, loss = 2.03617148\n",
            "Validation score: 0.286325\n",
            "Iteration 95, loss = 2.03344620\n",
            "Validation score: 0.294872\n",
            "Iteration 96, loss = 2.03139570\n",
            "Validation score: 0.277778\n",
            "Iteration 97, loss = 2.03053541\n",
            "Validation score: 0.286325\n",
            "Iteration 98, loss = 2.02731216\n",
            "Validation score: 0.299145\n",
            "Iteration 99, loss = 2.02632581\n",
            "Validation score: 0.282051\n",
            "Iteration 100, loss = 2.02386029\n",
            "Validation score: 0.277778\n",
            "Iteration 101, loss = 2.02239342\n",
            "Validation score: 0.282051\n",
            "Iteration 102, loss = 2.02063979\n",
            "Validation score: 0.286325\n",
            "Iteration 103, loss = 2.01823458\n",
            "Validation score: 0.294872\n",
            "Iteration 104, loss = 2.01733854\n",
            "Validation score: 0.286325\n",
            "Iteration 105, loss = 2.01525326\n",
            "Validation score: 0.290598\n",
            "Iteration 106, loss = 2.01368705\n",
            "Validation score: 0.282051\n",
            "Iteration 107, loss = 2.01202624\n",
            "Validation score: 0.282051\n",
            "Iteration 108, loss = 2.01050954\n",
            "Validation score: 0.286325\n",
            "Iteration 109, loss = 2.00935941\n",
            "Validation score: 0.286325\n",
            "Iteration 110, loss = 2.00766540\n",
            "Validation score: 0.294872\n",
            "Iteration 111, loss = 2.00523890\n",
            "Validation score: 0.273504\n",
            "Iteration 112, loss = 2.00335326\n",
            "Validation score: 0.277778\n",
            "Iteration 113, loss = 2.00322591\n",
            "Validation score: 0.290598\n",
            "Iteration 114, loss = 2.00125440\n",
            "Validation score: 0.311966\n",
            "Iteration 115, loss = 1.99890366\n",
            "Validation score: 0.277778\n",
            "Iteration 116, loss = 1.99791640\n",
            "Validation score: 0.269231\n",
            "Iteration 117, loss = 1.99701659\n",
            "Validation score: 0.294872\n",
            "Iteration 118, loss = 1.99498684\n",
            "Validation score: 0.290598\n",
            "Iteration 119, loss = 1.99464772\n",
            "Validation score: 0.264957\n",
            "Iteration 120, loss = 1.99382784\n",
            "Validation score: 0.311966\n",
            "Iteration 121, loss = 1.99075612\n",
            "Validation score: 0.282051\n",
            "Iteration 122, loss = 1.99088831\n",
            "Validation score: 0.307692\n",
            "Iteration 123, loss = 1.98917171\n",
            "Validation score: 0.311966\n",
            "Iteration 124, loss = 1.98742257\n",
            "Validation score: 0.316239\n",
            "Iteration 125, loss = 1.98709467\n",
            "Validation score: 0.269231\n",
            "Iteration 126, loss = 1.98516637\n",
            "Validation score: 0.311966\n",
            "Iteration 127, loss = 1.98347611\n",
            "Validation score: 0.311966\n",
            "Iteration 128, loss = 1.98412397\n",
            "Validation score: 0.320513\n",
            "Iteration 129, loss = 1.98208234\n",
            "Validation score: 0.299145\n",
            "Iteration 130, loss = 1.98176078\n",
            "Validation score: 0.294872\n",
            "Iteration 131, loss = 1.97988146\n",
            "Validation score: 0.316239\n",
            "Iteration 132, loss = 1.97918541\n",
            "Validation score: 0.307692\n",
            "Iteration 133, loss = 1.97771230\n",
            "Validation score: 0.307692\n",
            "Iteration 134, loss = 1.97767258\n",
            "Validation score: 0.307692\n",
            "Iteration 135, loss = 1.97708185\n",
            "Validation score: 0.337607\n",
            "Iteration 136, loss = 1.97553807\n",
            "Validation score: 0.311966\n",
            "Iteration 137, loss = 1.97538051\n",
            "Validation score: 0.320513\n",
            "Iteration 138, loss = 1.97480845\n",
            "Validation score: 0.307692\n",
            "Iteration 139, loss = 1.97447503\n",
            "Validation score: 0.299145\n",
            "Iteration 140, loss = 1.97291493\n",
            "Validation score: 0.290598\n",
            "Iteration 141, loss = 1.97000359\n",
            "Validation score: 0.320513\n",
            "Iteration 142, loss = 1.97218437\n",
            "Validation score: 0.311966\n",
            "Iteration 143, loss = 1.97118477\n",
            "Validation score: 0.324786\n",
            "Iteration 144, loss = 1.97014745\n",
            "Validation score: 0.316239\n",
            "Iteration 145, loss = 1.97031537\n",
            "Validation score: 0.324786\n",
            "Iteration 146, loss = 1.96968949\n",
            "Validation score: 0.307692\n",
            "Iteration 147, loss = 1.96872439\n",
            "Validation score: 0.316239\n",
            "Iteration 148, loss = 1.96685817\n",
            "Validation score: 0.316239\n",
            "Iteration 149, loss = 1.96857538\n",
            "Validation score: 0.299145\n",
            "Iteration 150, loss = 1.96654766\n",
            "Validation score: 0.307692\n",
            "Iteration 151, loss = 1.96688209\n",
            "Validation score: 0.320513\n",
            "Iteration 152, loss = 1.96558307\n",
            "Validation score: 0.329060\n",
            "Iteration 153, loss = 1.96533215\n",
            "Validation score: 0.324786\n",
            "Iteration 154, loss = 1.96624265\n",
            "Validation score: 0.329060\n",
            "Iteration 155, loss = 1.96419518\n",
            "Validation score: 0.316239\n",
            "Iteration 156, loss = 1.96536670\n",
            "Validation score: 0.320513\n",
            "Iteration 157, loss = 1.96324328\n",
            "Validation score: 0.307692\n",
            "Iteration 158, loss = 1.96384047\n",
            "Validation score: 0.341880\n",
            "Iteration 159, loss = 1.96157744\n",
            "Validation score: 0.273504\n",
            "Iteration 160, loss = 1.96321079\n",
            "Validation score: 0.311966\n",
            "Iteration 161, loss = 1.96256078\n",
            "Validation score: 0.329060\n",
            "Iteration 162, loss = 1.96057568\n",
            "Validation score: 0.307692\n",
            "Iteration 163, loss = 1.96132273\n",
            "Validation score: 0.329060\n",
            "Iteration 164, loss = 1.96211104\n",
            "Validation score: 0.333333\n",
            "Iteration 165, loss = 1.96132062\n",
            "Validation score: 0.337607\n",
            "Iteration 166, loss = 1.96108672\n",
            "Validation score: 0.333333\n",
            "Iteration 167, loss = 1.96142527\n",
            "Validation score: 0.320513\n",
            "Iteration 168, loss = 1.96038746\n",
            "Validation score: 0.316239\n",
            "Iteration 169, loss = 1.96150549\n",
            "Validation score: 0.324786\n",
            "Iteration 170, loss = 1.96011656\n",
            "Validation score: 0.320513\n",
            "Iteration 171, loss = 1.95821799\n",
            "Validation score: 0.324786\n",
            "Iteration 172, loss = 1.96067515\n",
            "Validation score: 0.337607\n",
            "Iteration 173, loss = 1.95930627\n",
            "Validation score: 0.316239\n",
            "Iteration 174, loss = 1.96029089\n",
            "Validation score: 0.303419\n",
            "Iteration 175, loss = 1.95767625\n",
            "Validation score: 0.299145\n",
            "Iteration 176, loss = 1.95922301\n",
            "Validation score: 0.341880\n",
            "Iteration 177, loss = 1.95885179\n",
            "Validation score: 0.329060\n",
            "Iteration 178, loss = 1.95846999\n",
            "Validation score: 0.329060\n",
            "Iteration 179, loss = 1.95787379\n",
            "Validation score: 0.329060\n",
            "Iteration 180, loss = 1.95761113\n",
            "Validation score: 0.329060\n",
            "Iteration 181, loss = 1.95808272\n",
            "Validation score: 0.350427\n",
            "Iteration 182, loss = 1.95743921\n",
            "Validation score: 0.337607\n",
            "Iteration 183, loss = 1.95724951\n",
            "Validation score: 0.324786\n",
            "Iteration 184, loss = 1.95763567\n",
            "Validation score: 0.307692\n",
            "Iteration 185, loss = 1.95727907\n",
            "Validation score: 0.329060\n",
            "Iteration 186, loss = 1.95658624\n",
            "Validation score: 0.337607\n",
            "Iteration 187, loss = 1.95836930\n",
            "Validation score: 0.337607\n",
            "Iteration 188, loss = 1.95522657\n",
            "Validation score: 0.346154\n",
            "Iteration 189, loss = 1.95582814\n",
            "Validation score: 0.337607\n",
            "Iteration 190, loss = 1.95726540\n",
            "Validation score: 0.307692\n",
            "Iteration 191, loss = 1.95570390\n",
            "Validation score: 0.324786\n",
            "Iteration 192, loss = 1.95691228\n",
            "Validation score: 0.333333\n",
            "Iteration 193, loss = 1.95571801\n",
            "Validation score: 0.346154\n",
            "Iteration 194, loss = 1.95693110\n",
            "Validation score: 0.320513\n",
            "Iteration 195, loss = 1.95694950\n",
            "Validation score: 0.350427\n",
            "Iteration 196, loss = 1.95598040\n",
            "Validation score: 0.329060\n",
            "Iteration 197, loss = 1.95591231\n",
            "Validation score: 0.324786\n",
            "Iteration 198, loss = 1.95521513\n",
            "Validation score: 0.311966\n",
            "Iteration 199, loss = 1.95430159\n",
            "Validation score: 0.333333\n",
            "Iteration 200, loss = 1.95632270\n",
            "Validation score: 0.320513\n",
            "Iteration 1, loss = 3.21457346\n",
            "Validation score: 0.115385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "Validation score: 0.243590\n",
            "Iteration 70, loss = 2.15108949\n",
            "Validation score: 0.235043\n",
            "Iteration 71, loss = 2.14868169\n",
            "Validation score: 0.247863\n",
            "Iteration 72, loss = 2.14713611\n",
            "Validation score: 0.247863\n",
            "Iteration 73, loss = 2.14373433\n",
            "Validation score: 0.239316\n",
            "Iteration 74, loss = 2.14189827\n",
            "Validation score: 0.239316\n",
            "Iteration 75, loss = 2.14044429\n",
            "Validation score: 0.235043\n",
            "Iteration 76, loss = 2.13861474\n",
            "Validation score: 0.230769\n",
            "Iteration 77, loss = 2.13608020\n",
            "Validation score: 0.247863\n",
            "Iteration 78, loss = 2.13478029\n",
            "Validation score: 0.239316\n",
            "Iteration 79, loss = 2.13294972\n",
            "Validation score: 0.235043\n",
            "Iteration 80, loss = 2.13168789\n",
            "Validation score: 0.239316\n",
            "Iteration 81, loss = 2.13033273\n",
            "Validation score: 0.239316\n",
            "Iteration 82, loss = 2.12868104\n",
            "Validation score: 0.239316\n",
            "Iteration 83, loss = 2.12688660\n",
            "Validation score: 0.239316\n",
            "Iteration 84, loss = 2.12510769\n",
            "Validation score: 0.239316\n",
            "Iteration 85, loss = 2.12366771\n",
            "Validation score: 0.235043\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.07344660\n",
            "Validation score: 0.183761\n",
            "Iteration 2, loss = 2.99149027\n",
            "Validation score: 0.183761\n",
            "Iteration 3, loss = 2.92001041\n",
            "Validation score: 0.183761\n",
            "Iteration 4, loss = 2.85788787\n",
            "Validation score: 0.183761\n",
            "Iteration 5, loss = 2.80444147\n",
            "Validation score: 0.183761\n",
            "Iteration 6, loss = 2.75869470\n",
            "Validation score: 0.183761\n",
            "Iteration 7, loss = 2.71982973\n",
            "Validation score: 0.183761\n",
            "Iteration 8, loss = 2.68693989\n",
            "Validation score: 0.183761\n",
            "Iteration 9, loss = 2.65897046\n",
            "Validation score: 0.183761\n",
            "Iteration 10, loss = 2.63561959\n",
            "Validation score: 0.183761\n",
            "Iteration 11, loss = 2.61611753\n",
            "Validation score: 0.183761\n",
            "Iteration 12, loss = 2.59970439\n",
            "Validation score: 0.183761\n",
            "Iteration 13, loss = 2.58579785\n",
            "Validation score: 0.183761\n",
            "Iteration 14, loss = 2.57409101\n",
            "Validation score: 0.183761\n",
            "Iteration 15, loss = 2.56426621\n",
            "Validation score: 0.183761\n",
            "Iteration 16, loss = 2.55591535\n",
            "Validation score: 0.183761\n",
            "Iteration 17, loss = 2.54878799\n",
            "Validation score: 0.089744\n",
            "Iteration 18, loss = 2.54278789\n",
            "Validation score: 0.089744\n",
            "Iteration 19, loss = 2.53768533\n",
            "Validation score: 0.089744\n",
            "Iteration 20, loss = 2.53324393\n",
            "Validation score: 0.089744\n",
            "Iteration 21, loss = 2.52940981\n",
            "Validation score: 0.089744\n",
            "Iteration 22, loss = 2.52612559\n",
            "Validation score: 0.089744\n",
            "Iteration 23, loss = 2.52327048\n",
            "Validation score: 0.089744\n",
            "Iteration 24, loss = 2.52080855\n",
            "Validation score: 0.089744\n",
            "Iteration 25, loss = 2.51866684\n",
            "Validation score: 0.089744\n",
            "Iteration 26, loss = 2.51666687\n",
            "Validation score: 0.089744\n",
            "Iteration 27, loss = 2.51489605\n",
            "Validation score: 0.089744\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.09010506\n",
            "Validation score: 0.170940\n",
            "Iteration 2, loss = 3.00858360\n",
            "Validation score: 0.170940\n",
            "Iteration 3, loss = 2.93757654\n",
            "Validation score: 0.170940\n",
            "Iteration 4, loss = 2.87657069\n",
            "Validation score: 0.170940\n",
            "Iteration 5, loss = 2.82425257\n",
            "Validation score: 0.149573\n",
            "Iteration 6, loss = 2.77983694\n",
            "Validation score: 0.149573\n",
            "Iteration 7, loss = 2.74181652\n",
            "Validation score: 0.149573\n",
            "Iteration 8, loss = 2.70950493\n",
            "Validation score: 0.149573\n",
            "Iteration 9, loss = 2.68205164\n",
            "Validation score: 0.149573\n",
            "Iteration 10, loss = 2.65893220\n",
            "Validation score: 0.149573\n",
            "Iteration 11, loss = 2.63912618\n",
            "Validation score: 0.149573\n",
            "Iteration 12, loss = 2.62243002\n",
            "Validation score: 0.149573\n",
            "Iteration 13, loss = 2.60816374\n",
            "Validation score: 0.149573\n",
            "Iteration 14, loss = 2.59603724\n",
            "Validation score: 0.149573\n",
            "Iteration 15, loss = 2.58576898\n",
            "Validation score: 0.149573\n",
            "Iteration 16, loss = 2.57705464\n",
            "Validation score: 0.149573\n",
            "Iteration 17, loss = 2.56944788\n",
            "Validation score: 0.149573\n",
            "Iteration 18, loss = 2.56320334\n",
            "Validation score: 0.149573\n",
            "Iteration 19, loss = 2.55764849\n",
            "Validation score: 0.149573\n",
            "Iteration 20, loss = 2.55295656\n",
            "Validation score: 0.149573\n",
            "Iteration 21, loss = 2.54886893\n",
            "Validation score: 0.149573\n",
            "Iteration 22, loss = 2.54539185\n",
            "Validation score: 0.149573\n",
            "Iteration 23, loss = 2.54233720\n",
            "Validation score: 0.149573\n",
            "Iteration 24, loss = 2.53977281\n",
            "Validation score: 0.149573\n",
            "Iteration 25, loss = 2.53741247\n",
            "Validation score: 0.149573\n",
            "Iteration 26, loss = 2.53537521\n",
            "Validation score: 0.149573\n",
            "Iteration 27, loss = 2.53367284\n",
            "Validation score: 0.149573\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.22906019\n",
            "Validation score: 0.025641\n",
            "Iteration 2, loss = 2.91923559\n",
            "Validation score: 0.141026\n",
            "Iteration 3, loss = 2.64440064\n",
            "Validation score: 0.141026\n",
            "Iteration 4, loss = 2.55358267\n",
            "Validation score: 0.149573\n",
            "Iteration 5, loss = 2.52161871\n",
            "Validation score: 0.162393\n",
            "Iteration 6, loss = 2.50775649\n",
            "Validation score: 0.145299\n",
            "Iteration 7, loss = 2.49999438\n",
            "Validation score: 0.145299\n",
            "Iteration 8, loss = 2.49423020\n",
            "Validation score: 0.149573\n",
            "Iteration 9, loss = 2.48947236\n",
            "Validation score: 0.166667\n",
            "Iteration 10, loss = 2.48513218\n",
            "Validation score: 0.145299\n",
            "Iteration 11, loss = 2.47959504\n",
            "Validation score: 0.145299\n",
            "Iteration 12, loss = 2.47427095\n",
            "Validation score: 0.170940\n",
            "Iteration 13, loss = 2.46846461\n",
            "Validation score: 0.145299\n",
            "Iteration 14, loss = 2.46222998\n",
            "Validation score: 0.158120\n",
            "Iteration 15, loss = 2.45549385\n",
            "Validation score: 0.183761\n",
            "Iteration 16, loss = 2.44852984\n",
            "Validation score: 0.162393\n",
            "Iteration 17, loss = 2.44080939\n",
            "Validation score: 0.192308\n",
            "Iteration 18, loss = 2.43322574\n",
            "Validation score: 0.217949\n",
            "Iteration 19, loss = 2.42538489\n",
            "Validation score: 0.217949\n",
            "Iteration 20, loss = 2.41864462\n",
            "Validation score: 0.217949\n",
            "Iteration 21, loss = 2.41170943\n",
            "Validation score: 0.222222\n",
            "Iteration 22, loss = 2.40325898\n",
            "Validation score: 0.175214\n",
            "Iteration 23, loss = 2.39571511\n",
            "Validation score: 0.222222\n",
            "Iteration 24, loss = 2.38889891\n",
            "Validation score: 0.222222\n",
            "Iteration 25, loss = 2.38199978\n",
            "Validation score: 0.226496\n",
            "Iteration 26, loss = 2.37591603\n",
            "Validation score: 0.226496\n",
            "Iteration 27, loss = 2.36851351\n",
            "Validation score: 0.230769\n",
            "Iteration 28, loss = 2.36182634\n",
            "Validation score: 0.235043\n",
            "Iteration 29, loss = 2.35581755\n",
            "Validation score: 0.235043\n",
            "Iteration 30, loss = 2.35033536\n",
            "Validation score: 0.243590\n",
            "Iteration 31, loss = 2.34452684\n",
            "Validation score: 0.252137\n",
            "Iteration 32, loss = 2.33918565\n",
            "Validation score: 0.247863\n",
            "Iteration 33, loss = 2.33327917\n",
            "Validation score: 0.243590\n",
            "Iteration 34, loss = 2.32832046\n",
            "Validation score: 0.247863\n",
            "Iteration 35, loss = 2.32296721\n",
            "Validation score: 0.252137\n",
            "Iteration 36, loss = 2.31854509\n",
            "Validation score: 0.252137\n",
            "Iteration 37, loss = 2.31439983\n",
            "Validation score: 0.247863\n",
            "Iteration 38, loss = 2.30994303\n",
            "Validation score: 0.247863\n",
            "Iteration 39, loss = 2.30518627\n",
            "Validation score: 0.239316\n",
            "Iteration 40, loss = 2.30148335\n",
            "Validation score: 0.247863\n",
            "Iteration 41, loss = 2.29721365\n",
            "Validation score: 0.256410\n",
            "Iteration 42, loss = 2.29344369\n",
            "Validation score: 0.243590\n",
            "Iteration 43, loss = 2.28981390\n",
            "Validation score: 0.256410\n",
            "Iteration 44, loss = 2.28665600\n",
            "Validation score: 0.264957\n",
            "Iteration 45, loss = 2.28283863\n",
            "Validation score: 0.260684\n",
            "Iteration 46, loss = 2.27974941\n",
            "Validation score: 0.256410\n",
            "Iteration 47, loss = 2.27654251\n",
            "Validation score: 0.243590\n",
            "Iteration 48, loss = 2.27450424\n",
            "Validation score: 0.264957\n",
            "Iteration 49, loss = 2.27139871\n",
            "Validation score: 0.252137\n",
            "Iteration 50, loss = 2.26839009\n",
            "Validation score: 0.260684\n",
            "Iteration 51, loss = 2.26682178\n",
            "Validation score: 0.247863\n",
            "Iteration 52, loss = 2.26411169\n",
            "Validation score: 0.256410\n",
            "Iteration 53, loss = 2.26192705\n",
            "Validation score: 0.256410\n",
            "Iteration 54, loss = 2.25988341\n",
            "Validation score: 0.256410\n",
            "Iteration 55, loss = 2.25743737\n",
            "Validation score: 0.256410\n",
            "Iteration 56, loss = 2.25517542\n",
            "Validation score: 0.247863\n",
            "Iteration 57, loss = 2.25305873\n",
            "Validation score: 0.247863\n",
            "Iteration 58, loss = 2.25228800\n",
            "Validation score: 0.247863\n",
            "Iteration 59, loss = 2.25020663\n",
            "Validation score: 0.256410\n",
            "Iteration 60, loss = 2.24790143\n",
            "Validation score: 0.252137\n",
            "Iteration 61, loss = 2.24651979\n",
            "Validation score: 0.243590\n",
            "Iteration 62, loss = 2.24472482\n",
            "Validation score: 0.260684\n",
            "Iteration 63, loss = 2.24229612\n",
            "Validation score: 0.264957\n",
            "Iteration 64, loss = 2.22470724\n",
            "Validation score: 0.256410\n",
            "Iteration 65, loss = 2.20167616\n",
            "Validation score: 0.256410\n",
            "Iteration 66, loss = 2.18520096\n",
            "Validation score: 0.282051\n",
            "Iteration 67, loss = 2.17354970\n",
            "Validation score: 0.277778\n",
            "Iteration 68, loss = 2.16667165\n",
            "Validation score: 0.277778\n",
            "Iteration 69, loss = 2.15920292\n",
            "Validation score: 0.277778\n",
            "Iteration 70, loss = 2.15304601\n",
            "Validation score: 0.286325\n",
            "Iteration 71, loss = 2.14800528\n",
            "Validation score: 0.277778\n",
            "Iteration 72, loss = 2.14321827\n",
            "Validation score: 0.273504\n",
            "Iteration 73, loss = 2.13901733\n",
            "Validation score: 0.286325\n",
            "Iteration 74, loss = 2.13455742\n",
            "Validation score: 0.277778\n",
            "Iteration 75, loss = 2.13191990\n",
            "Validation score: 0.277778\n",
            "Iteration 76, loss = 2.12884707\n",
            "Validation score: 0.277778\n",
            "Iteration 77, loss = 2.12523498\n",
            "Validation score: 0.269231\n",
            "Iteration 78, loss = 2.12269959\n",
            "Validation score: 0.303419\n",
            "Iteration 79, loss = 2.11964702\n",
            "Validation score: 0.264957\n",
            "Iteration 80, loss = 2.11625170\n",
            "Validation score: 0.307692\n",
            "Iteration 81, loss = 2.11436818\n",
            "Validation score: 0.299145\n",
            "Iteration 82, loss = 2.11258996\n",
            "Validation score: 0.286325\n",
            "Iteration 83, loss = 2.10961808\n",
            "Validation score: 0.269231\n",
            "Iteration 84, loss = 2.10818341\n",
            "Validation score: 0.290598\n",
            "Iteration 85, loss = 2.10544593\n",
            "Validation score: 0.273504\n",
            "Iteration 86, loss = 2.10515048\n",
            "Validation score: 0.299145\n",
            "Iteration 87, loss = 2.10201785\n",
            "Validation score: 0.273504\n",
            "Iteration 88, loss = 2.10016670\n",
            "Validation score: 0.290598\n",
            "Iteration 89, loss = 2.09917657\n",
            "Validation score: 0.290598\n",
            "Iteration 90, loss = 2.09681810\n",
            "Validation score: 0.282051\n",
            "Iteration 91, loss = 2.09570560\n",
            "Validation score: 0.269231\n",
            "Iteration 92, loss = 2.09409669\n",
            "Validation score: 0.277778\n",
            "Iteration 93, loss = 2.09135570\n",
            "Validation score: 0.290598\n",
            "Iteration 94, loss = 2.08979250\n",
            "Validation score: 0.290598\n",
            "Iteration 95, loss = 2.08790217\n",
            "Validation score: 0.273504\n",
            "Iteration 96, loss = 2.08570761\n",
            "Validation score: 0.277778\n",
            "Iteration 97, loss = 2.08560664\n",
            "Validation score: 0.282051\n",
            "Iteration 98, loss = 2.08397400\n",
            "Validation score: 0.299145\n",
            "Iteration 99, loss = 2.08113420\n",
            "Validation score: 0.286325\n",
            "Iteration 100, loss = 2.08039257\n",
            "Validation score: 0.282051\n",
            "Iteration 101, loss = 2.07685648\n",
            "Validation score: 0.294872\n",
            "Iteration 102, loss = 2.07642684\n",
            "Validation score: 0.290598\n",
            "Iteration 103, loss = 2.07455005\n",
            "Validation score: 0.299145\n",
            "Iteration 104, loss = 2.07253557\n",
            "Validation score: 0.290598\n",
            "Iteration 105, loss = 2.07015019\n",
            "Validation score: 0.269231\n",
            "Iteration 106, loss = 2.07007184\n",
            "Validation score: 0.277778\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.16736275\n",
            "Validation score: 0.102564\n",
            "Iteration 2, loss = 2.94583783\n",
            "Validation score: 0.170940\n",
            "Iteration 3, loss = 2.71480620\n",
            "Validation score: 0.170940\n",
            "Iteration 4, loss = 2.58993139\n",
            "Validation score: 0.170940\n",
            "Iteration 5, loss = 2.54686465\n",
            "Validation score: 0.179487\n",
            "Iteration 6, loss = 2.53021401\n",
            "Validation score: 0.239316\n",
            "Iteration 7, loss = 2.52112792\n",
            "Validation score: 0.217949\n",
            "Iteration 8, loss = 2.51526779\n",
            "Validation score: 0.196581\n",
            "Iteration 9, loss = 2.51085706\n",
            "Validation score: 0.196581\n",
            "Iteration 10, loss = 2.50796316\n",
            "Validation score: 0.200855\n",
            "Iteration 11, loss = 2.50560307\n",
            "Validation score: 0.209402\n",
            "Iteration 12, loss = 2.50245916\n",
            "Validation score: 0.209402\n",
            "Iteration 13, loss = 2.50071186\n",
            "Validation score: 0.213675\n",
            "Iteration 14, loss = 2.49789487\n",
            "Validation score: 0.209402\n",
            "Iteration 15, loss = 2.49536374\n",
            "Validation score: 0.200855\n",
            "Iteration 16, loss = 2.49308254\n",
            "Validation score: 0.217949\n",
            "Iteration 17, loss = 2.49055791\n",
            "Validation score: 0.213675\n",
            "Iteration 18, loss = 2.48753492\n",
            "Validation score: 0.205128\n",
            "Iteration 19, loss = 2.48374453\n",
            "Validation score: 0.196581\n",
            "Iteration 20, loss = 2.48078657\n",
            "Validation score: 0.205128\n",
            "Iteration 21, loss = 2.47743768\n",
            "Validation score: 0.200855\n",
            "Iteration 22, loss = 2.47357802\n",
            "Validation score: 0.192308\n",
            "Iteration 23, loss = 2.46964587\n",
            "Validation score: 0.196581\n",
            "Iteration 24, loss = 2.46515525\n",
            "Validation score: 0.196581\n",
            "Iteration 25, loss = 2.46141491\n",
            "Validation score: 0.196581\n",
            "Iteration 26, loss = 2.45687071\n",
            "Validation score: 0.192308\n",
            "Iteration 27, loss = 2.45113098\n",
            "Validation score: 0.188034\n",
            "Iteration 28, loss = 2.44614490\n",
            "Validation score: 0.188034\n",
            "Iteration 29, loss = 2.44121331\n",
            "Validation score: 0.196581\n",
            "Iteration 30, loss = 2.43556030\n",
            "Validation score: 0.188034\n",
            "Iteration 31, loss = 2.43038465\n",
            "Validation score: 0.192308\n",
            "Iteration 32, loss = 2.42491437\n",
            "Validation score: 0.196581\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.21514341\n",
            "Validation score: 0.111111\n",
            "Iteration 2, loss = 3.00734086\n",
            "Validation score: 0.076923\n",
            "Iteration 3, loss = 2.70826408\n",
            "Validation score: 0.111111\n",
            "Iteration 4, loss = 2.58438233\n",
            "Validation score: 0.128205\n",
            "Iteration 5, loss = 2.53208511\n",
            "Validation score: 0.141026\n",
            "Iteration 6, loss = 2.50850143\n",
            "Validation score: 0.132479\n",
            "Iteration 7, loss = 2.49488649\n",
            "Validation score: 0.153846\n",
            "Iteration 8, loss = 2.48461807\n",
            "Validation score: 0.141026\n",
            "Iteration 9, loss = 2.47618040\n",
            "Validation score: 0.158120\n",
            "Iteration 10, loss = 2.46843136\n",
            "Validation score: 0.158120\n",
            "Iteration 11, loss = 2.45942827\n",
            "Validation score: 0.128205\n",
            "Iteration 12, loss = 2.45052018\n",
            "Validation score: 0.132479\n",
            "Iteration 13, loss = 2.44224026\n",
            "Validation score: 0.153846\n",
            "Iteration 14, loss = 2.43354425\n",
            "Validation score: 0.179487\n",
            "Iteration 15, loss = 2.42537379\n",
            "Validation score: 0.179487\n",
            "Iteration 16, loss = 2.41706480\n",
            "Validation score: 0.179487\n",
            "Iteration 17, loss = 2.40892199\n",
            "Validation score: 0.209402\n",
            "Iteration 18, loss = 2.40062228\n",
            "Validation score: 0.205128\n",
            "Iteration 19, loss = 2.39313013\n",
            "Validation score: 0.200855\n",
            "Iteration 20, loss = 2.38522457\n",
            "Validation score: 0.205128\n",
            "Iteration 21, loss = 2.37795920\n",
            "Validation score: 0.256410\n",
            "Iteration 22, loss = 2.37089992\n",
            "Validation score: 0.256410\n",
            "Iteration 23, loss = 2.36284232\n",
            "Validation score: 0.269231\n",
            "Iteration 24, loss = 2.35647119\n",
            "Validation score: 0.277778\n",
            "Iteration 25, loss = 2.35017710\n",
            "Validation score: 0.277778\n",
            "Iteration 26, loss = 2.34354607\n",
            "Validation score: 0.273504\n",
            "Iteration 27, loss = 2.33773530\n",
            "Validation score: 0.277778\n",
            "Iteration 28, loss = 2.33179483\n",
            "Validation score: 0.273504\n",
            "Iteration 29, loss = 2.32623309\n",
            "Validation score: 0.192308\n",
            "Iteration 30, loss = 2.31995385\n",
            "Validation score: 0.269231\n",
            "Iteration 31, loss = 2.31494609\n",
            "Validation score: 0.282051\n",
            "Iteration 32, loss = 2.31008088\n",
            "Validation score: 0.282051\n",
            "Iteration 33, loss = 2.30488340\n",
            "Validation score: 0.282051\n",
            "Iteration 34, loss = 2.30022468\n",
            "Validation score: 0.286325\n",
            "Iteration 35, loss = 2.29546024\n",
            "Validation score: 0.273504\n",
            "Iteration 36, loss = 2.29109674\n",
            "Validation score: 0.269231\n",
            "Iteration 37, loss = 2.28700272\n",
            "Validation score: 0.277778\n",
            "Iteration 38, loss = 2.28282427\n",
            "Validation score: 0.282051\n",
            "Iteration 39, loss = 2.27933030\n",
            "Validation score: 0.282051\n",
            "Iteration 40, loss = 2.27560900\n",
            "Validation score: 0.277778\n",
            "Iteration 41, loss = 2.27212566\n",
            "Validation score: 0.260684\n",
            "Iteration 42, loss = 2.26907231\n",
            "Validation score: 0.277778\n",
            "Iteration 43, loss = 2.26576741\n",
            "Validation score: 0.273504\n",
            "Iteration 44, loss = 2.26258077\n",
            "Validation score: 0.286325\n",
            "Iteration 45, loss = 2.25911004\n",
            "Validation score: 0.277778\n",
            "Iteration 46, loss = 2.25685516\n",
            "Validation score: 0.277778\n",
            "Iteration 47, loss = 2.25379933\n",
            "Validation score: 0.286325\n",
            "Iteration 48, loss = 2.25118921\n",
            "Validation score: 0.260684\n",
            "Iteration 49, loss = 2.24878156\n",
            "Validation score: 0.260684\n",
            "Iteration 50, loss = 2.24642041\n",
            "Validation score: 0.282051\n",
            "Iteration 51, loss = 2.24373971\n",
            "Validation score: 0.269231\n",
            "Iteration 52, loss = 2.24193794\n",
            "Validation score: 0.252137\n",
            "Iteration 53, loss = 2.23990877\n",
            "Validation score: 0.256410\n",
            "Iteration 54, loss = 2.23760777\n",
            "Validation score: 0.256410\n",
            "Iteration 55, loss = 2.23562346\n",
            "Validation score: 0.256410\n",
            "Iteration 56, loss = 2.23422426\n",
            "Validation score: 0.269231\n",
            "Iteration 57, loss = 2.23150425\n",
            "Validation score: 0.269231\n",
            "Iteration 58, loss = 2.22986184\n",
            "Validation score: 0.260684\n",
            "Iteration 59, loss = 2.22803261\n",
            "Validation score: 0.260684\n",
            "Iteration 60, loss = 2.22592281\n",
            "Validation score: 0.273504\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.07507088\n",
            "Validation score: 0.081197\n",
            "Iteration 2, loss = 2.99086726\n",
            "Validation score: 0.076923\n",
            "Iteration 3, loss = 2.91812374\n",
            "Validation score: 0.076923\n",
            "Iteration 4, loss = 2.85605999\n",
            "Validation score: 0.076923\n",
            "Iteration 5, loss = 2.80361227\n",
            "Validation score: 0.076923\n",
            "Iteration 6, loss = 2.75914069\n",
            "Validation score: 0.076923\n",
            "Iteration 7, loss = 2.72189365\n",
            "Validation score: 0.076923\n",
            "Iteration 8, loss = 2.69051551\n",
            "Validation score: 0.076923\n",
            "Iteration 9, loss = 2.66441801\n",
            "Validation score: 0.076923\n",
            "Iteration 10, loss = 2.64247565\n",
            "Validation score: 0.076923\n",
            "Iteration 11, loss = 2.62399602\n",
            "Validation score: 0.076923\n",
            "Iteration 12, loss = 2.60873896\n",
            "Validation score: 0.076923\n",
            "Iteration 13, loss = 2.59575273\n",
            "Validation score: 0.158120\n",
            "Iteration 14, loss = 2.58487614\n",
            "Validation score: 0.158120\n",
            "Iteration 15, loss = 2.57568066\n",
            "Validation score: 0.158120\n",
            "Iteration 16, loss = 2.56778213\n",
            "Validation score: 0.158120\n",
            "Iteration 17, loss = 2.56107307\n",
            "Validation score: 0.158120\n",
            "Iteration 18, loss = 2.55536852\n",
            "Validation score: 0.158120\n",
            "Iteration 19, loss = 2.55042929\n",
            "Validation score: 0.158120\n",
            "Iteration 20, loss = 2.54611298\n",
            "Validation score: 0.158120\n",
            "Iteration 21, loss = 2.54245532\n",
            "Validation score: 0.158120\n",
            "Iteration 22, loss = 2.53925033\n",
            "Validation score: 0.158120\n",
            "Iteration 23, loss = 2.53642981\n",
            "Validation score: 0.158120\n",
            "Iteration 24, loss = 2.53390077\n",
            "Validation score: 0.158120\n",
            "Iteration 25, loss = 2.53184135\n",
            "Validation score: 0.158120\n",
            "Iteration 26, loss = 2.52983039\n",
            "Validation score: 0.158120\n",
            "Iteration 27, loss = 2.52812631\n",
            "Validation score: 0.158120\n",
            "Iteration 28, loss = 2.52661282\n",
            "Validation score: 0.158120\n",
            "Iteration 29, loss = 2.52529884\n",
            "Validation score: 0.158120\n",
            "Iteration 30, loss = 2.52406785\n",
            "Validation score: 0.158120\n",
            "Iteration 31, loss = 2.52294485\n",
            "Validation score: 0.158120\n",
            "Iteration 32, loss = 2.52211800\n",
            "Validation score: 0.158120\n",
            "Iteration 33, loss = 2.52119606\n",
            "Validation score: 0.158120\n",
            "Iteration 34, loss = 2.52035071\n",
            "Validation score: 0.158120\n",
            "Iteration 35, loss = 2.51966012\n",
            "Validation score: 0.158120\n",
            "Iteration 36, loss = 2.51900685\n",
            "Validation score: 0.158120\n",
            "Iteration 37, loss = 2.51851247\n",
            "Validation score: 0.158120\n",
            "Iteration 38, loss = 2.51789609\n",
            "Validation score: 0.158120\n",
            "Iteration 39, loss = 2.51740080\n",
            "Validation score: 0.158120\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.23306977\n",
            "Validation score: 0.128205\n",
            "Iteration 2, loss = 3.07144834\n",
            "Validation score: 0.128205\n",
            "Iteration 3, loss = 2.82519055\n",
            "Validation score: 0.128205\n",
            "Iteration 4, loss = 2.65776955\n",
            "Validation score: 0.141026\n",
            "Iteration 5, loss = 2.57415305\n",
            "Validation score: 0.188034\n",
            "Iteration 6, loss = 2.53426033\n",
            "Validation score: 0.200855\n",
            "Iteration 7, loss = 2.51614717\n",
            "Validation score: 0.200855\n",
            "Iteration 8, loss = 2.50728231\n",
            "Validation score: 0.175214\n",
            "Iteration 9, loss = 2.50091168\n",
            "Validation score: 0.149573\n",
            "Iteration 10, loss = 2.49585531\n",
            "Validation score: 0.149573\n",
            "Iteration 11, loss = 2.49067154\n",
            "Validation score: 0.149573\n",
            "Iteration 12, loss = 2.48558259\n",
            "Validation score: 0.149573\n",
            "Iteration 13, loss = 2.48103657\n",
            "Validation score: 0.153846\n",
            "Iteration 14, loss = 2.47591630\n",
            "Validation score: 0.153846\n",
            "Iteration 15, loss = 2.47051325\n",
            "Validation score: 0.166667\n",
            "Iteration 16, loss = 2.46486838\n",
            "Validation score: 0.162393\n",
            "Iteration 17, loss = 2.45953616\n",
            "Validation score: 0.162393\n",
            "Iteration 18, loss = 2.45252568\n",
            "Validation score: 0.166667\n",
            "Iteration 19, loss = 2.44709248\n",
            "Validation score: 0.166667\n",
            "Iteration 20, loss = 2.44071751\n",
            "Validation score: 0.166667\n",
            "Iteration 21, loss = 2.43464638\n",
            "Validation score: 0.166667\n",
            "Iteration 22, loss = 2.42891014\n",
            "Validation score: 0.166667\n",
            "Iteration 23, loss = 2.42352682\n",
            "Validation score: 0.166667\n",
            "Iteration 24, loss = 2.41796663\n",
            "Validation score: 0.166667\n",
            "Iteration 25, loss = 2.41247836\n",
            "Validation score: 0.170940\n",
            "Iteration 26, loss = 2.40711367\n",
            "Validation score: 0.170940\n",
            "Iteration 27, loss = 2.40188188\n",
            "Validation score: 0.170940\n",
            "Iteration 28, loss = 2.39707568\n",
            "Validation score: 0.179487\n",
            "Iteration 29, loss = 2.39289775\n",
            "Validation score: 0.179487\n",
            "Iteration 30, loss = 2.38772524\n",
            "Validation score: 0.179487\n",
            "Iteration 31, loss = 2.38336689\n",
            "Validation score: 0.183761\n",
            "Iteration 32, loss = 2.37910893\n",
            "Validation score: 0.183761\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.13083414\n",
            "Validation score: 0.119658\n",
            "Iteration 2, loss = 3.04154644\n",
            "Validation score: 0.119658\n",
            "Iteration 3, loss = 2.96455175\n",
            "Validation score: 0.119658\n",
            "Iteration 4, loss = 2.89832510\n",
            "Validation score: 0.119658\n",
            "Iteration 5, loss = 2.84189203\n",
            "Validation score: 0.119658\n",
            "Iteration 6, loss = 2.79382193\n",
            "Validation score: 0.119658\n",
            "Iteration 7, loss = 2.75290210\n",
            "Validation score: 0.175214\n",
            "Iteration 8, loss = 2.71810087\n",
            "Validation score: 0.175214\n",
            "Iteration 9, loss = 2.68868269\n",
            "Validation score: 0.175214\n",
            "Iteration 10, loss = 2.66373228\n",
            "Validation score: 0.175214\n",
            "Iteration 11, loss = 2.64261968\n",
            "Validation score: 0.175214\n",
            "Iteration 12, loss = 2.62460101\n",
            "Validation score: 0.175214\n",
            "Iteration 13, loss = 2.60935474\n",
            "Validation score: 0.175214\n",
            "Iteration 14, loss = 2.59630855\n",
            "Validation score: 0.175214\n",
            "Iteration 15, loss = 2.58511215\n",
            "Validation score: 0.175214\n",
            "Iteration 16, loss = 2.57550826\n",
            "Validation score: 0.175214\n",
            "Iteration 17, loss = 2.56718775\n",
            "Validation score: 0.175214\n",
            "Iteration 18, loss = 2.55996349\n",
            "Validation score: 0.175214\n",
            "Iteration 19, loss = 2.55384726\n",
            "Validation score: 0.175214\n",
            "Iteration 20, loss = 2.54833069\n",
            "Validation score: 0.175214\n",
            "Iteration 21, loss = 2.54363298\n",
            "Validation score: 0.175214\n",
            "Iteration 22, loss = 2.53944770\n",
            "Validation score: 0.175214\n",
            "Iteration 23, loss = 2.53575132\n",
            "Validation score: 0.175214\n",
            "Iteration 24, loss = 2.53247524\n",
            "Validation score: 0.175214\n",
            "Iteration 25, loss = 2.52957073\n",
            "Validation score: 0.145299\n",
            "Iteration 26, loss = 2.52691142\n",
            "Validation score: 0.145299\n",
            "Iteration 27, loss = 2.52459160\n",
            "Validation score: 0.145299\n",
            "Iteration 28, loss = 2.52254856\n",
            "Validation score: 0.145299\n",
            "Iteration 29, loss = 2.52073665\n",
            "Validation score: 0.145299\n",
            "Iteration 30, loss = 2.51898804\n",
            "Validation score: 0.145299\n",
            "Iteration 31, loss = 2.51742288\n",
            "Validation score: 0.145299\n",
            "Iteration 32, loss = 2.51597537\n",
            "Validation score: 0.145299\n",
            "Iteration 33, loss = 2.51475249\n",
            "Validation score: 0.145299\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.20100103\n",
            "Validation score: 0.055556\n",
            "Iteration 2, loss = 3.05794739\n",
            "Validation score: 0.132479\n",
            "Iteration 3, loss = 2.83566121\n",
            "Validation score: 0.119658\n",
            "Iteration 4, loss = 2.66816394\n",
            "Validation score: 0.115385\n",
            "Iteration 5, loss = 2.58382195\n",
            "Validation score: 0.153846\n",
            "Iteration 6, loss = 2.54509245\n",
            "Validation score: 0.170940\n",
            "Iteration 7, loss = 2.52701982\n",
            "Validation score: 0.196581\n",
            "Iteration 8, loss = 2.51742640\n",
            "Validation score: 0.188034\n",
            "Iteration 9, loss = 2.51134641\n",
            "Validation score: 0.162393\n",
            "Iteration 10, loss = 2.50619086\n",
            "Validation score: 0.183761\n",
            "Iteration 11, loss = 2.50281394\n",
            "Validation score: 0.179487\n",
            "Iteration 12, loss = 2.49887916\n",
            "Validation score: 0.183761\n",
            "Iteration 13, loss = 2.49559174\n",
            "Validation score: 0.209402\n",
            "Iteration 14, loss = 2.49216599\n",
            "Validation score: 0.213675\n",
            "Iteration 15, loss = 2.48862499\n",
            "Validation score: 0.217949\n",
            "Iteration 16, loss = 2.48519461\n",
            "Validation score: 0.205128\n",
            "Iteration 17, loss = 2.48174730\n",
            "Validation score: 0.217949\n",
            "Iteration 18, loss = 2.47733306\n",
            "Validation score: 0.230769\n",
            "Iteration 19, loss = 2.47336773\n",
            "Validation score: 0.235043\n",
            "Iteration 20, loss = 2.46859534\n",
            "Validation score: 0.230769\n",
            "Iteration 21, loss = 2.46399270\n",
            "Validation score: 0.205128\n",
            "Iteration 22, loss = 2.45901901\n",
            "Validation score: 0.213675\n",
            "Iteration 23, loss = 2.45397593\n",
            "Validation score: 0.213675\n",
            "Iteration 24, loss = 2.44854037\n",
            "Validation score: 0.217949\n",
            "Iteration 25, loss = 2.44326436\n",
            "Validation score: 0.209402\n",
            "Iteration 26, loss = 2.43749339\n",
            "Validation score: 0.213675\n",
            "Iteration 27, loss = 2.43181203\n",
            "Validation score: 0.222222\n",
            "Iteration 28, loss = 2.42588087\n",
            "Validation score: 0.213675\n",
            "Iteration 29, loss = 2.41978384\n",
            "Validation score: 0.222222\n",
            "Iteration 30, loss = 2.41403058\n",
            "Validation score: 0.213675\n",
            "Iteration 31, loss = 2.40787499\n",
            "Validation score: 0.217949\n",
            "Iteration 32, loss = 2.40210911\n",
            "Validation score: 0.213675\n",
            "Iteration 33, loss = 2.39638374\n",
            "Validation score: 0.217949\n",
            "Iteration 34, loss = 2.39063306\n",
            "Validation score: 0.213675\n",
            "Iteration 35, loss = 2.38530804\n",
            "Validation score: 0.213675\n",
            "Iteration 36, loss = 2.37952942\n",
            "Validation score: 0.213675\n",
            "Iteration 37, loss = 2.37426213\n",
            "Validation score: 0.217949\n",
            "Iteration 38, loss = 2.36871384\n",
            "Validation score: 0.217949\n",
            "Iteration 39, loss = 2.36388379\n",
            "Validation score: 0.217949\n",
            "Iteration 40, loss = 2.35887335\n",
            "Validation score: 0.217949\n",
            "Iteration 41, loss = 2.35351598\n",
            "Validation score: 0.217949\n",
            "Iteration 42, loss = 2.34884491\n",
            "Validation score: 0.217949\n",
            "Iteration 43, loss = 2.34385994\n",
            "Validation score: 0.235043\n",
            "Iteration 44, loss = 2.33904268\n",
            "Validation score: 0.235043\n",
            "Iteration 45, loss = 2.33423167\n",
            "Validation score: 0.256410\n",
            "Iteration 46, loss = 2.32972648\n",
            "Validation score: 0.256410\n",
            "Iteration 47, loss = 2.32511197\n",
            "Validation score: 0.256410\n",
            "Iteration 48, loss = 2.32103002\n",
            "Validation score: 0.256410\n",
            "Iteration 49, loss = 2.31678145\n",
            "Validation score: 0.260684\n",
            "Iteration 50, loss = 2.31275805\n",
            "Validation score: 0.252137\n",
            "Iteration 51, loss = 2.30825571\n",
            "Validation score: 0.252137\n",
            "Iteration 52, loss = 2.30505857\n",
            "Validation score: 0.247863\n",
            "Iteration 53, loss = 2.30107161\n",
            "Validation score: 0.239316\n",
            "Iteration 54, loss = 2.29708058\n",
            "Validation score: 0.243590\n",
            "Iteration 55, loss = 2.29349341\n",
            "Validation score: 0.247863\n",
            "Iteration 56, loss = 2.29029009\n",
            "Validation score: 0.235043\n",
            "Iteration 57, loss = 2.28689194\n",
            "Validation score: 0.235043\n",
            "Iteration 58, loss = 2.28294943\n",
            "Validation score: 0.239316\n",
            "Iteration 59, loss = 2.28001266\n",
            "Validation score: 0.239316\n",
            "Iteration 60, loss = 2.27679030\n",
            "Validation score: 0.247863\n",
            "Iteration 61, loss = 2.27390355\n",
            "Validation score: 0.243590\n",
            "Iteration 62, loss = 2.27052559\n",
            "Validation score: 0.252137\n",
            "Iteration 63, loss = 2.26794722\n",
            "Validation score: 0.252137\n",
            "Iteration 64, loss = 2.26469724\n",
            "Validation score: 0.243590\n",
            "Iteration 65, loss = 2.26203573\n",
            "Validation score: 0.256410\n",
            "Iteration 66, loss = 2.25932322\n",
            "Validation score: 0.252137\n",
            "Iteration 67, loss = 2.25653424\n",
            "Validation score: 0.247863\n",
            "Iteration 68, loss = 2.25421587\n",
            "Validation score: 0.256410\n",
            "Iteration 69, loss = 2.25132079\n",
            "Validation score: 0.256410\n",
            "Iteration 70, loss = 2.24889266\n",
            "Validation score: 0.256410\n",
            "Iteration 71, loss = 2.24629350\n",
            "Validation score: 0.247863\n",
            "Iteration 72, loss = 2.24385609\n",
            "Validation score: 0.256410\n",
            "Iteration 73, loss = 2.24197082\n",
            "Validation score: 0.252137\n",
            "Iteration 74, loss = 2.23962935\n",
            "Validation score: 0.252137\n",
            "Iteration 75, loss = 2.23688844\n",
            "Validation score: 0.256410\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.16027782\n",
            "Validation score: 0.128205\n",
            "Iteration 2, loss = 3.05362129\n",
            "Validation score: 0.128205\n",
            "Iteration 3, loss = 2.96755888\n",
            "Validation score: 0.128205\n",
            "Iteration 4, loss = 2.87619500\n",
            "Validation score: 0.128205\n",
            "Iteration 5, loss = 2.76694832\n",
            "Validation score: 0.128205\n",
            "Iteration 6, loss = 2.66252364\n",
            "Validation score: 0.128205\n",
            "Iteration 7, loss = 2.59166540\n",
            "Validation score: 0.128205\n",
            "Iteration 8, loss = 2.54957218\n",
            "Validation score: 0.128205\n",
            "Iteration 9, loss = 2.52395639\n",
            "Validation score: 0.188034\n",
            "Iteration 10, loss = 2.50622755\n",
            "Validation score: 0.183761\n",
            "Iteration 11, loss = 2.49300519\n",
            "Validation score: 0.188034\n",
            "Iteration 12, loss = 2.48131153\n",
            "Validation score: 0.192308\n",
            "Iteration 13, loss = 2.47054652\n",
            "Validation score: 0.183761\n",
            "Iteration 14, loss = 2.46124752\n",
            "Validation score: 0.188034\n",
            "Iteration 15, loss = 2.45220895\n",
            "Validation score: 0.188034\n",
            "Iteration 16, loss = 2.44344308\n",
            "Validation score: 0.222222\n",
            "Iteration 17, loss = 2.43507192\n",
            "Validation score: 0.226496\n",
            "Iteration 18, loss = 2.42750435\n",
            "Validation score: 0.209402\n",
            "Iteration 19, loss = 2.41899450\n",
            "Validation score: 0.209402\n",
            "Iteration 20, loss = 2.41130223\n",
            "Validation score: 0.205128\n",
            "Iteration 21, loss = 2.40332300\n",
            "Validation score: 0.209402\n",
            "Iteration 22, loss = 2.39572745\n",
            "Validation score: 0.196581\n",
            "Iteration 23, loss = 2.38778672\n",
            "Validation score: 0.200855\n",
            "Iteration 24, loss = 2.38030479\n",
            "Validation score: 0.209402\n",
            "Iteration 25, loss = 2.37293084\n",
            "Validation score: 0.205128\n",
            "Iteration 26, loss = 2.36546238\n",
            "Validation score: 0.213675\n",
            "Iteration 27, loss = 2.35855788\n",
            "Validation score: 0.196581\n",
            "Iteration 28, loss = 2.35187544\n",
            "Validation score: 0.217949\n",
            "Iteration 29, loss = 2.34525244\n",
            "Validation score: 0.230769\n",
            "Iteration 30, loss = 2.33873430\n",
            "Validation score: 0.230769\n",
            "Iteration 31, loss = 2.33243800\n",
            "Validation score: 0.235043\n",
            "Iteration 32, loss = 2.32690188\n",
            "Validation score: 0.235043\n",
            "Iteration 33, loss = 2.32089759\n",
            "Validation score: 0.247863\n",
            "Iteration 34, loss = 2.31526146\n",
            "Validation score: 0.243590\n",
            "Iteration 35, loss = 2.31023676\n",
            "Validation score: 0.239316\n",
            "Iteration 36, loss = 2.30507218\n",
            "Validation score: 0.243590\n",
            "Iteration 37, loss = 2.30019684\n",
            "Validation score: 0.239316\n",
            "Iteration 38, loss = 2.29580573\n",
            "Validation score: 0.247863\n",
            "Iteration 39, loss = 2.29128291\n",
            "Validation score: 0.247863\n",
            "Iteration 40, loss = 2.28691696\n",
            "Validation score: 0.243590\n",
            "Iteration 41, loss = 2.28288353\n",
            "Validation score: 0.247863\n",
            "Iteration 42, loss = 2.27928265\n",
            "Validation score: 0.243590\n",
            "Iteration 43, loss = 2.27540910\n",
            "Validation score: 0.247863\n",
            "Iteration 44, loss = 2.27177427\n",
            "Validation score: 0.252137\n",
            "Iteration 45, loss = 2.26810625\n",
            "Validation score: 0.256410\n",
            "Iteration 46, loss = 2.26483729\n",
            "Validation score: 0.252137\n",
            "Iteration 47, loss = 2.26134883\n",
            "Validation score: 0.247863\n",
            "Iteration 48, loss = 2.25827565\n",
            "Validation score: 0.256410\n",
            "Iteration 49, loss = 2.25526509\n",
            "Validation score: 0.256410\n",
            "Iteration 50, loss = 2.25234322\n",
            "Validation score: 0.260684\n",
            "Iteration 51, loss = 2.24946442\n",
            "Validation score: 0.260684\n",
            "Iteration 52, loss = 2.24662751\n",
            "Validation score: 0.264957\n",
            "Iteration 53, loss = 2.24444526\n",
            "Validation score: 0.256410\n",
            "Iteration 54, loss = 2.24155781\n",
            "Validation score: 0.260684\n",
            "Iteration 55, loss = 2.23873936\n",
            "Validation score: 0.256410\n",
            "Iteration 56, loss = 2.23623205\n",
            "Validation score: 0.260684\n",
            "Iteration 57, loss = 2.23456380\n",
            "Validation score: 0.256410\n",
            "Iteration 58, loss = 2.23186708\n",
            "Validation score: 0.252137\n",
            "Iteration 59, loss = 2.22961809\n",
            "Validation score: 0.256410\n",
            "Iteration 60, loss = 2.22751575\n",
            "Validation score: 0.260684\n",
            "Iteration 61, loss = 2.22509044\n",
            "Validation score: 0.256410\n",
            "Iteration 62, loss = 2.22351687\n",
            "Validation score: 0.256410\n",
            "Iteration 63, loss = 2.22122548\n",
            "Validation score: 0.256410\n",
            "Iteration 64, loss = 2.21881165\n",
            "Validation score: 0.260684\n",
            "Iteration 65, loss = 2.21724305\n",
            "Validation score: 0.256410\n",
            "Iteration 66, loss = 2.21548404\n",
            "Validation score: 0.252137\n",
            "Iteration 67, loss = 2.21329784\n",
            "Validation score: 0.256410\n",
            "Iteration 68, loss = 2.21187241\n",
            "Validation score: 0.247863\n",
            "Iteration 69, loss = 2.21007550\n",
            "Validation score: 0.256410\n",
            "Iteration 70, loss = 2.20836078\n",
            "Validation score: 0.256410\n",
            "Iteration 71, loss = 2.20632264\n",
            "Validation score: 0.252137\n",
            "Iteration 72, loss = 2.20439343\n",
            "Validation score: 0.252137\n",
            "Iteration 73, loss = 2.20278503\n",
            "Validation score: 0.256410\n",
            "Iteration 74, loss = 2.20205454\n",
            "Validation score: 0.252137\n",
            "Iteration 75, loss = 2.19990155\n",
            "Validation score: 0.260684\n",
            "Iteration 76, loss = 2.19807919\n",
            "Validation score: 0.256410\n",
            "Iteration 77, loss = 2.19678698\n",
            "Validation score: 0.256410\n",
            "Iteration 78, loss = 2.19520700\n",
            "Validation score: 0.247863\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.03077540\n",
            "Validation score: 0.076923\n",
            "Iteration 2, loss = 2.83688736\n",
            "Validation score: 0.076923\n",
            "Iteration 3, loss = 2.69113632\n",
            "Validation score: 0.115385\n",
            "Iteration 4, loss = 2.60080616\n",
            "Validation score: 0.115385\n",
            "Iteration 5, loss = 2.55379648\n",
            "Validation score: 0.153846\n",
            "Iteration 6, loss = 2.53120480\n",
            "Validation score: 0.153846\n",
            "Iteration 7, loss = 2.51964016\n",
            "Validation score: 0.153846\n",
            "Iteration 8, loss = 2.51305731\n",
            "Validation score: 0.153846\n",
            "Iteration 9, loss = 2.50889346\n",
            "Validation score: 0.179487\n",
            "Iteration 10, loss = 2.50611003\n",
            "Validation score: 0.153846\n",
            "Iteration 11, loss = 2.50417013\n",
            "Validation score: 0.153846\n",
            "Iteration 12, loss = 2.50267870\n",
            "Validation score: 0.179487\n",
            "Iteration 13, loss = 2.50185508\n",
            "Validation score: 0.179487\n",
            "Iteration 14, loss = 2.50107586\n",
            "Validation score: 0.179487\n",
            "Iteration 15, loss = 2.50020944\n",
            "Validation score: 0.153846\n",
            "Iteration 16, loss = 2.49983700\n",
            "Validation score: 0.153846\n",
            "Iteration 17, loss = 2.49940657\n",
            "Validation score: 0.179487\n",
            "Iteration 18, loss = 2.49896211\n",
            "Validation score: 0.153846\n",
            "Iteration 19, loss = 2.49852797\n",
            "Validation score: 0.179487\n",
            "Iteration 20, loss = 2.49855309\n",
            "Validation score: 0.153846\n",
            "Iteration 21, loss = 2.49825450\n",
            "Validation score: 0.153846\n",
            "Iteration 22, loss = 2.49794360\n",
            "Validation score: 0.179487\n",
            "Iteration 23, loss = 2.49799691\n",
            "Validation score: 0.179487\n",
            "Iteration 24, loss = 2.49787225\n",
            "Validation score: 0.179487\n",
            "Iteration 25, loss = 2.49755286\n",
            "Validation score: 0.153846\n",
            "Iteration 26, loss = 2.49789628\n",
            "Validation score: 0.153846\n",
            "Iteration 27, loss = 2.49758952\n",
            "Validation score: 0.179487\n",
            "Iteration 28, loss = 2.49777154\n",
            "Validation score: 0.153846\n",
            "Iteration 29, loss = 2.49767064\n",
            "Validation score: 0.153846\n",
            "Iteration 30, loss = 2.49749273\n",
            "Validation score: 0.179487\n",
            "Iteration 31, loss = 2.49739381\n",
            "Validation score: 0.153846\n",
            "Iteration 32, loss = 2.49762208\n",
            "Validation score: 0.153846\n",
            "Iteration 33, loss = 2.49754402\n",
            "Validation score: 0.153846\n",
            "Iteration 34, loss = 2.49721084\n",
            "Validation score: 0.153846\n",
            "Iteration 35, loss = 2.49740905\n",
            "Validation score: 0.153846\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.22715756\n",
            "Validation score: 0.008547\n",
            "Iteration 2, loss = 3.04805403\n",
            "Validation score: 0.145299\n",
            "Iteration 3, loss = 2.89150316\n",
            "Validation score: 0.145299\n",
            "Iteration 4, loss = 2.76708827\n",
            "Validation score: 0.153846\n",
            "Iteration 5, loss = 2.67625474\n",
            "Validation score: 0.153846\n",
            "Iteration 6, loss = 2.61279934\n",
            "Validation score: 0.153846\n",
            "Iteration 7, loss = 2.56888733\n",
            "Validation score: 0.149573\n",
            "Iteration 8, loss = 2.53854812\n",
            "Validation score: 0.153846\n",
            "Iteration 9, loss = 2.51782844\n",
            "Validation score: 0.158120\n",
            "Iteration 10, loss = 2.50290820\n",
            "Validation score: 0.162393\n",
            "Iteration 11, loss = 2.49140227\n",
            "Validation score: 0.166667\n",
            "Iteration 12, loss = 2.48220562\n",
            "Validation score: 0.170940\n",
            "Iteration 13, loss = 2.47440852\n",
            "Validation score: 0.153846\n",
            "Iteration 14, loss = 2.46859960\n",
            "Validation score: 0.162393\n",
            "Iteration 15, loss = 2.46297239\n",
            "Validation score: 0.162393\n",
            "Iteration 16, loss = 2.45812309\n",
            "Validation score: 0.179487\n",
            "Iteration 17, loss = 2.45304289\n",
            "Validation score: 0.162393\n",
            "Iteration 18, loss = 2.44808962\n",
            "Validation score: 0.179487\n",
            "Iteration 19, loss = 2.44310377\n",
            "Validation score: 0.188034\n",
            "Iteration 20, loss = 2.43804011\n",
            "Validation score: 0.188034\n",
            "Iteration 21, loss = 2.43271307\n",
            "Validation score: 0.192308\n",
            "Iteration 22, loss = 2.42817370\n",
            "Validation score: 0.188034\n",
            "Iteration 23, loss = 2.42347601\n",
            "Validation score: 0.188034\n",
            "Iteration 24, loss = 2.41893163\n",
            "Validation score: 0.196581\n",
            "Iteration 25, loss = 2.41412786\n",
            "Validation score: 0.200855\n",
            "Iteration 26, loss = 2.40958074\n",
            "Validation score: 0.200855\n",
            "Iteration 27, loss = 2.40469523\n",
            "Validation score: 0.200855\n",
            "Iteration 28, loss = 2.40027558\n",
            "Validation score: 0.196581\n",
            "Iteration 29, loss = 2.39572004\n",
            "Validation score: 0.196581\n",
            "Iteration 30, loss = 2.39086723\n",
            "Validation score: 0.200855\n",
            "Iteration 31, loss = 2.38672472\n",
            "Validation score: 0.200855\n",
            "Iteration 32, loss = 2.38189872\n",
            "Validation score: 0.196581\n",
            "Iteration 33, loss = 2.37793089\n",
            "Validation score: 0.200855\n",
            "Iteration 34, loss = 2.37306607\n",
            "Validation score: 0.200855\n",
            "Iteration 35, loss = 2.36906370\n",
            "Validation score: 0.200855\n",
            "Iteration 36, loss = 2.36503256\n",
            "Validation score: 0.209402\n",
            "Iteration 37, loss = 2.36040152\n",
            "Validation score: 0.213675\n",
            "Iteration 38, loss = 2.35654606\n",
            "Validation score: 0.209402\n",
            "Iteration 39, loss = 2.35219256\n",
            "Validation score: 0.226496\n",
            "Iteration 40, loss = 2.34796037\n",
            "Validation score: 0.217949\n",
            "Iteration 41, loss = 2.34406411\n",
            "Validation score: 0.222222\n",
            "Iteration 42, loss = 2.33982961\n",
            "Validation score: 0.217949\n",
            "Iteration 43, loss = 2.33543955\n",
            "Validation score: 0.217949\n",
            "Iteration 44, loss = 2.33098539\n",
            "Validation score: 0.209402\n",
            "Iteration 45, loss = 2.32754532\n",
            "Validation score: 0.213675\n",
            "Iteration 46, loss = 2.32357622\n",
            "Validation score: 0.196581\n",
            "Iteration 47, loss = 2.31934251\n",
            "Validation score: 0.200855\n",
            "Iteration 48, loss = 2.31588851\n",
            "Validation score: 0.196581\n",
            "Iteration 49, loss = 2.31185728\n",
            "Validation score: 0.192308\n",
            "Iteration 50, loss = 2.30825751\n",
            "Validation score: 0.200855\n",
            "Iteration 51, loss = 2.30471530\n",
            "Validation score: 0.209402\n",
            "Iteration 52, loss = 2.30113202\n",
            "Validation score: 0.192308\n",
            "Iteration 53, loss = 2.29741490\n",
            "Validation score: 0.196581\n",
            "Iteration 54, loss = 2.29395854\n",
            "Validation score: 0.205128\n",
            "Iteration 55, loss = 2.29122431\n",
            "Validation score: 0.205128\n",
            "Iteration 56, loss = 2.28765380\n",
            "Validation score: 0.213675\n",
            "Iteration 57, loss = 2.28473590\n",
            "Validation score: 0.209402\n",
            "Iteration 58, loss = 2.28155749\n",
            "Validation score: 0.209402\n",
            "Iteration 59, loss = 2.27954511\n",
            "Validation score: 0.209402\n",
            "Iteration 60, loss = 2.27602448\n",
            "Validation score: 0.213675\n",
            "Iteration 61, loss = 2.27291497\n",
            "Validation score: 0.226496\n",
            "Iteration 62, loss = 2.27078890\n",
            "Validation score: 0.222222\n",
            "Iteration 63, loss = 2.26794340\n",
            "Validation score: 0.230769\n",
            "Iteration 64, loss = 2.26483851\n",
            "Validation score: 0.222222\n",
            "Iteration 65, loss = 2.26246200\n",
            "Validation score: 0.230769\n",
            "Iteration 66, loss = 2.25977466\n",
            "Validation score: 0.230769\n",
            "Iteration 67, loss = 2.25720951\n",
            "Validation score: 0.235043\n",
            "Iteration 68, loss = 2.25468461\n",
            "Validation score: 0.235043\n",
            "Iteration 69, loss = 2.25243175\n",
            "Validation score: 0.239316\n",
            "Iteration 70, loss = 2.24949649\n",
            "Validation score: 0.252137\n",
            "Iteration 71, loss = 2.24677061\n",
            "Validation score: 0.235043\n",
            "Iteration 72, loss = 2.24462124\n",
            "Validation score: 0.247863\n",
            "Iteration 73, loss = 2.24189716\n",
            "Validation score: 0.256410\n",
            "Iteration 74, loss = 2.23941058\n",
            "Validation score: 0.247863\n",
            "Iteration 75, loss = 2.23717282\n",
            "Validation score: 0.243590\n",
            "Iteration 76, loss = 2.23479928\n",
            "Validation score: 0.256410\n",
            "Iteration 77, loss = 2.23287148\n",
            "Validation score: 0.243590\n",
            "Iteration 78, loss = 2.23090453\n",
            "Validation score: 0.247863\n",
            "Iteration 79, loss = 2.22888516\n",
            "Validation score: 0.243590\n",
            "Iteration 80, loss = 2.22648698\n",
            "Validation score: 0.247863\n",
            "Iteration 81, loss = 2.22463983\n",
            "Validation score: 0.247863\n",
            "Iteration 82, loss = 2.22310140\n",
            "Validation score: 0.247863\n",
            "Iteration 83, loss = 2.22080399\n",
            "Validation score: 0.247863\n",
            "Iteration 84, loss = 2.21912221\n",
            "Validation score: 0.247863\n",
            "Iteration 85, loss = 2.21725823\n",
            "Validation score: 0.252137\n",
            "Iteration 86, loss = 2.21558449\n",
            "Validation score: 0.247863\n",
            "Iteration 87, loss = 2.21384917\n",
            "Validation score: 0.243590\n",
            "Iteration 88, loss = 2.21222160\n",
            "Validation score: 0.247863\n",
            "Iteration 89, loss = 2.21029658\n",
            "Validation score: 0.260684\n",
            "Iteration 90, loss = 2.20890538\n",
            "Validation score: 0.243590\n",
            "Iteration 91, loss = 2.20690063\n",
            "Validation score: 0.252137\n",
            "Iteration 92, loss = 2.20541783\n",
            "Validation score: 0.264957\n",
            "Iteration 93, loss = 2.20396492\n",
            "Validation score: 0.252137\n",
            "Iteration 94, loss = 2.20230748\n",
            "Validation score: 0.264957\n",
            "Iteration 95, loss = 2.20015858\n",
            "Validation score: 0.269231\n",
            "Iteration 96, loss = 2.19883077\n",
            "Validation score: 0.260684\n",
            "Iteration 97, loss = 2.19735663\n",
            "Validation score: 0.269231\n",
            "Iteration 98, loss = 2.19601970\n",
            "Validation score: 0.264957\n",
            "Iteration 99, loss = 2.19487116\n",
            "Validation score: 0.247863\n",
            "Iteration 100, loss = 2.19314465\n",
            "Validation score: 0.273504\n",
            "Iteration 101, loss = 2.19194588\n",
            "Validation score: 0.252137\n",
            "Iteration 102, loss = 2.18990154\n",
            "Validation score: 0.252137\n",
            "Iteration 103, loss = 2.18911874\n",
            "Validation score: 0.247863\n",
            "Iteration 104, loss = 2.18762398\n",
            "Validation score: 0.247863\n",
            "Iteration 105, loss = 2.18639905\n",
            "Validation score: 0.247863\n",
            "Iteration 106, loss = 2.18474319\n",
            "Validation score: 0.264957\n",
            "Iteration 107, loss = 2.18314684\n",
            "Validation score: 0.247863\n",
            "Iteration 108, loss = 2.18244854\n",
            "Validation score: 0.247863\n",
            "Iteration 109, loss = 2.18112843\n",
            "Validation score: 0.252137\n",
            "Iteration 110, loss = 2.17924106\n",
            "Validation score: 0.277778\n",
            "Iteration 111, loss = 2.17904491\n",
            "Validation score: 0.256410\n",
            "Iteration 112, loss = 2.17699990\n",
            "Validation score: 0.277778\n",
            "Iteration 113, loss = 2.17663938\n",
            "Validation score: 0.252137\n",
            "Iteration 114, loss = 2.17493228\n",
            "Validation score: 0.243590\n",
            "Iteration 115, loss = 2.17348474\n",
            "Validation score: 0.247863\n",
            "Iteration 116, loss = 2.17221476\n",
            "Validation score: 0.269231\n",
            "Iteration 117, loss = 2.17108691\n",
            "Validation score: 0.264957\n",
            "Iteration 118, loss = 2.16974984\n",
            "Validation score: 0.247863\n",
            "Iteration 119, loss = 2.16871508\n",
            "Validation score: 0.264957\n",
            "Iteration 120, loss = 2.16766836\n",
            "Validation score: 0.252137\n",
            "Iteration 121, loss = 2.16613819\n",
            "Validation score: 0.264957\n",
            "Iteration 122, loss = 2.16576413\n",
            "Validation score: 0.264957\n",
            "Iteration 123, loss = 2.16395774\n",
            "Validation score: 0.264957\n",
            "Iteration 124, loss = 2.16321836\n",
            "Validation score: 0.264957\n",
            "Iteration 125, loss = 2.16237297\n",
            "Validation score: 0.252137\n",
            "Iteration 126, loss = 2.16082288\n",
            "Validation score: 0.264957\n",
            "Iteration 127, loss = 2.16026990\n",
            "Validation score: 0.260684\n",
            "Iteration 128, loss = 2.15874047\n",
            "Validation score: 0.269231\n",
            "Iteration 129, loss = 2.15788871\n",
            "Validation score: 0.252137\n",
            "Iteration 130, loss = 2.15621219\n",
            "Validation score: 0.256410\n",
            "Iteration 131, loss = 2.15614284\n",
            "Validation score: 0.256410\n",
            "Iteration 132, loss = 2.15496318\n",
            "Validation score: 0.256410\n",
            "Iteration 133, loss = 2.15341978\n",
            "Validation score: 0.252137\n",
            "Iteration 134, loss = 2.15292337\n",
            "Validation score: 0.252137\n",
            "Iteration 135, loss = 2.15146998\n",
            "Validation score: 0.256410\n",
            "Iteration 136, loss = 2.15107696\n",
            "Validation score: 0.256410\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.43847388\n",
            "Validation score: 0.068376\n",
            "Iteration 2, loss = 3.22907320\n",
            "Validation score: 0.068376\n",
            "Iteration 3, loss = 2.87404625\n",
            "Validation score: 0.119658\n",
            "Iteration 4, loss = 2.64482768\n",
            "Validation score: 0.119658\n",
            "Iteration 5, loss = 2.55908907\n",
            "Validation score: 0.119658\n",
            "Iteration 6, loss = 2.52460746\n",
            "Validation score: 0.166667\n",
            "Iteration 7, loss = 2.50787334\n",
            "Validation score: 0.166667\n",
            "Iteration 8, loss = 2.49907011\n",
            "Validation score: 0.123932\n",
            "Iteration 9, loss = 2.49290872\n",
            "Validation score: 0.183761\n",
            "Iteration 10, loss = 2.48915304\n",
            "Validation score: 0.162393\n",
            "Iteration 11, loss = 2.48532388\n",
            "Validation score: 0.175214\n",
            "Iteration 12, loss = 2.48239611\n",
            "Validation score: 0.170940\n",
            "Iteration 13, loss = 2.47954017\n",
            "Validation score: 0.166667\n",
            "Iteration 14, loss = 2.47673893\n",
            "Validation score: 0.162393\n",
            "Iteration 15, loss = 2.47374042\n",
            "Validation score: 0.175214\n",
            "Iteration 16, loss = 2.47114577\n",
            "Validation score: 0.175214\n",
            "Iteration 17, loss = 2.46908341\n",
            "Validation score: 0.170940\n",
            "Iteration 18, loss = 2.46555519\n",
            "Validation score: 0.179487\n",
            "Iteration 19, loss = 2.46248222\n",
            "Validation score: 0.200855\n",
            "Iteration 20, loss = 2.45913987\n",
            "Validation score: 0.179487\n",
            "Iteration 21, loss = 2.45578018\n",
            "Validation score: 0.196581\n",
            "Iteration 22, loss = 2.45216626\n",
            "Validation score: 0.209402\n",
            "Iteration 23, loss = 2.44866615\n",
            "Validation score: 0.217949\n",
            "Iteration 24, loss = 2.44431974\n",
            "Validation score: 0.222222\n",
            "Iteration 25, loss = 2.44028635\n",
            "Validation score: 0.226496\n",
            "Iteration 26, loss = 2.43543519\n",
            "Validation score: 0.226496\n",
            "Iteration 27, loss = 2.43121407\n",
            "Validation score: 0.239316\n",
            "Iteration 28, loss = 2.42627981\n",
            "Validation score: 0.230769\n",
            "Iteration 29, loss = 2.42132002\n",
            "Validation score: 0.226496\n",
            "Iteration 30, loss = 2.41639976\n",
            "Validation score: 0.239316\n",
            "Iteration 31, loss = 2.41172309\n",
            "Validation score: 0.230769\n",
            "Iteration 32, loss = 2.40646344\n",
            "Validation score: 0.235043\n",
            "Iteration 33, loss = 2.40090982\n",
            "Validation score: 0.239316\n",
            "Iteration 34, loss = 2.39595040\n",
            "Validation score: 0.226496\n",
            "Iteration 35, loss = 2.39011401\n",
            "Validation score: 0.235043\n",
            "Iteration 36, loss = 2.38538872\n",
            "Validation score: 0.230769\n",
            "Iteration 37, loss = 2.37986736\n",
            "Validation score: 0.222222\n",
            "Iteration 38, loss = 2.37427812\n",
            "Validation score: 0.235043\n",
            "Iteration 39, loss = 2.36914765\n",
            "Validation score: 0.235043\n",
            "Iteration 40, loss = 2.36408995\n",
            "Validation score: 0.239316\n",
            "Iteration 41, loss = 2.35879953\n",
            "Validation score: 0.235043\n",
            "Iteration 42, loss = 2.35395775\n",
            "Validation score: 0.239316\n",
            "Iteration 43, loss = 2.34880482\n",
            "Validation score: 0.239316\n",
            "Iteration 44, loss = 2.34348275\n",
            "Validation score: 0.239316\n",
            "Iteration 45, loss = 2.33827027\n",
            "Validation score: 0.239316\n",
            "Iteration 46, loss = 2.33385731\n",
            "Validation score: 0.239316\n",
            "Iteration 47, loss = 2.32862783\n",
            "Validation score: 0.239316\n",
            "Iteration 48, loss = 2.32455914\n",
            "Validation score: 0.235043\n",
            "Iteration 49, loss = 2.31960705\n",
            "Validation score: 0.235043\n",
            "Iteration 50, loss = 2.31555098\n",
            "Validation score: 0.247863\n",
            "Iteration 51, loss = 2.31126081\n",
            "Validation score: 0.252137\n",
            "Iteration 52, loss = 2.30685175\n",
            "Validation score: 0.243590\n",
            "Iteration 53, loss = 2.30300767\n",
            "Validation score: 0.243590\n",
            "Iteration 54, loss = 2.29838873\n",
            "Validation score: 0.243590\n",
            "Iteration 55, loss = 2.29470651\n",
            "Validation score: 0.252137\n",
            "Iteration 56, loss = 2.29060565\n",
            "Validation score: 0.252137\n",
            "Iteration 57, loss = 2.28649502\n",
            "Validation score: 0.243590\n",
            "Iteration 58, loss = 2.28320583\n",
            "Validation score: 0.247863\n",
            "Iteration 59, loss = 2.27962616\n",
            "Validation score: 0.256410\n",
            "Iteration 60, loss = 2.27636782\n",
            "Validation score: 0.252137\n",
            "Iteration 61, loss = 2.27305546\n",
            "Validation score: 0.243590\n",
            "Iteration 62, loss = 2.26938353\n",
            "Validation score: 0.239316\n",
            "Iteration 63, loss = 2.26626616\n",
            "Validation score: 0.247863\n",
            "Iteration 64, loss = 2.26310707\n",
            "Validation score: 0.252137\n",
            "Iteration 65, loss = 2.25977601\n",
            "Validation score: 0.256410\n",
            "Iteration 66, loss = 2.25647253\n",
            "Validation score: 0.256410\n",
            "Iteration 67, loss = 2.25362200\n",
            "Validation score: 0.260684\n",
            "Iteration 68, loss = 2.25040243\n",
            "Validation score: 0.256410\n",
            "Iteration 69, loss = 2.24775356\n",
            "Validation score: 0.243590\n",
            "Iteration 70, loss = 2.24419997\n",
            "Validation score: 0.235043\n",
            "Iteration 71, loss = 2.24158329\n",
            "Validation score: 0.243590\n",
            "Iteration 72, loss = 2.23895937\n",
            "Validation score: 0.243590\n",
            "Iteration 73, loss = 2.23606109\n",
            "Validation score: 0.247863\n",
            "Iteration 74, loss = 2.23336928\n",
            "Validation score: 0.252137\n",
            "Iteration 75, loss = 2.23093045\n",
            "Validation score: 0.213675\n",
            "Iteration 76, loss = 2.22792846\n",
            "Validation score: 0.213675\n",
            "Iteration 77, loss = 2.22561861\n",
            "Validation score: 0.200855\n",
            "Iteration 78, loss = 2.22373608\n",
            "Validation score: 0.209402\n",
            "Iteration 79, loss = 2.22113934\n",
            "Validation score: 0.213675\n",
            "Iteration 80, loss = 2.21816192\n",
            "Validation score: 0.209402\n",
            "Iteration 81, loss = 2.21617756\n",
            "Validation score: 0.209402\n",
            "Iteration 82, loss = 2.21414377\n",
            "Validation score: 0.209402\n",
            "Iteration 83, loss = 2.21166058\n",
            "Validation score: 0.209402\n",
            "Iteration 84, loss = 2.20945373\n",
            "Validation score: 0.217949\n",
            "Iteration 85, loss = 2.20780169\n",
            "Validation score: 0.209402\n",
            "Iteration 86, loss = 2.20545871\n",
            "Validation score: 0.209402\n",
            "Iteration 87, loss = 2.20330171\n",
            "Validation score: 0.217949\n",
            "Iteration 88, loss = 2.20165881\n",
            "Validation score: 0.217949\n",
            "Iteration 89, loss = 2.19964857\n",
            "Validation score: 0.222222\n",
            "Iteration 90, loss = 2.19818600\n",
            "Validation score: 0.213675\n",
            "Iteration 91, loss = 2.19615566\n",
            "Validation score: 0.213675\n",
            "Iteration 92, loss = 2.19443983\n",
            "Validation score: 0.217949\n",
            "Iteration 93, loss = 2.19280622\n",
            "Validation score: 0.213675\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.30767546\n",
            "Validation score: 0.136752\n",
            "Iteration 2, loss = 3.12545106\n",
            "Validation score: 0.136752\n",
            "Iteration 3, loss = 2.98824762\n",
            "Validation score: 0.136752\n",
            "Iteration 4, loss = 2.86464234\n",
            "Validation score: 0.136752\n",
            "Iteration 5, loss = 2.74560863\n",
            "Validation score: 0.136752\n",
            "Iteration 6, loss = 2.64212310\n",
            "Validation score: 0.136752\n",
            "Iteration 7, loss = 2.57073981\n",
            "Validation score: 0.136752\n",
            "Iteration 8, loss = 2.53443992\n",
            "Validation score: 0.136752\n",
            "Iteration 9, loss = 2.51773964\n",
            "Validation score: 0.136752\n",
            "Iteration 10, loss = 2.50763973\n",
            "Validation score: 0.128205\n",
            "Iteration 11, loss = 2.50028320\n",
            "Validation score: 0.136752\n",
            "Iteration 12, loss = 2.49343857\n",
            "Validation score: 0.132479\n",
            "Iteration 13, loss = 2.48725418\n",
            "Validation score: 0.128205\n",
            "Iteration 14, loss = 2.48004600\n",
            "Validation score: 0.136752\n",
            "Iteration 15, loss = 2.47363991\n",
            "Validation score: 0.136752\n",
            "Iteration 16, loss = 2.46693302\n",
            "Validation score: 0.141026\n",
            "Iteration 17, loss = 2.46071992\n",
            "Validation score: 0.141026\n",
            "Iteration 18, loss = 2.45421708\n",
            "Validation score: 0.141026\n",
            "Iteration 19, loss = 2.44853374\n",
            "Validation score: 0.141026\n",
            "Iteration 20, loss = 2.44225215\n",
            "Validation score: 0.149573\n",
            "Iteration 21, loss = 2.43615029\n",
            "Validation score: 0.145299\n",
            "Iteration 22, loss = 2.43021138\n",
            "Validation score: 0.145299\n",
            "Iteration 23, loss = 2.42403397\n",
            "Validation score: 0.145299\n",
            "Iteration 24, loss = 2.41815578\n",
            "Validation score: 0.145299\n",
            "Iteration 25, loss = 2.41222842\n",
            "Validation score: 0.145299\n",
            "Iteration 26, loss = 2.40633865\n",
            "Validation score: 0.145299\n",
            "Iteration 27, loss = 2.40075253\n",
            "Validation score: 0.153846\n",
            "Iteration 28, loss = 2.39458591\n",
            "Validation score: 0.158120\n",
            "Iteration 29, loss = 2.38858369\n",
            "Validation score: 0.183761\n",
            "Iteration 30, loss = 2.38302425\n",
            "Validation score: 0.188034\n",
            "Iteration 31, loss = 2.37740316\n",
            "Validation score: 0.192308\n",
            "Iteration 32, loss = 2.37191549\n",
            "Validation score: 0.209402\n",
            "Iteration 33, loss = 2.36632368\n",
            "Validation score: 0.196581\n",
            "Iteration 34, loss = 2.36093561\n",
            "Validation score: 0.196581\n",
            "Iteration 35, loss = 2.35550620\n",
            "Validation score: 0.200855\n",
            "Iteration 36, loss = 2.35062531\n",
            "Validation score: 0.209402\n",
            "Iteration 37, loss = 2.34609789\n",
            "Validation score: 0.200855\n",
            "Iteration 38, loss = 2.34062008\n",
            "Validation score: 0.196581\n",
            "Iteration 39, loss = 2.33601150\n",
            "Validation score: 0.205128\n",
            "Iteration 40, loss = 2.33161320\n",
            "Validation score: 0.213675\n",
            "Iteration 41, loss = 2.32717743\n",
            "Validation score: 0.217949\n",
            "Iteration 42, loss = 2.32280328\n",
            "Validation score: 0.217949\n",
            "Iteration 43, loss = 2.31880103\n",
            "Validation score: 0.213675\n",
            "Iteration 44, loss = 2.31474995\n",
            "Validation score: 0.226496\n",
            "Iteration 45, loss = 2.31109525\n",
            "Validation score: 0.230769\n",
            "Iteration 46, loss = 2.30726328\n",
            "Validation score: 0.230769\n",
            "Iteration 47, loss = 2.30376497\n",
            "Validation score: 0.230769\n",
            "Iteration 48, loss = 2.30052089\n",
            "Validation score: 0.230769\n",
            "Iteration 49, loss = 2.29727560\n",
            "Validation score: 0.230769\n",
            "Iteration 50, loss = 2.29387001\n",
            "Validation score: 0.230769\n",
            "Iteration 51, loss = 2.29041672\n",
            "Validation score: 0.226496\n",
            "Iteration 52, loss = 2.28726758\n",
            "Validation score: 0.230769\n",
            "Iteration 53, loss = 2.28464685\n",
            "Validation score: 0.235043\n",
            "Iteration 54, loss = 2.28176408\n",
            "Validation score: 0.226496\n",
            "Iteration 55, loss = 2.27847819\n",
            "Validation score: 0.239316\n",
            "Iteration 56, loss = 2.27552282\n",
            "Validation score: 0.235043\n",
            "Iteration 57, loss = 2.27304329\n",
            "Validation score: 0.235043\n",
            "Iteration 58, loss = 2.27020297\n",
            "Validation score: 0.230769\n",
            "Iteration 59, loss = 2.26793453\n",
            "Validation score: 0.235043\n",
            "Iteration 60, loss = 2.26502541\n",
            "Validation score: 0.235043\n",
            "Iteration 61, loss = 2.26267020\n",
            "Validation score: 0.235043\n",
            "Iteration 62, loss = 2.25968951\n",
            "Validation score: 0.235043\n",
            "Iteration 63, loss = 2.25766434\n",
            "Validation score: 0.243590\n",
            "Iteration 64, loss = 2.25524780\n",
            "Validation score: 0.239316\n",
            "Iteration 65, loss = 2.25319177\n",
            "Validation score: 0.239316\n",
            "Iteration 66, loss = 2.25152030\n",
            "Validation score: 0.239316\n",
            "Iteration 67, loss = 2.24891070\n",
            "Validation score: 0.239316\n",
            "Iteration 68, loss = 2.24676097\n",
            "Validation score: 0.247863\n",
            "Iteration 69, loss = 2.24455863\n",
            "Validation score: 0.239316\n",
            "Iteration 70, loss = 2.24236969\n",
            "Validation score: 0.247863\n",
            "Iteration 71, loss = 2.24006900\n",
            "Validation score: 0.235043\n",
            "Iteration 72, loss = 2.23801256\n",
            "Validation score: 0.252137\n",
            "Iteration 73, loss = 2.23594129\n",
            "Validation score: 0.247863\n",
            "Iteration 74, loss = 2.23320793\n",
            "Validation score: 0.247863\n",
            "Iteration 75, loss = 2.23171232\n",
            "Validation score: 0.252137\n",
            "Iteration 76, loss = 2.22900433\n",
            "Validation score: 0.243590\n",
            "Iteration 77, loss = 2.22700450\n",
            "Validation score: 0.256410\n",
            "Iteration 78, loss = 2.22489298\n",
            "Validation score: 0.256410\n",
            "Iteration 79, loss = 2.22305876\n",
            "Validation score: 0.260684\n",
            "Iteration 80, loss = 2.22131778\n",
            "Validation score: 0.260684\n",
            "Iteration 81, loss = 2.22011752\n",
            "Validation score: 0.260684\n",
            "Iteration 82, loss = 2.21850930\n",
            "Validation score: 0.260684\n",
            "Iteration 83, loss = 2.21622037\n",
            "Validation score: 0.260684\n",
            "Iteration 84, loss = 2.21541770\n",
            "Validation score: 0.260684\n",
            "Iteration 85, loss = 2.21412995\n",
            "Validation score: 0.260684\n",
            "Iteration 86, loss = 2.21204708\n",
            "Validation score: 0.260684\n",
            "Iteration 87, loss = 2.21062494\n",
            "Validation score: 0.260684\n",
            "Iteration 88, loss = 2.20895031\n",
            "Validation score: 0.260684\n",
            "Iteration 89, loss = 2.20785856\n",
            "Validation score: 0.277778\n",
            "Iteration 90, loss = 2.20611213\n",
            "Validation score: 0.264957\n",
            "Iteration 91, loss = 2.20469003\n",
            "Validation score: 0.269231\n",
            "Iteration 92, loss = 2.20331976\n",
            "Validation score: 0.277778\n",
            "Iteration 93, loss = 2.20207729\n",
            "Validation score: 0.260684\n",
            "Iteration 94, loss = 2.20020311\n",
            "Validation score: 0.264957\n",
            "Iteration 95, loss = 2.19921099\n",
            "Validation score: 0.256410\n",
            "Iteration 96, loss = 2.19764904\n",
            "Validation score: 0.264957\n",
            "Iteration 97, loss = 2.19613346\n",
            "Validation score: 0.260684\n",
            "Iteration 98, loss = 2.19480084\n",
            "Validation score: 0.260684\n",
            "Iteration 99, loss = 2.19360924\n",
            "Validation score: 0.260684\n",
            "Iteration 100, loss = 2.19205912\n",
            "Validation score: 0.264957\n",
            "Iteration 101, loss = 2.19096269\n",
            "Validation score: 0.264957\n",
            "Iteration 102, loss = 2.18988107\n",
            "Validation score: 0.252137\n",
            "Iteration 103, loss = 2.18832108\n",
            "Validation score: 0.269231\n",
            "Iteration 104, loss = 2.18742803\n",
            "Validation score: 0.269231\n",
            "Iteration 105, loss = 2.18596178\n",
            "Validation score: 0.282051\n",
            "Iteration 106, loss = 2.18636917\n",
            "Validation score: 0.269231\n",
            "Iteration 107, loss = 2.18452963\n",
            "Validation score: 0.264957\n",
            "Iteration 108, loss = 2.18339350\n",
            "Validation score: 0.269231\n",
            "Iteration 109, loss = 2.18221826\n",
            "Validation score: 0.269231\n",
            "Iteration 110, loss = 2.18104632\n",
            "Validation score: 0.269231\n",
            "Iteration 111, loss = 2.18002178\n",
            "Validation score: 0.264957\n",
            "Iteration 112, loss = 2.17889830\n",
            "Validation score: 0.264957\n",
            "Iteration 113, loss = 2.17804445\n",
            "Validation score: 0.260684\n",
            "Iteration 114, loss = 2.17663787\n",
            "Validation score: 0.277778\n",
            "Iteration 115, loss = 2.17618667\n",
            "Validation score: 0.269231\n",
            "Iteration 116, loss = 2.17558867\n",
            "Validation score: 0.264957\n",
            "Iteration 117, loss = 2.17413590\n",
            "Validation score: 0.264957\n",
            "Iteration 118, loss = 2.17342469\n",
            "Validation score: 0.277778\n",
            "Iteration 119, loss = 2.17258888\n",
            "Validation score: 0.277778\n",
            "Iteration 120, loss = 2.17140427\n",
            "Validation score: 0.269231\n",
            "Iteration 121, loss = 2.17045007\n",
            "Validation score: 0.269231\n",
            "Iteration 122, loss = 2.17006066\n",
            "Validation score: 0.269231\n",
            "Iteration 123, loss = 2.16925910\n",
            "Validation score: 0.273504\n",
            "Iteration 124, loss = 2.16795639\n",
            "Validation score: 0.256410\n",
            "Iteration 125, loss = 2.16645585\n",
            "Validation score: 0.273504\n",
            "Iteration 126, loss = 2.16577663\n",
            "Validation score: 0.282051\n",
            "Iteration 127, loss = 2.16480886\n",
            "Validation score: 0.273504\n",
            "Iteration 128, loss = 2.16386109\n",
            "Validation score: 0.264957\n",
            "Iteration 129, loss = 2.16389981\n",
            "Validation score: 0.273504\n",
            "Iteration 130, loss = 2.16244334\n",
            "Validation score: 0.273504\n",
            "Iteration 131, loss = 2.16256246\n",
            "Validation score: 0.282051\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.23251279\n",
            "Validation score: 0.094017\n",
            "Iteration 2, loss = 3.10324622\n",
            "Validation score: 0.094017\n",
            "Iteration 3, loss = 3.00556113\n",
            "Validation score: 0.094017\n",
            "Iteration 4, loss = 2.88503816\n",
            "Validation score: 0.094017\n",
            "Iteration 5, loss = 2.73028258\n",
            "Validation score: 0.149573\n",
            "Iteration 6, loss = 2.60733233\n",
            "Validation score: 0.235043\n",
            "Iteration 7, loss = 2.54573896\n",
            "Validation score: 0.256410\n",
            "Iteration 8, loss = 2.51945012\n",
            "Validation score: 0.256410\n",
            "Iteration 9, loss = 2.50446286\n",
            "Validation score: 0.256410\n",
            "Iteration 10, loss = 2.49276555\n",
            "Validation score: 0.256410\n",
            "Iteration 11, loss = 2.48321769\n",
            "Validation score: 0.256410\n",
            "Iteration 12, loss = 2.47284965\n",
            "Validation score: 0.256410\n",
            "Iteration 13, loss = 2.46273316\n",
            "Validation score: 0.256410\n",
            "Iteration 14, loss = 2.45235553\n",
            "Validation score: 0.256410\n",
            "Iteration 15, loss = 2.44222581\n",
            "Validation score: 0.256410\n",
            "Iteration 16, loss = 2.43271466\n",
            "Validation score: 0.256410\n",
            "Iteration 17, loss = 2.42320917\n",
            "Validation score: 0.256410\n",
            "Iteration 18, loss = 2.41395799\n",
            "Validation score: 0.256410\n",
            "Iteration 19, loss = 2.40520042\n",
            "Validation score: 0.256410\n",
            "Iteration 20, loss = 2.39694219\n",
            "Validation score: 0.256410\n",
            "Iteration 21, loss = 2.38955083\n",
            "Validation score: 0.252137\n",
            "Iteration 22, loss = 2.38176558\n",
            "Validation score: 0.247863\n",
            "Iteration 23, loss = 2.37368549\n",
            "Validation score: 0.247863\n",
            "Iteration 24, loss = 2.36705457\n",
            "Validation score: 0.264957\n",
            "Iteration 25, loss = 2.35936658\n",
            "Validation score: 0.264957\n",
            "Iteration 26, loss = 2.35330530\n",
            "Validation score: 0.264957\n",
            "Iteration 27, loss = 2.34694865\n",
            "Validation score: 0.277778\n",
            "Iteration 28, loss = 2.34092387\n",
            "Validation score: 0.286325\n",
            "Iteration 29, loss = 2.33400325\n",
            "Validation score: 0.264957\n",
            "Iteration 30, loss = 2.32775142\n",
            "Validation score: 0.269231\n",
            "Iteration 31, loss = 2.32156516\n",
            "Validation score: 0.264957\n",
            "Iteration 32, loss = 2.31357599\n",
            "Validation score: 0.294872\n",
            "Iteration 33, loss = 2.30731276\n",
            "Validation score: 0.273504\n",
            "Iteration 34, loss = 2.30174221\n",
            "Validation score: 0.286325\n",
            "Iteration 35, loss = 2.29633331\n",
            "Validation score: 0.273504\n",
            "Iteration 36, loss = 2.29070578\n",
            "Validation score: 0.273504\n",
            "Iteration 37, loss = 2.28508113\n",
            "Validation score: 0.260684\n",
            "Iteration 38, loss = 2.27990728\n",
            "Validation score: 0.264957\n",
            "Iteration 39, loss = 2.27472445\n",
            "Validation score: 0.273504\n",
            "Iteration 40, loss = 2.26929283\n",
            "Validation score: 0.247863\n",
            "Iteration 41, loss = 2.26382392\n",
            "Validation score: 0.252137\n",
            "Iteration 42, loss = 2.25920824\n",
            "Validation score: 0.252137\n",
            "Iteration 43, loss = 2.25425429\n",
            "Validation score: 0.260684\n",
            "Iteration 44, loss = 2.24938051\n",
            "Validation score: 0.256410\n",
            "Iteration 45, loss = 2.24409301\n",
            "Validation score: 0.256410\n",
            "Iteration 46, loss = 2.23897119\n",
            "Validation score: 0.235043\n",
            "Iteration 47, loss = 2.23411981\n",
            "Validation score: 0.243590\n",
            "Iteration 48, loss = 2.22961791\n",
            "Validation score: 0.239316\n",
            "Iteration 49, loss = 2.22511127\n",
            "Validation score: 0.247863\n",
            "Iteration 50, loss = 2.22143232\n",
            "Validation score: 0.243590\n",
            "Iteration 51, loss = 2.21775281\n",
            "Validation score: 0.247863\n",
            "Iteration 52, loss = 2.21375930\n",
            "Validation score: 0.252137\n",
            "Iteration 53, loss = 2.21089703\n",
            "Validation score: 0.256410\n",
            "Iteration 54, loss = 2.20772221\n",
            "Validation score: 0.256410\n",
            "Iteration 55, loss = 2.20425435\n",
            "Validation score: 0.247863\n",
            "Iteration 56, loss = 2.20161535\n",
            "Validation score: 0.247863\n",
            "Iteration 57, loss = 2.19855677\n",
            "Validation score: 0.260684\n",
            "Iteration 58, loss = 2.19591079\n",
            "Validation score: 0.260684\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.23249661\n",
            "Validation score: 0.000000\n",
            "Iteration 2, loss = 3.13562220\n",
            "Validation score: 0.128205\n",
            "Iteration 3, loss = 3.04983066\n",
            "Validation score: 0.128205\n",
            "Iteration 4, loss = 2.97422542\n",
            "Validation score: 0.128205\n",
            "Iteration 5, loss = 2.90818672\n",
            "Validation score: 0.128205\n",
            "Iteration 6, loss = 2.85112013\n",
            "Validation score: 0.128205\n",
            "Iteration 7, loss = 2.80182768\n",
            "Validation score: 0.128205\n",
            "Iteration 8, loss = 2.75933599\n",
            "Validation score: 0.128205\n",
            "Iteration 9, loss = 2.72320500\n",
            "Validation score: 0.128205\n",
            "Iteration 10, loss = 2.69234636\n",
            "Validation score: 0.128205\n",
            "Iteration 11, loss = 2.66615904\n",
            "Validation score: 0.128205\n",
            "Iteration 12, loss = 2.64393057\n",
            "Validation score: 0.128205\n",
            "Iteration 13, loss = 2.62499730\n",
            "Validation score: 0.128205\n",
            "Iteration 14, loss = 2.60894947\n",
            "Validation score: 0.128205\n",
            "Iteration 15, loss = 2.59520380\n",
            "Validation score: 0.128205\n",
            "Iteration 16, loss = 2.58363204\n",
            "Validation score: 0.128205\n",
            "Iteration 17, loss = 2.57354391\n",
            "Validation score: 0.128205\n",
            "Iteration 18, loss = 2.56503286\n",
            "Validation score: 0.128205\n",
            "Iteration 19, loss = 2.55776787\n",
            "Validation score: 0.128205\n",
            "Iteration 20, loss = 2.55162996\n",
            "Validation score: 0.128205\n",
            "Iteration 21, loss = 2.54618368\n",
            "Validation score: 0.128205\n",
            "Iteration 22, loss = 2.54150879\n",
            "Validation score: 0.128205\n",
            "Iteration 23, loss = 2.53750700\n",
            "Validation score: 0.128205\n",
            "Iteration 24, loss = 2.53409180\n",
            "Validation score: 0.128205\n",
            "Iteration 25, loss = 2.53101330\n",
            "Validation score: 0.128205\n",
            "Iteration 26, loss = 2.52832871\n",
            "Validation score: 0.128205\n",
            "Iteration 27, loss = 2.52593752\n",
            "Validation score: 0.128205\n",
            "Iteration 28, loss = 2.52400333\n",
            "Validation score: 0.128205\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.28526596\n",
            "Validation score: 0.000000\n",
            "Iteration 2, loss = 3.15593159\n",
            "Validation score: 0.141026\n",
            "Iteration 3, loss = 3.04059182\n",
            "Validation score: 0.183761\n",
            "Iteration 4, loss = 2.90867500\n",
            "Validation score: 0.183761\n",
            "Iteration 5, loss = 2.78090410\n",
            "Validation score: 0.183761\n",
            "Iteration 6, loss = 2.67905559\n",
            "Validation score: 0.183761\n",
            "Iteration 7, loss = 2.60776674\n",
            "Validation score: 0.183761\n",
            "Iteration 8, loss = 2.56194691\n",
            "Validation score: 0.175214\n",
            "Iteration 9, loss = 2.53302159\n",
            "Validation score: 0.136752\n",
            "Iteration 10, loss = 2.51420253\n",
            "Validation score: 0.136752\n",
            "Iteration 11, loss = 2.50062875\n",
            "Validation score: 0.136752\n",
            "Iteration 12, loss = 2.49012216\n",
            "Validation score: 0.132479\n",
            "Iteration 13, loss = 2.48183517\n",
            "Validation score: 0.141026\n",
            "Iteration 14, loss = 2.47513969\n",
            "Validation score: 0.132479\n",
            "Iteration 15, loss = 2.46984416\n",
            "Validation score: 0.132479\n",
            "Iteration 16, loss = 2.46498056\n",
            "Validation score: 0.132479\n",
            "Iteration 17, loss = 2.46073051\n",
            "Validation score: 0.132479\n",
            "Iteration 18, loss = 2.45655551\n",
            "Validation score: 0.132479\n",
            "Iteration 19, loss = 2.45266195\n",
            "Validation score: 0.132479\n",
            "Iteration 20, loss = 2.44866443\n",
            "Validation score: 0.132479\n",
            "Iteration 21, loss = 2.44455218\n",
            "Validation score: 0.132479\n",
            "Iteration 22, loss = 2.44069495\n",
            "Validation score: 0.132479\n",
            "Iteration 23, loss = 2.43656517\n",
            "Validation score: 0.132479\n",
            "Iteration 24, loss = 2.43270052\n",
            "Validation score: 0.132479\n",
            "Iteration 25, loss = 2.42864339\n",
            "Validation score: 0.132479\n",
            "Iteration 26, loss = 2.42479477\n",
            "Validation score: 0.132479\n",
            "Iteration 27, loss = 2.42055193\n",
            "Validation score: 0.132479\n",
            "Iteration 28, loss = 2.41638587\n",
            "Validation score: 0.145299\n",
            "Iteration 29, loss = 2.41233407\n",
            "Validation score: 0.149573\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.21331038\n",
            "Validation score: 0.102564\n",
            "Iteration 2, loss = 2.93170568\n",
            "Validation score: 0.128205\n",
            "Iteration 3, loss = 2.70276971\n",
            "Validation score: 0.128205\n",
            "Iteration 4, loss = 2.59499324\n",
            "Validation score: 0.128205\n",
            "Iteration 5, loss = 2.53854745\n",
            "Validation score: 0.175214\n",
            "Iteration 6, loss = 2.51512152\n",
            "Validation score: 0.175214\n",
            "Iteration 7, loss = 2.50567784\n",
            "Validation score: 0.175214\n",
            "Iteration 8, loss = 2.50061011\n",
            "Validation score: 0.175214\n",
            "Iteration 9, loss = 2.49607514\n",
            "Validation score: 0.183761\n",
            "Iteration 10, loss = 2.49229914\n",
            "Validation score: 0.192308\n",
            "Iteration 11, loss = 2.48861655\n",
            "Validation score: 0.213675\n",
            "Iteration 12, loss = 2.48520023\n",
            "Validation score: 0.196581\n",
            "Iteration 13, loss = 2.48216194\n",
            "Validation score: 0.196581\n",
            "Iteration 14, loss = 2.47774568\n",
            "Validation score: 0.222222\n",
            "Iteration 15, loss = 2.47432233\n",
            "Validation score: 0.192308\n",
            "Iteration 16, loss = 2.47091822\n",
            "Validation score: 0.209402\n",
            "Iteration 17, loss = 2.46638426\n",
            "Validation score: 0.209402\n",
            "Iteration 18, loss = 2.46186076\n",
            "Validation score: 0.183761\n",
            "Iteration 19, loss = 2.45772632\n",
            "Validation score: 0.209402\n",
            "Iteration 20, loss = 2.45267749\n",
            "Validation score: 0.209402\n",
            "Iteration 21, loss = 2.44812967\n",
            "Validation score: 0.179487\n",
            "Iteration 22, loss = 2.44294156\n",
            "Validation score: 0.200855\n",
            "Iteration 23, loss = 2.43778260\n",
            "Validation score: 0.196581\n",
            "Iteration 24, loss = 2.43289257\n",
            "Validation score: 0.200855\n",
            "Iteration 25, loss = 2.42559531\n",
            "Validation score: 0.196581\n",
            "Iteration 26, loss = 2.41863085\n",
            "Validation score: 0.213675\n",
            "Iteration 27, loss = 2.41211883\n",
            "Validation score: 0.196581\n",
            "Iteration 28, loss = 2.40407878\n",
            "Validation score: 0.188034\n",
            "Iteration 29, loss = 2.39648947\n",
            "Validation score: 0.205128\n",
            "Iteration 30, loss = 2.38739821\n",
            "Validation score: 0.205128\n",
            "Iteration 31, loss = 2.37820590\n",
            "Validation score: 0.200855\n",
            "Iteration 32, loss = 2.36863572\n",
            "Validation score: 0.192308\n",
            "Iteration 33, loss = 2.35932067\n",
            "Validation score: 0.179487\n",
            "Iteration 34, loss = 2.34920131\n",
            "Validation score: 0.209402\n",
            "Iteration 35, loss = 2.33921119\n",
            "Validation score: 0.196581\n",
            "Iteration 36, loss = 2.32911380\n",
            "Validation score: 0.170940\n",
            "Iteration 37, loss = 2.31966543\n",
            "Validation score: 0.175214\n",
            "Iteration 38, loss = 2.31092069\n",
            "Validation score: 0.166667\n",
            "Iteration 39, loss = 2.30184154\n",
            "Validation score: 0.175214\n",
            "Iteration 40, loss = 2.29283503\n",
            "Validation score: 0.175214\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.26206996\n",
            "Validation score: 0.179487\n",
            "Iteration 2, loss = 3.00233167\n",
            "Validation score: 0.149573\n",
            "Iteration 3, loss = 2.70847120\n",
            "Validation score: 0.149573\n",
            "Iteration 4, loss = 2.56506246\n",
            "Validation score: 0.158120\n",
            "Iteration 5, loss = 2.50786117\n",
            "Validation score: 0.162393\n",
            "Iteration 6, loss = 2.48265999\n",
            "Validation score: 0.179487\n",
            "Iteration 7, loss = 2.46832293\n",
            "Validation score: 0.179487\n",
            "Iteration 8, loss = 2.45703031\n",
            "Validation score: 0.179487\n",
            "Iteration 9, loss = 2.44744929\n",
            "Validation score: 0.179487\n",
            "Iteration 10, loss = 2.43908015\n",
            "Validation score: 0.183761\n",
            "Iteration 11, loss = 2.43002189\n",
            "Validation score: 0.183761\n",
            "Iteration 12, loss = 2.42191127\n",
            "Validation score: 0.188034\n",
            "Iteration 13, loss = 2.41379969\n",
            "Validation score: 0.188034\n",
            "Iteration 14, loss = 2.40581865\n",
            "Validation score: 0.192308\n",
            "Iteration 15, loss = 2.39810926\n",
            "Validation score: 0.192308\n",
            "Iteration 16, loss = 2.38988551\n",
            "Validation score: 0.192308\n",
            "Iteration 17, loss = 2.38268394\n",
            "Validation score: 0.192308\n",
            "Iteration 18, loss = 2.37529557\n",
            "Validation score: 0.188034\n",
            "Iteration 19, loss = 2.36882002\n",
            "Validation score: 0.192308\n",
            "Iteration 20, loss = 2.36183200\n",
            "Validation score: 0.196581\n",
            "Iteration 21, loss = 2.35566351\n",
            "Validation score: 0.196581\n",
            "Iteration 22, loss = 2.34905807\n",
            "Validation score: 0.196581\n",
            "Iteration 23, loss = 2.34373829\n",
            "Validation score: 0.196581\n",
            "Iteration 24, loss = 2.33767102\n",
            "Validation score: 0.205128\n",
            "Iteration 25, loss = 2.33229501\n",
            "Validation score: 0.200855\n",
            "Iteration 26, loss = 2.32684831\n",
            "Validation score: 0.205128\n",
            "Iteration 27, loss = 2.32176068\n",
            "Validation score: 0.196581\n",
            "Iteration 28, loss = 2.31696985\n",
            "Validation score: 0.209402\n",
            "Iteration 29, loss = 2.31255832\n",
            "Validation score: 0.205128\n",
            "Iteration 30, loss = 2.30740402\n",
            "Validation score: 0.192308\n",
            "Iteration 31, loss = 2.30345537\n",
            "Validation score: 0.205128\n",
            "Iteration 32, loss = 2.29893654\n",
            "Validation score: 0.205128\n",
            "Iteration 33, loss = 2.29458703\n",
            "Validation score: 0.205128\n",
            "Iteration 34, loss = 2.29116029\n",
            "Validation score: 0.209402\n",
            "Iteration 35, loss = 2.28718538\n",
            "Validation score: 0.213675\n",
            "Iteration 36, loss = 2.28362761\n",
            "Validation score: 0.196581\n",
            "Iteration 37, loss = 2.28075198\n",
            "Validation score: 0.196581\n",
            "Iteration 38, loss = 2.27708291\n",
            "Validation score: 0.209402\n",
            "Iteration 39, loss = 2.27397837\n",
            "Validation score: 0.205128\n",
            "Iteration 40, loss = 2.27131777\n",
            "Validation score: 0.213675\n",
            "Iteration 41, loss = 2.26770604\n",
            "Validation score: 0.205128\n",
            "Iteration 42, loss = 2.26577198\n",
            "Validation score: 0.209402\n",
            "Iteration 43, loss = 2.26320502\n",
            "Validation score: 0.209402\n",
            "Iteration 44, loss = 2.26071030\n",
            "Validation score: 0.205128\n",
            "Iteration 45, loss = 2.25739677\n",
            "Validation score: 0.209402\n",
            "Iteration 46, loss = 2.25507011\n",
            "Validation score: 0.213675\n",
            "Iteration 47, loss = 2.25307354\n",
            "Validation score: 0.217949\n",
            "Iteration 48, loss = 2.25013916\n",
            "Validation score: 0.217949\n",
            "Iteration 49, loss = 2.24789451\n",
            "Validation score: 0.192308\n",
            "Iteration 50, loss = 2.24631029\n",
            "Validation score: 0.205128\n",
            "Iteration 51, loss = 2.24439404\n",
            "Validation score: 0.205128\n",
            "Iteration 52, loss = 2.24229616\n",
            "Validation score: 0.200855\n",
            "Iteration 53, loss = 2.24023049\n",
            "Validation score: 0.200855\n",
            "Iteration 54, loss = 2.23899370\n",
            "Validation score: 0.213675\n",
            "Iteration 55, loss = 2.23695960\n",
            "Validation score: 0.205128\n",
            "Iteration 56, loss = 2.23475046\n",
            "Validation score: 0.196581\n",
            "Iteration 57, loss = 2.23321110\n",
            "Validation score: 0.196581\n",
            "Iteration 58, loss = 2.23169720\n",
            "Validation score: 0.200855\n",
            "Iteration 59, loss = 2.23039418\n",
            "Validation score: 0.192308\n",
            "Iteration 60, loss = 2.22883652\n",
            "Validation score: 0.196581\n",
            "Iteration 61, loss = 2.22710064\n",
            "Validation score: 0.213675\n",
            "Iteration 62, loss = 2.22584645\n",
            "Validation score: 0.200855\n",
            "Iteration 63, loss = 2.22458877\n",
            "Validation score: 0.205128\n",
            "Iteration 64, loss = 2.22286733\n",
            "Validation score: 0.205128\n",
            "Iteration 65, loss = 2.22162445\n",
            "Validation score: 0.200855\n",
            "Iteration 66, loss = 2.22080999\n",
            "Validation score: 0.209402\n",
            "Iteration 67, loss = 2.21867529\n",
            "Validation score: 0.222222\n",
            "Iteration 68, loss = 2.21779008\n",
            "Validation score: 0.213675\n",
            "Iteration 69, loss = 2.21618930\n",
            "Validation score: 0.222222\n",
            "Iteration 70, loss = 2.21543079\n",
            "Validation score: 0.217949\n",
            "Iteration 71, loss = 2.21412144\n",
            "Validation score: 0.226496\n",
            "Iteration 72, loss = 2.21263094\n",
            "Validation score: 0.226496\n",
            "Iteration 73, loss = 2.21212842\n",
            "Validation score: 0.209402\n",
            "Iteration 74, loss = 2.21072318\n",
            "Validation score: 0.235043\n",
            "Iteration 75, loss = 2.21008090\n",
            "Validation score: 0.222222\n",
            "Iteration 76, loss = 2.20835205\n",
            "Validation score: 0.226496\n",
            "Iteration 77, loss = 2.20769197\n",
            "Validation score: 0.230769\n",
            "Iteration 78, loss = 2.20672497\n",
            "Validation score: 0.226496\n",
            "Iteration 79, loss = 2.20543744\n",
            "Validation score: 0.222222\n",
            "Iteration 80, loss = 2.20467426\n",
            "Validation score: 0.213675\n",
            "Iteration 81, loss = 2.20366597\n",
            "Validation score: 0.213675\n",
            "Iteration 82, loss = 2.20241238\n",
            "Validation score: 0.230769\n",
            "Iteration 83, loss = 2.20117475\n",
            "Validation score: 0.213675\n",
            "Iteration 84, loss = 2.20043836\n",
            "Validation score: 0.217949\n",
            "Iteration 85, loss = 2.19936853\n",
            "Validation score: 0.213675\n",
            "Iteration 86, loss = 2.19770212\n",
            "Validation score: 0.243590\n",
            "Iteration 87, loss = 2.19827993\n",
            "Validation score: 0.247863\n",
            "Iteration 88, loss = 2.19659378\n",
            "Validation score: 0.230769\n",
            "Iteration 89, loss = 2.19584789\n",
            "Validation score: 0.222222\n",
            "Iteration 90, loss = 2.19467438\n",
            "Validation score: 0.226496\n",
            "Iteration 91, loss = 2.19373410\n",
            "Validation score: 0.230769\n",
            "Iteration 92, loss = 2.19216669\n",
            "Validation score: 0.226496\n",
            "Iteration 93, loss = 2.19092042\n",
            "Validation score: 0.230769\n",
            "Iteration 94, loss = 2.18991567\n",
            "Validation score: 0.226496\n",
            "Iteration 95, loss = 2.18979414\n",
            "Validation score: 0.235043\n",
            "Iteration 96, loss = 2.18753767\n",
            "Validation score: 0.239316\n",
            "Iteration 97, loss = 2.18723317\n",
            "Validation score: 0.235043\n",
            "Iteration 98, loss = 2.18590985\n",
            "Validation score: 0.239316\n",
            "Iteration 99, loss = 2.18512904\n",
            "Validation score: 0.239316\n",
            "Iteration 100, loss = 2.18385677\n",
            "Validation score: 0.230769\n",
            "Iteration 101, loss = 2.18332044\n",
            "Validation score: 0.213675\n",
            "Iteration 102, loss = 2.18224540\n",
            "Validation score: 0.230769\n",
            "Iteration 103, loss = 2.18116299\n",
            "Validation score: 0.252137\n",
            "Iteration 104, loss = 2.18090283\n",
            "Validation score: 0.252137\n",
            "Iteration 105, loss = 2.17993784\n",
            "Validation score: 0.252137\n",
            "Iteration 106, loss = 2.17951552\n",
            "Validation score: 0.256410\n",
            "Iteration 107, loss = 2.17844247\n",
            "Validation score: 0.269231\n",
            "Iteration 108, loss = 2.17737936\n",
            "Validation score: 0.252137\n",
            "Iteration 109, loss = 2.17660202\n",
            "Validation score: 0.260684\n",
            "Iteration 110, loss = 2.17565858\n",
            "Validation score: 0.273504\n",
            "Iteration 111, loss = 2.17541549\n",
            "Validation score: 0.264957\n",
            "Iteration 112, loss = 2.17432452\n",
            "Validation score: 0.269231\n",
            "Iteration 113, loss = 2.17369305\n",
            "Validation score: 0.269231\n",
            "Iteration 114, loss = 2.17297839\n",
            "Validation score: 0.260684\n",
            "Iteration 115, loss = 2.17109827\n",
            "Validation score: 0.273504\n",
            "Iteration 116, loss = 2.17118809\n",
            "Validation score: 0.264957\n",
            "Iteration 117, loss = 2.17054606\n",
            "Validation score: 0.277778\n",
            "Iteration 118, loss = 2.16910577\n",
            "Validation score: 0.264957\n",
            "Iteration 119, loss = 2.16860781\n",
            "Validation score: 0.273504\n",
            "Iteration 120, loss = 2.16822754\n",
            "Validation score: 0.264957\n",
            "Iteration 121, loss = 2.16734329\n",
            "Validation score: 0.260684\n",
            "Iteration 122, loss = 2.16604107\n",
            "Validation score: 0.260684\n",
            "Iteration 123, loss = 2.16604936\n",
            "Validation score: 0.269231\n",
            "Iteration 124, loss = 2.16523927\n",
            "Validation score: 0.264957\n",
            "Iteration 125, loss = 2.16489677\n",
            "Validation score: 0.269231\n",
            "Iteration 126, loss = 2.16392270\n",
            "Validation score: 0.260684\n",
            "Iteration 127, loss = 2.16330118\n",
            "Validation score: 0.260684\n",
            "Iteration 128, loss = 2.16178225\n",
            "Validation score: 0.273504\n",
            "Iteration 129, loss = 2.16144824\n",
            "Validation score: 0.273504\n",
            "Iteration 130, loss = 2.16078955\n",
            "Validation score: 0.260684\n",
            "Iteration 131, loss = 2.16069906\n",
            "Validation score: 0.260684\n",
            "Iteration 132, loss = 2.16071398\n",
            "Validation score: 0.277778\n",
            "Iteration 133, loss = 2.15880918\n",
            "Validation score: 0.269231\n",
            "Iteration 134, loss = 2.15891208\n",
            "Validation score: 0.264957\n",
            "Iteration 135, loss = 2.15852223\n",
            "Validation score: 0.260684\n",
            "Iteration 136, loss = 2.15796903\n",
            "Validation score: 0.277778\n",
            "Iteration 137, loss = 2.15701558\n",
            "Validation score: 0.277778\n",
            "Iteration 138, loss = 2.15650507\n",
            "Validation score: 0.264957\n",
            "Iteration 139, loss = 2.15581001\n",
            "Validation score: 0.269231\n",
            "Iteration 140, loss = 2.15506291\n",
            "Validation score: 0.260684\n",
            "Iteration 141, loss = 2.15435503\n",
            "Validation score: 0.269231\n",
            "Iteration 142, loss = 2.15391151\n",
            "Validation score: 0.260684\n",
            "Iteration 143, loss = 2.15360825\n",
            "Validation score: 0.260684\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.18494505\n",
            "Validation score: 0.025641\n",
            "Iteration 2, loss = 3.02886513\n",
            "Validation score: 0.179487\n",
            "Iteration 3, loss = 2.77365462\n",
            "Validation score: 0.149573\n",
            "Iteration 4, loss = 2.59140122\n",
            "Validation score: 0.162393\n",
            "Iteration 5, loss = 2.50146602\n",
            "Validation score: 0.170940\n",
            "Iteration 6, loss = 2.46707548\n",
            "Validation score: 0.166667\n",
            "Iteration 7, loss = 2.44886197\n",
            "Validation score: 0.166667\n",
            "Iteration 8, loss = 2.43363092\n",
            "Validation score: 0.192308\n",
            "Iteration 9, loss = 2.42136409\n",
            "Validation score: 0.213675\n",
            "Iteration 10, loss = 2.40939613\n",
            "Validation score: 0.200855\n",
            "Iteration 11, loss = 2.39897071\n",
            "Validation score: 0.222222\n",
            "Iteration 12, loss = 2.38792631\n",
            "Validation score: 0.222222\n",
            "Iteration 13, loss = 2.37860721\n",
            "Validation score: 0.217949\n",
            "Iteration 14, loss = 2.36835562\n",
            "Validation score: 0.226496\n",
            "Iteration 15, loss = 2.36007664\n",
            "Validation score: 0.230769\n",
            "Iteration 16, loss = 2.35132055\n",
            "Validation score: 0.235043\n",
            "Iteration 17, loss = 2.34336042\n",
            "Validation score: 0.235043\n",
            "Iteration 18, loss = 2.33577273\n",
            "Validation score: 0.239316\n",
            "Iteration 19, loss = 2.32832011\n",
            "Validation score: 0.239316\n",
            "Iteration 20, loss = 2.32119080\n",
            "Validation score: 0.243590\n",
            "Iteration 21, loss = 2.31485414\n",
            "Validation score: 0.247863\n",
            "Iteration 22, loss = 2.30760432\n",
            "Validation score: 0.239316\n",
            "Iteration 23, loss = 2.30200895\n",
            "Validation score: 0.235043\n",
            "Iteration 24, loss = 2.29629284\n",
            "Validation score: 0.247863\n",
            "Iteration 25, loss = 2.29108974\n",
            "Validation score: 0.235043\n",
            "Iteration 26, loss = 2.28561132\n",
            "Validation score: 0.235043\n",
            "Iteration 27, loss = 2.28069217\n",
            "Validation score: 0.235043\n",
            "Iteration 28, loss = 2.27586353\n",
            "Validation score: 0.235043\n",
            "Iteration 29, loss = 2.27160199\n",
            "Validation score: 0.235043\n",
            "Iteration 30, loss = 2.26740316\n",
            "Validation score: 0.226496\n",
            "Iteration 31, loss = 2.26310949\n",
            "Validation score: 0.226496\n",
            "Iteration 32, loss = 2.25976163\n",
            "Validation score: 0.226496\n",
            "Iteration 33, loss = 2.25598183\n",
            "Validation score: 0.222222\n",
            "Iteration 34, loss = 2.25233669\n",
            "Validation score: 0.226496\n",
            "Iteration 35, loss = 2.24892571\n",
            "Validation score: 0.222222\n",
            "Iteration 36, loss = 2.24633792\n",
            "Validation score: 0.222222\n",
            "Iteration 37, loss = 2.24252757\n",
            "Validation score: 0.213675\n",
            "Iteration 38, loss = 2.23973575\n",
            "Validation score: 0.230769\n",
            "Iteration 39, loss = 2.23732406\n",
            "Validation score: 0.235043\n",
            "Iteration 40, loss = 2.23428769\n",
            "Validation score: 0.239316\n",
            "Iteration 41, loss = 2.23201508\n",
            "Validation score: 0.239316\n",
            "Iteration 42, loss = 2.22968694\n",
            "Validation score: 0.252137\n",
            "Iteration 43, loss = 2.22725522\n",
            "Validation score: 0.226496\n",
            "Iteration 44, loss = 2.22525515\n",
            "Validation score: 0.222222\n",
            "Iteration 45, loss = 2.22331784\n",
            "Validation score: 0.235043\n",
            "Iteration 46, loss = 2.22056866\n",
            "Validation score: 0.217949\n",
            "Iteration 47, loss = 2.21923130\n",
            "Validation score: 0.243590\n",
            "Iteration 48, loss = 2.21724790\n",
            "Validation score: 0.239316\n",
            "Iteration 49, loss = 2.21547411\n",
            "Validation score: 0.247863\n",
            "Iteration 50, loss = 2.21398405\n",
            "Validation score: 0.243590\n",
            "Iteration 51, loss = 2.21145800\n",
            "Validation score: 0.217949\n",
            "Iteration 52, loss = 2.21085949\n",
            "Validation score: 0.243590\n",
            "Iteration 53, loss = 2.20924495\n",
            "Validation score: 0.247863\n",
            "Iteration 54, loss = 2.20741691\n",
            "Validation score: 0.217949\n",
            "Iteration 55, loss = 2.20586354\n",
            "Validation score: 0.239316\n",
            "Iteration 56, loss = 2.20430045\n",
            "Validation score: 0.243590\n",
            "Iteration 57, loss = 2.20344383\n",
            "Validation score: 0.235043\n",
            "Iteration 58, loss = 2.20192623\n",
            "Validation score: 0.247863\n",
            "Iteration 59, loss = 2.20044207\n",
            "Validation score: 0.222222\n",
            "Iteration 60, loss = 2.20041148\n",
            "Validation score: 0.222222\n",
            "Iteration 61, loss = 2.19841272\n",
            "Validation score: 0.247863\n",
            "Iteration 62, loss = 2.19709020\n",
            "Validation score: 0.243590\n",
            "Iteration 63, loss = 2.19602482\n",
            "Validation score: 0.252137\n",
            "Iteration 64, loss = 2.19507056\n",
            "Validation score: 0.252137\n",
            "Iteration 65, loss = 2.19401484\n",
            "Validation score: 0.243590\n",
            "Iteration 66, loss = 2.19254715\n",
            "Validation score: 0.247863\n",
            "Iteration 67, loss = 2.19192547\n",
            "Validation score: 0.247863\n",
            "Iteration 68, loss = 2.19065844\n",
            "Validation score: 0.247863\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.14533780\n",
            "Validation score: 0.145299\n",
            "Iteration 2, loss = 3.05830240\n",
            "Validation score: 0.145299\n",
            "Iteration 3, loss = 2.98213517\n",
            "Validation score: 0.145299\n",
            "Iteration 4, loss = 2.91550926\n",
            "Validation score: 0.145299\n",
            "Iteration 5, loss = 2.85782375\n",
            "Validation score: 0.145299\n",
            "Iteration 6, loss = 2.80779340\n",
            "Validation score: 0.145299\n",
            "Iteration 7, loss = 2.76489518\n",
            "Validation score: 0.145299\n",
            "Iteration 8, loss = 2.72807997\n",
            "Validation score: 0.145299\n",
            "Iteration 9, loss = 2.69636402\n",
            "Validation score: 0.145299\n",
            "Iteration 10, loss = 2.66910002\n",
            "Validation score: 0.145299\n",
            "Iteration 11, loss = 2.64591089\n",
            "Validation score: 0.141026\n",
            "Iteration 12, loss = 2.62590630\n",
            "Validation score: 0.141026\n",
            "Iteration 13, loss = 2.60896639\n",
            "Validation score: 0.141026\n",
            "Iteration 14, loss = 2.59443980\n",
            "Validation score: 0.141026\n",
            "Iteration 15, loss = 2.58204001\n",
            "Validation score: 0.141026\n",
            "Iteration 16, loss = 2.57150353\n",
            "Validation score: 0.141026\n",
            "Iteration 17, loss = 2.56249358\n",
            "Validation score: 0.141026\n",
            "Iteration 18, loss = 2.55483892\n",
            "Validation score: 0.141026\n",
            "Iteration 19, loss = 2.54821558\n",
            "Validation score: 0.141026\n",
            "Iteration 20, loss = 2.54270212\n",
            "Validation score: 0.141026\n",
            "Iteration 21, loss = 2.53787202\n",
            "Validation score: 0.141026\n",
            "Iteration 22, loss = 2.53374181\n",
            "Validation score: 0.141026\n",
            "Iteration 23, loss = 2.53018803\n",
            "Validation score: 0.141026\n",
            "Iteration 24, loss = 2.52715642\n",
            "Validation score: 0.141026\n",
            "Iteration 25, loss = 2.52453675\n",
            "Validation score: 0.141026\n",
            "Iteration 26, loss = 2.52219695\n",
            "Validation score: 0.141026\n",
            "Iteration 27, loss = 2.52011810\n",
            "Validation score: 0.141026\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.10826608\n",
            "Validation score: 0.145299\n",
            "Iteration 2, loss = 2.83095473\n",
            "Validation score: 0.132479\n",
            "Iteration 3, loss = 2.63772119\n",
            "Validation score: 0.132479\n",
            "Iteration 4, loss = 2.56218054\n",
            "Validation score: 0.106838\n",
            "Iteration 5, loss = 2.53206833\n",
            "Validation score: 0.098291\n",
            "Iteration 6, loss = 2.51843941\n",
            "Validation score: 0.102564\n",
            "Iteration 7, loss = 2.50955329\n",
            "Validation score: 0.106838\n",
            "Iteration 8, loss = 2.50327541\n",
            "Validation score: 0.102564\n",
            "Iteration 9, loss = 2.49770585\n",
            "Validation score: 0.102564\n",
            "Iteration 10, loss = 2.49255101\n",
            "Validation score: 0.111111\n",
            "Iteration 11, loss = 2.48802825\n",
            "Validation score: 0.111111\n",
            "Iteration 12, loss = 2.48418636\n",
            "Validation score: 0.111111\n",
            "Iteration 13, loss = 2.47886076\n",
            "Validation score: 0.119658\n",
            "Iteration 14, loss = 2.47470889\n",
            "Validation score: 0.132479\n",
            "Iteration 15, loss = 2.46990774\n",
            "Validation score: 0.119658\n",
            "Iteration 16, loss = 2.46549120\n",
            "Validation score: 0.162393\n",
            "Iteration 17, loss = 2.46005233\n",
            "Validation score: 0.158120\n",
            "Iteration 18, loss = 2.45479953\n",
            "Validation score: 0.158120\n",
            "Iteration 19, loss = 2.44954831\n",
            "Validation score: 0.128205\n",
            "Iteration 20, loss = 2.44437490\n",
            "Validation score: 0.141026\n",
            "Iteration 21, loss = 2.43890563\n",
            "Validation score: 0.149573\n",
            "Iteration 22, loss = 2.43359934\n",
            "Validation score: 0.175214\n",
            "Iteration 23, loss = 2.42848841\n",
            "Validation score: 0.179487\n",
            "Iteration 24, loss = 2.42327907\n",
            "Validation score: 0.175214\n",
            "Iteration 25, loss = 2.41809485\n",
            "Validation score: 0.158120\n",
            "Iteration 26, loss = 2.41286744\n",
            "Validation score: 0.153846\n",
            "Iteration 27, loss = 2.40776292\n",
            "Validation score: 0.170940\n",
            "Iteration 28, loss = 2.40191736\n",
            "Validation score: 0.162393\n",
            "Iteration 29, loss = 2.39694876\n",
            "Validation score: 0.183761\n",
            "Iteration 30, loss = 2.39144380\n",
            "Validation score: 0.192308\n",
            "Iteration 31, loss = 2.38657776\n",
            "Validation score: 0.188034\n",
            "Iteration 32, loss = 2.38104972\n",
            "Validation score: 0.183761\n",
            "Iteration 33, loss = 2.37575871\n",
            "Validation score: 0.192308\n",
            "Iteration 34, loss = 2.37090237\n",
            "Validation score: 0.192308\n",
            "Iteration 35, loss = 2.36551052\n",
            "Validation score: 0.196581\n",
            "Iteration 36, loss = 2.36098636\n",
            "Validation score: 0.196581\n",
            "Iteration 37, loss = 2.35576492\n",
            "Validation score: 0.188034\n",
            "Iteration 38, loss = 2.35089183\n",
            "Validation score: 0.196581\n",
            "Iteration 39, loss = 2.34599766\n",
            "Validation score: 0.183761\n",
            "Iteration 40, loss = 2.34207977\n",
            "Validation score: 0.170940\n",
            "Iteration 41, loss = 2.33700244\n",
            "Validation score: 0.192308\n",
            "Iteration 42, loss = 2.33253627\n",
            "Validation score: 0.196581\n",
            "Iteration 43, loss = 2.32852828\n",
            "Validation score: 0.192308\n",
            "Iteration 44, loss = 2.32425870\n",
            "Validation score: 0.192308\n",
            "Iteration 45, loss = 2.32098120\n",
            "Validation score: 0.192308\n",
            "Iteration 46, loss = 2.31661779\n",
            "Validation score: 0.192308\n",
            "Iteration 47, loss = 2.31275086\n",
            "Validation score: 0.192308\n",
            "Iteration 48, loss = 2.30972994\n",
            "Validation score: 0.188034\n",
            "Iteration 49, loss = 2.30579557\n",
            "Validation score: 0.192308\n",
            "Iteration 50, loss = 2.30270242\n",
            "Validation score: 0.192308\n",
            "Iteration 51, loss = 2.29903837\n",
            "Validation score: 0.192308\n",
            "Iteration 52, loss = 2.29611692\n",
            "Validation score: 0.192308\n",
            "Iteration 53, loss = 2.29329055\n",
            "Validation score: 0.192308\n",
            "Iteration 54, loss = 2.29076637\n",
            "Validation score: 0.196581\n",
            "Iteration 55, loss = 2.28830235\n",
            "Validation score: 0.192308\n",
            "Iteration 56, loss = 2.28532617\n",
            "Validation score: 0.196581\n",
            "Iteration 57, loss = 2.28301998\n",
            "Validation score: 0.196581\n",
            "Iteration 58, loss = 2.27992232\n",
            "Validation score: 0.192308\n",
            "Iteration 59, loss = 2.27779144\n",
            "Validation score: 0.200855\n",
            "Iteration 60, loss = 2.27535573\n",
            "Validation score: 0.205128\n",
            "Iteration 61, loss = 2.27302043\n",
            "Validation score: 0.196581\n",
            "Iteration 62, loss = 2.27062514\n",
            "Validation score: 0.213675\n",
            "Iteration 63, loss = 2.26930527\n",
            "Validation score: 0.213675\n",
            "Iteration 64, loss = 2.26605822\n",
            "Validation score: 0.209402\n",
            "Iteration 65, loss = 2.26463298\n",
            "Validation score: 0.213675\n",
            "Iteration 66, loss = 2.26261907\n",
            "Validation score: 0.213675\n",
            "Iteration 67, loss = 2.26091290\n",
            "Validation score: 0.217949\n",
            "Iteration 68, loss = 2.25935232\n",
            "Validation score: 0.217949\n",
            "Iteration 69, loss = 2.25791493\n",
            "Validation score: 0.222222\n",
            "Iteration 70, loss = 2.25714062\n",
            "Validation score: 0.217949\n",
            "Iteration 71, loss = 2.25432729\n",
            "Validation score: 0.217949\n",
            "Iteration 72, loss = 2.25292670\n",
            "Validation score: 0.217949\n",
            "Iteration 73, loss = 2.25206808\n",
            "Validation score: 0.226496\n",
            "Iteration 74, loss = 2.25007070\n",
            "Validation score: 0.217949\n",
            "Iteration 75, loss = 2.24914516\n",
            "Validation score: 0.222222\n",
            "Iteration 76, loss = 2.24782367\n",
            "Validation score: 0.213675\n",
            "Iteration 77, loss = 2.24674869\n",
            "Validation score: 0.230769\n",
            "Iteration 78, loss = 2.24546375\n",
            "Validation score: 0.217949\n",
            "Iteration 79, loss = 2.24399611\n",
            "Validation score: 0.222222\n",
            "Iteration 80, loss = 2.24274825\n",
            "Validation score: 0.209402\n",
            "Iteration 81, loss = 2.24155650\n",
            "Validation score: 0.222222\n",
            "Iteration 82, loss = 2.24041960\n",
            "Validation score: 0.230769\n",
            "Iteration 83, loss = 2.23878411\n",
            "Validation score: 0.222222\n",
            "Iteration 84, loss = 2.23811037\n",
            "Validation score: 0.230769\n",
            "Iteration 85, loss = 2.23704102\n",
            "Validation score: 0.222222\n",
            "Iteration 86, loss = 2.23622141\n",
            "Validation score: 0.226496\n",
            "Iteration 87, loss = 2.23478625\n",
            "Validation score: 0.222222\n",
            "Iteration 88, loss = 2.23314655\n",
            "Validation score: 0.230769\n",
            "Iteration 89, loss = 2.23305592\n",
            "Validation score: 0.226496\n",
            "Iteration 90, loss = 2.23190095\n",
            "Validation score: 0.226496\n",
            "Iteration 91, loss = 2.23099051\n",
            "Validation score: 0.239316\n",
            "Iteration 92, loss = 2.23050724\n",
            "Validation score: 0.222222\n",
            "Iteration 93, loss = 2.22943606\n",
            "Validation score: 0.222222\n",
            "Iteration 94, loss = 2.22792758\n",
            "Validation score: 0.235043\n",
            "Iteration 95, loss = 2.22751895\n",
            "Validation score: 0.222222\n",
            "Iteration 96, loss = 2.22692945\n",
            "Validation score: 0.222222\n",
            "Iteration 97, loss = 2.22508161\n",
            "Validation score: 0.239316\n",
            "Iteration 98, loss = 2.22444190\n",
            "Validation score: 0.235043\n",
            "Iteration 99, loss = 2.22381920\n",
            "Validation score: 0.239316\n",
            "Iteration 100, loss = 2.22308827\n",
            "Validation score: 0.230769\n",
            "Iteration 101, loss = 2.22204685\n",
            "Validation score: 0.230769\n",
            "Iteration 102, loss = 2.22120974\n",
            "Validation score: 0.235043\n",
            "Iteration 103, loss = 2.22021942\n",
            "Validation score: 0.239316\n",
            "Iteration 104, loss = 2.21924203\n",
            "Validation score: 0.239316\n",
            "Iteration 105, loss = 2.21950089\n",
            "Validation score: 0.239316\n",
            "Iteration 106, loss = 2.21867110\n",
            "Validation score: 0.239316\n",
            "Iteration 107, loss = 2.21730007\n",
            "Validation score: 0.247863\n",
            "Iteration 108, loss = 2.21703540\n",
            "Validation score: 0.239316\n",
            "Iteration 109, loss = 2.21650914\n",
            "Validation score: 0.235043\n",
            "Iteration 110, loss = 2.21478321\n",
            "Validation score: 0.235043\n",
            "Iteration 111, loss = 2.21492328\n",
            "Validation score: 0.230769\n",
            "Iteration 112, loss = 2.21356391\n",
            "Validation score: 0.230769\n",
            "Iteration 113, loss = 2.21290296\n",
            "Validation score: 0.252137\n",
            "Iteration 114, loss = 2.21188901\n",
            "Validation score: 0.235043\n",
            "Iteration 115, loss = 2.21107668\n",
            "Validation score: 0.256410\n",
            "Iteration 116, loss = 2.21039507\n",
            "Validation score: 0.235043\n",
            "Iteration 117, loss = 2.20933241\n",
            "Validation score: 0.235043\n",
            "Iteration 118, loss = 2.20897969\n",
            "Validation score: 0.247863\n",
            "Iteration 119, loss = 2.20757612\n",
            "Validation score: 0.235043\n",
            "Iteration 120, loss = 2.20749170\n",
            "Validation score: 0.243590\n",
            "Iteration 121, loss = 2.20601150\n",
            "Validation score: 0.230769\n",
            "Iteration 122, loss = 2.20475300\n",
            "Validation score: 0.239316\n",
            "Iteration 123, loss = 2.20435060\n",
            "Validation score: 0.230769\n",
            "Iteration 124, loss = 2.20323904\n",
            "Validation score: 0.235043\n",
            "Iteration 125, loss = 2.20312070\n",
            "Validation score: 0.247863\n",
            "Iteration 126, loss = 2.20199757\n",
            "Validation score: 0.235043\n",
            "Iteration 127, loss = 2.20131434\n",
            "Validation score: 0.239316\n",
            "Iteration 128, loss = 2.19955960\n",
            "Validation score: 0.243590\n",
            "Iteration 129, loss = 2.19950676\n",
            "Validation score: 0.252137\n",
            "Iteration 130, loss = 2.19702268\n",
            "Validation score: 0.217949\n",
            "Iteration 131, loss = 2.19908577\n",
            "Validation score: 0.243590\n",
            "Iteration 132, loss = 2.19743998\n",
            "Validation score: 0.243590\n",
            "Iteration 133, loss = 2.19589556\n",
            "Validation score: 0.243590\n",
            "Iteration 134, loss = 2.19459823\n",
            "Validation score: 0.239316\n",
            "Iteration 135, loss = 2.19452555\n",
            "Validation score: 0.243590\n",
            "Iteration 136, loss = 2.19270478\n",
            "Validation score: 0.247863\n",
            "Iteration 137, loss = 2.19217606\n",
            "Validation score: 0.252137\n",
            "Iteration 138, loss = 2.19142900\n",
            "Validation score: 0.239316\n",
            "Iteration 139, loss = 2.19055438\n",
            "Validation score: 0.243590\n",
            "Iteration 140, loss = 2.18866729\n",
            "Validation score: 0.247863\n",
            "Iteration 141, loss = 2.18835215\n",
            "Validation score: 0.252137\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.29518498\n",
            "Validation score: 0.055556\n",
            "Iteration 2, loss = 3.19128241\n",
            "Validation score: 0.183761\n",
            "Iteration 3, loss = 3.10062299\n",
            "Validation score: 0.183761\n",
            "Iteration 4, loss = 3.02052039\n",
            "Validation score: 0.183761\n",
            "Iteration 5, loss = 2.95080317\n",
            "Validation score: 0.183761\n",
            "Iteration 6, loss = 2.89003668\n",
            "Validation score: 0.183761\n",
            "Iteration 7, loss = 2.83770865\n",
            "Validation score: 0.183761\n",
            "Iteration 8, loss = 2.79254277\n",
            "Validation score: 0.183761\n",
            "Iteration 9, loss = 2.75375748\n",
            "Validation score: 0.183761\n",
            "Iteration 10, loss = 2.72029029\n",
            "Validation score: 0.183761\n",
            "Iteration 11, loss = 2.69172329\n",
            "Validation score: 0.183761\n",
            "Iteration 12, loss = 2.66742139\n",
            "Validation score: 0.183761\n",
            "Iteration 13, loss = 2.64661233\n",
            "Validation score: 0.183761\n",
            "Iteration 14, loss = 2.62884395\n",
            "Validation score: 0.183761\n",
            "Iteration 15, loss = 2.61352821\n",
            "Validation score: 0.183761\n",
            "Iteration 16, loss = 2.60051802\n",
            "Validation score: 0.183761\n",
            "Iteration 17, loss = 2.58940027\n",
            "Validation score: 0.183761\n",
            "Iteration 18, loss = 2.57983104\n",
            "Validation score: 0.183761\n",
            "Iteration 19, loss = 2.57155261\n",
            "Validation score: 0.183761\n",
            "Iteration 20, loss = 2.56466845\n",
            "Validation score: 0.183761\n",
            "Iteration 21, loss = 2.55847167\n",
            "Validation score: 0.183761\n",
            "Iteration 22, loss = 2.55312898\n",
            "Validation score: 0.183761\n",
            "Iteration 23, loss = 2.54866099\n",
            "Validation score: 0.183761\n",
            "Iteration 24, loss = 2.54463856\n",
            "Validation score: 0.183761\n",
            "Iteration 25, loss = 2.54125573\n",
            "Validation score: 0.183761\n",
            "Iteration 26, loss = 2.53817770\n",
            "Validation score: 0.183761\n",
            "Iteration 27, loss = 2.53547915\n",
            "Validation score: 0.183761\n",
            "Iteration 28, loss = 2.53309575\n",
            "Validation score: 0.183761\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.20580933\n",
            "Validation score: 0.128205\n",
            "Iteration 2, loss = 2.99634389\n",
            "Validation score: 0.098291\n",
            "Iteration 3, loss = 2.64991420\n",
            "Validation score: 0.128205\n",
            "Iteration 4, loss = 2.52532204\n",
            "Validation score: 0.123932\n",
            "Iteration 5, loss = 2.49398858\n",
            "Validation score: 0.136752\n",
            "Iteration 6, loss = 2.47890541\n",
            "Validation score: 0.136752\n",
            "Iteration 7, loss = 2.46886836\n",
            "Validation score: 0.136752\n",
            "Iteration 8, loss = 2.45932547\n",
            "Validation score: 0.145299\n",
            "Iteration 9, loss = 2.45117623\n",
            "Validation score: 0.149573\n",
            "Iteration 10, loss = 2.44310015\n",
            "Validation score: 0.145299\n",
            "Iteration 11, loss = 2.43561246\n",
            "Validation score: 0.141026\n",
            "Iteration 12, loss = 2.42849538\n",
            "Validation score: 0.149573\n",
            "Iteration 13, loss = 2.42090443\n",
            "Validation score: 0.149573\n",
            "Iteration 14, loss = 2.41412320\n",
            "Validation score: 0.162393\n",
            "Iteration 15, loss = 2.40790934\n",
            "Validation score: 0.162393\n",
            "Iteration 16, loss = 2.40095295\n",
            "Validation score: 0.153846\n",
            "Iteration 17, loss = 2.39416631\n",
            "Validation score: 0.162393\n",
            "Iteration 18, loss = 2.38738744\n",
            "Validation score: 0.162393\n",
            "Iteration 19, loss = 2.38127113\n",
            "Validation score: 0.179487\n",
            "Iteration 20, loss = 2.37507709\n",
            "Validation score: 0.166667\n",
            "Iteration 21, loss = 2.36786506\n",
            "Validation score: 0.175214\n",
            "Iteration 22, loss = 2.36230715\n",
            "Validation score: 0.170940\n",
            "Iteration 23, loss = 2.35625651\n",
            "Validation score: 0.175214\n",
            "Iteration 24, loss = 2.35054993\n",
            "Validation score: 0.175214\n",
            "Iteration 25, loss = 2.34508389\n",
            "Validation score: 0.188034\n",
            "Iteration 26, loss = 2.34034889\n",
            "Validation score: 0.179487\n",
            "Iteration 27, loss = 2.33431586\n",
            "Validation score: 0.188034\n",
            "Iteration 28, loss = 2.32981038\n",
            "Validation score: 0.179487\n",
            "Iteration 29, loss = 2.32439329\n",
            "Validation score: 0.188034\n",
            "Iteration 30, loss = 2.31995616\n",
            "Validation score: 0.183761\n",
            "Iteration 31, loss = 2.31525068\n",
            "Validation score: 0.183761\n",
            "Iteration 32, loss = 2.30972429\n",
            "Validation score: 0.200855\n",
            "Iteration 33, loss = 2.30508983\n",
            "Validation score: 0.192308\n",
            "Iteration 34, loss = 2.30076123\n",
            "Validation score: 0.192308\n",
            "Iteration 35, loss = 2.29682614\n",
            "Validation score: 0.192308\n",
            "Iteration 36, loss = 2.29219750\n",
            "Validation score: 0.196581\n",
            "Iteration 37, loss = 2.28790125\n",
            "Validation score: 0.205128\n",
            "Iteration 38, loss = 2.28409988\n",
            "Validation score: 0.209402\n",
            "Iteration 39, loss = 2.28019484\n",
            "Validation score: 0.196581\n",
            "Iteration 40, loss = 2.27706159\n",
            "Validation score: 0.205128\n",
            "Iteration 41, loss = 2.27281339\n",
            "Validation score: 0.226496\n",
            "Iteration 42, loss = 2.26984440\n",
            "Validation score: 0.222222\n",
            "Iteration 43, loss = 2.26646600\n",
            "Validation score: 0.217949\n",
            "Iteration 44, loss = 2.26345196\n",
            "Validation score: 0.217949\n",
            "Iteration 45, loss = 2.26019891\n",
            "Validation score: 0.222222\n",
            "Iteration 46, loss = 2.25717989\n",
            "Validation score: 0.217949\n",
            "Iteration 47, loss = 2.25383267\n",
            "Validation score: 0.222222\n",
            "Iteration 48, loss = 2.25091120\n",
            "Validation score: 0.213675\n",
            "Iteration 49, loss = 2.24899413\n",
            "Validation score: 0.226496\n",
            "Iteration 50, loss = 2.24627840\n",
            "Validation score: 0.226496\n",
            "Iteration 51, loss = 2.24378426\n",
            "Validation score: 0.226496\n",
            "Iteration 52, loss = 2.24138277\n",
            "Validation score: 0.217949\n",
            "Iteration 53, loss = 2.23854455\n",
            "Validation score: 0.222222\n",
            "Iteration 54, loss = 2.23611529\n",
            "Validation score: 0.217949\n",
            "Iteration 55, loss = 2.23383676\n",
            "Validation score: 0.222222\n",
            "Iteration 56, loss = 2.23170620\n",
            "Validation score: 0.230769\n",
            "Iteration 57, loss = 2.22989973\n",
            "Validation score: 0.209402\n",
            "Iteration 58, loss = 2.22739566\n",
            "Validation score: 0.226496\n",
            "Iteration 59, loss = 2.22543035\n",
            "Validation score: 0.222222\n",
            "Iteration 60, loss = 2.22343325\n",
            "Validation score: 0.230769\n",
            "Iteration 61, loss = 2.22197877\n",
            "Validation score: 0.222222\n",
            "Iteration 62, loss = 2.21952945\n",
            "Validation score: 0.222222\n",
            "Iteration 63, loss = 2.21878921\n",
            "Validation score: 0.217949\n",
            "Iteration 64, loss = 2.21625927\n",
            "Validation score: 0.235043\n",
            "Iteration 65, loss = 2.21447592\n",
            "Validation score: 0.230769\n",
            "Iteration 66, loss = 2.21385511\n",
            "Validation score: 0.222222\n",
            "Iteration 67, loss = 2.21158440\n",
            "Validation score: 0.230769\n",
            "Iteration 68, loss = 2.21045184\n",
            "Validation score: 0.226496\n",
            "Iteration 69, loss = 2.20964144\n",
            "Validation score: 0.226496\n",
            "Iteration 70, loss = 2.20729103\n",
            "Validation score: 0.222222\n",
            "Iteration 71, loss = 2.20657445\n",
            "Validation score: 0.235043\n",
            "Iteration 72, loss = 2.20512020\n",
            "Validation score: 0.226496\n",
            "Iteration 73, loss = 2.20442512\n",
            "Validation score: 0.226496\n",
            "Iteration 74, loss = 2.20210850\n",
            "Validation score: 0.230769\n",
            "Iteration 75, loss = 2.20080318\n",
            "Validation score: 0.239316\n",
            "Iteration 76, loss = 2.19931179\n",
            "Validation score: 0.239316\n",
            "Iteration 77, loss = 2.19848616\n",
            "Validation score: 0.235043\n",
            "Iteration 78, loss = 2.19746671\n",
            "Validation score: 0.226496\n",
            "Iteration 79, loss = 2.19619721\n",
            "Validation score: 0.226496\n",
            "Iteration 80, loss = 2.19449295\n",
            "Validation score: 0.217949\n",
            "Iteration 81, loss = 2.19379845\n",
            "Validation score: 0.230769\n",
            "Iteration 82, loss = 2.19326683\n",
            "Validation score: 0.209402\n",
            "Iteration 83, loss = 2.19121078\n",
            "Validation score: 0.226496\n",
            "Iteration 84, loss = 2.19015008\n",
            "Validation score: 0.230769\n",
            "Iteration 85, loss = 2.18890669\n",
            "Validation score: 0.226496\n",
            "Iteration 86, loss = 2.18803333\n",
            "Validation score: 0.235043\n",
            "Iteration 87, loss = 2.18691193\n",
            "Validation score: 0.226496\n",
            "Iteration 88, loss = 2.18651416\n",
            "Validation score: 0.230769\n",
            "Iteration 89, loss = 2.18474223\n",
            "Validation score: 0.230769\n",
            "Iteration 90, loss = 2.18440416\n",
            "Validation score: 0.217949\n",
            "Iteration 91, loss = 2.18184945\n",
            "Validation score: 0.235043\n",
            "Iteration 92, loss = 2.18082410\n",
            "Validation score: 0.222222\n",
            "Iteration 93, loss = 2.17974491\n",
            "Validation score: 0.217949\n",
            "Iteration 94, loss = 2.17868627\n",
            "Validation score: 0.226496\n",
            "Iteration 95, loss = 2.17825680\n",
            "Validation score: 0.230769\n",
            "Iteration 96, loss = 2.17712033\n",
            "Validation score: 0.243590\n",
            "Iteration 97, loss = 2.17566183\n",
            "Validation score: 0.239316\n",
            "Iteration 98, loss = 2.17543001\n",
            "Validation score: 0.243590\n",
            "Iteration 99, loss = 2.17424366\n",
            "Validation score: 0.247863\n",
            "Iteration 100, loss = 2.17346915\n",
            "Validation score: 0.235043\n",
            "Iteration 101, loss = 2.17269241\n",
            "Validation score: 0.252137\n",
            "Iteration 102, loss = 2.17120211\n",
            "Validation score: 0.252137\n",
            "Iteration 103, loss = 2.17051883\n",
            "Validation score: 0.243590\n",
            "Iteration 104, loss = 2.16987409\n",
            "Validation score: 0.235043\n",
            "Iteration 105, loss = 2.16900579\n",
            "Validation score: 0.239316\n",
            "Iteration 106, loss = 2.16776662\n",
            "Validation score: 0.230769\n",
            "Iteration 107, loss = 2.16815633\n",
            "Validation score: 0.247863\n",
            "Iteration 108, loss = 2.16581650\n",
            "Validation score: 0.247863\n",
            "Iteration 109, loss = 2.16554253\n",
            "Validation score: 0.247863\n",
            "Iteration 110, loss = 2.16611999\n",
            "Validation score: 0.243590\n",
            "Iteration 111, loss = 2.16398119\n",
            "Validation score: 0.252137\n",
            "Iteration 112, loss = 2.16317711\n",
            "Validation score: 0.260684\n",
            "Iteration 113, loss = 2.16202579\n",
            "Validation score: 0.256410\n",
            "Iteration 114, loss = 2.16063028\n",
            "Validation score: 0.256410\n",
            "Iteration 115, loss = 2.16051499\n",
            "Validation score: 0.256410\n",
            "Iteration 116, loss = 2.16008781\n",
            "Validation score: 0.256410\n",
            "Iteration 117, loss = 2.15928866\n",
            "Validation score: 0.247863\n",
            "Iteration 118, loss = 2.15893835\n",
            "Validation score: 0.252137\n",
            "Iteration 119, loss = 2.15769651\n",
            "Validation score: 0.260684\n",
            "Iteration 120, loss = 2.15653706\n",
            "Validation score: 0.252137\n",
            "Iteration 121, loss = 2.15626591\n",
            "Validation score: 0.247863\n",
            "Iteration 122, loss = 2.15536544\n",
            "Validation score: 0.256410\n",
            "Iteration 123, loss = 2.15448706\n",
            "Validation score: 0.256410\n",
            "Iteration 124, loss = 2.15381695\n",
            "Validation score: 0.264957\n",
            "Iteration 125, loss = 2.15341211\n",
            "Validation score: 0.264957\n",
            "Iteration 126, loss = 2.15205567\n",
            "Validation score: 0.256410\n",
            "Iteration 127, loss = 2.15129376\n",
            "Validation score: 0.247863\n",
            "Iteration 128, loss = 2.15056262\n",
            "Validation score: 0.247863\n",
            "Iteration 129, loss = 2.15063187\n",
            "Validation score: 0.239316\n",
            "Iteration 130, loss = 2.14990510\n",
            "Validation score: 0.260684\n",
            "Iteration 131, loss = 2.14916074\n",
            "Validation score: 0.252137\n",
            "Iteration 132, loss = 2.14805507\n",
            "Validation score: 0.243590\n",
            "Iteration 133, loss = 2.14838320\n",
            "Validation score: 0.264957\n",
            "Iteration 134, loss = 2.14767794\n",
            "Validation score: 0.269231\n",
            "Iteration 135, loss = 2.14656993\n",
            "Validation score: 0.264957\n",
            "Iteration 136, loss = 2.14573661\n",
            "Validation score: 0.260684\n",
            "Iteration 137, loss = 2.14566698\n",
            "Validation score: 0.264957\n",
            "Iteration 138, loss = 2.14465097\n",
            "Validation score: 0.269231\n",
            "Iteration 139, loss = 2.14411172\n",
            "Validation score: 0.269231\n",
            "Iteration 140, loss = 2.14304347\n",
            "Validation score: 0.277778\n",
            "Iteration 141, loss = 2.14378229\n",
            "Validation score: 0.269231\n",
            "Iteration 142, loss = 2.14258737\n",
            "Validation score: 0.269231\n",
            "Iteration 143, loss = 2.14185784\n",
            "Validation score: 0.256410\n",
            "Iteration 144, loss = 2.14042341\n",
            "Validation score: 0.269231\n",
            "Iteration 145, loss = 2.14088419\n",
            "Validation score: 0.264957\n",
            "Iteration 146, loss = 2.13964095\n",
            "Validation score: 0.269231\n",
            "Iteration 147, loss = 2.13902341\n",
            "Validation score: 0.264957\n",
            "Iteration 148, loss = 2.13920694\n",
            "Validation score: 0.264957\n",
            "Iteration 149, loss = 2.13757569\n",
            "Validation score: 0.282051\n",
            "Iteration 150, loss = 2.13797422\n",
            "Validation score: 0.269231\n",
            "Iteration 151, loss = 2.13719769\n",
            "Validation score: 0.252137\n",
            "Iteration 152, loss = 2.13663165\n",
            "Validation score: 0.264957\n",
            "Iteration 153, loss = 2.13617231\n",
            "Validation score: 0.277778\n",
            "Iteration 154, loss = 2.13548024\n",
            "Validation score: 0.256410\n",
            "Iteration 155, loss = 2.13416616\n",
            "Validation score: 0.282051\n",
            "Iteration 156, loss = 2.13365359\n",
            "Validation score: 0.273504\n",
            "Iteration 157, loss = 2.13332881\n",
            "Validation score: 0.260684\n",
            "Iteration 158, loss = 2.13264952\n",
            "Validation score: 0.286325\n",
            "Iteration 159, loss = 2.13160775\n",
            "Validation score: 0.260684\n",
            "Iteration 160, loss = 2.13123986\n",
            "Validation score: 0.247863\n",
            "Iteration 161, loss = 2.13040720\n",
            "Validation score: 0.260684\n",
            "Iteration 162, loss = 2.12931572\n",
            "Validation score: 0.282051\n",
            "Iteration 163, loss = 2.12938678\n",
            "Validation score: 0.256410\n",
            "Iteration 164, loss = 2.12920579\n",
            "Validation score: 0.273504\n",
            "Iteration 165, loss = 2.12907198\n",
            "Validation score: 0.273504\n",
            "Iteration 166, loss = 2.12741892\n",
            "Validation score: 0.286325\n",
            "Iteration 167, loss = 2.12792157\n",
            "Validation score: 0.260684\n",
            "Iteration 168, loss = 2.12659041\n",
            "Validation score: 0.269231\n",
            "Iteration 169, loss = 2.12564796\n",
            "Validation score: 0.282051\n",
            "Iteration 170, loss = 2.12479175\n",
            "Validation score: 0.247863\n",
            "Iteration 171, loss = 2.12433484\n",
            "Validation score: 0.264957\n",
            "Iteration 172, loss = 2.12373391\n",
            "Validation score: 0.269231\n",
            "Iteration 173, loss = 2.12270921\n",
            "Validation score: 0.273504\n",
            "Iteration 174, loss = 2.12215109\n",
            "Validation score: 0.264957\n",
            "Iteration 175, loss = 2.12113642\n",
            "Validation score: 0.256410\n",
            "Iteration 176, loss = 2.12038899\n",
            "Validation score: 0.260684\n",
            "Iteration 177, loss = 2.11993443\n",
            "Validation score: 0.264957\n",
            "Iteration 178, loss = 2.11894144\n",
            "Validation score: 0.277778\n",
            "Iteration 179, loss = 2.11932330\n",
            "Validation score: 0.260684\n",
            "Iteration 180, loss = 2.11799234\n",
            "Validation score: 0.243590\n",
            "Iteration 181, loss = 2.11773193\n",
            "Validation score: 0.269231\n",
            "Iteration 182, loss = 2.11660353\n",
            "Validation score: 0.247863\n",
            "Iteration 183, loss = 2.11719984\n",
            "Validation score: 0.282051\n",
            "Iteration 184, loss = 2.11597972\n",
            "Validation score: 0.252137\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.13597705\n",
            "Validation score: 0.123932\n",
            "Iteration 2, loss = 2.94920542\n",
            "Validation score: 0.123932\n",
            "Iteration 3, loss = 2.78489653\n",
            "Validation score: 0.123932\n",
            "Iteration 4, loss = 2.66394749\n",
            "Validation score: 0.123932\n",
            "Iteration 5, loss = 2.58949244\n",
            "Validation score: 0.222222\n",
            "Iteration 6, loss = 2.54818713\n",
            "Validation score: 0.213675\n",
            "Iteration 7, loss = 2.52747327\n",
            "Validation score: 0.196581\n",
            "Iteration 8, loss = 2.51674199\n",
            "Validation score: 0.128205\n",
            "Iteration 9, loss = 2.51132508\n",
            "Validation score: 0.153846\n",
            "Iteration 10, loss = 2.50655690\n",
            "Validation score: 0.128205\n",
            "Iteration 11, loss = 2.50341332\n",
            "Validation score: 0.132479\n",
            "Iteration 12, loss = 2.50020901\n",
            "Validation score: 0.162393\n",
            "Iteration 13, loss = 2.49740458\n",
            "Validation score: 0.136752\n",
            "Iteration 14, loss = 2.49401196\n",
            "Validation score: 0.162393\n",
            "Iteration 15, loss = 2.49142912\n",
            "Validation score: 0.145299\n",
            "Iteration 16, loss = 2.48852357\n",
            "Validation score: 0.136752\n",
            "Iteration 17, loss = 2.48491997\n",
            "Validation score: 0.123932\n",
            "Iteration 18, loss = 2.48190284\n",
            "Validation score: 0.141026\n",
            "Iteration 19, loss = 2.47828394\n",
            "Validation score: 0.162393\n",
            "Iteration 20, loss = 2.47541966\n",
            "Validation score: 0.158120\n",
            "Iteration 21, loss = 2.47121365\n",
            "Validation score: 0.149573\n",
            "Iteration 22, loss = 2.46599628\n",
            "Validation score: 0.119658\n",
            "Iteration 23, loss = 2.46065977\n",
            "Validation score: 0.123932\n",
            "Iteration 24, loss = 2.44780333\n",
            "Validation score: 0.141026\n",
            "Iteration 25, loss = 2.43702946\n",
            "Validation score: 0.128205\n",
            "Iteration 26, loss = 2.42632970\n",
            "Validation score: 0.128205\n",
            "Iteration 27, loss = 2.41727872\n",
            "Validation score: 0.123932\n",
            "Iteration 28, loss = 2.40929551\n",
            "Validation score: 0.123932\n",
            "Iteration 29, loss = 2.40060323\n",
            "Validation score: 0.136752\n",
            "Iteration 30, loss = 2.39287516\n",
            "Validation score: 0.132479\n",
            "Iteration 31, loss = 2.38497983\n",
            "Validation score: 0.145299\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.06164428\n",
            "Validation score: 0.081197\n",
            "Iteration 2, loss = 2.89763722\n",
            "Validation score: 0.170940\n",
            "Iteration 3, loss = 2.75940789\n",
            "Validation score: 0.170940\n",
            "Iteration 4, loss = 2.65340346\n",
            "Validation score: 0.170940\n",
            "Iteration 5, loss = 2.58163310\n",
            "Validation score: 0.170940\n",
            "Iteration 6, loss = 2.53714977\n",
            "Validation score: 0.170940\n",
            "Iteration 7, loss = 2.51333860\n",
            "Validation score: 0.175214\n",
            "Iteration 8, loss = 2.50001730\n",
            "Validation score: 0.183761\n",
            "Iteration 9, loss = 2.49100954\n",
            "Validation score: 0.162393\n",
            "Iteration 10, loss = 2.48338155\n",
            "Validation score: 0.158120\n",
            "Iteration 11, loss = 2.47636879\n",
            "Validation score: 0.166667\n",
            "Iteration 12, loss = 2.46855257\n",
            "Validation score: 0.162393\n",
            "Iteration 13, loss = 2.46123391\n",
            "Validation score: 0.170940\n",
            "Iteration 14, loss = 2.45378315\n",
            "Validation score: 0.175214\n",
            "Iteration 15, loss = 2.44605148\n",
            "Validation score: 0.179487\n",
            "Iteration 16, loss = 2.43871863\n",
            "Validation score: 0.183761\n",
            "Iteration 17, loss = 2.43129726\n",
            "Validation score: 0.170940\n",
            "Iteration 18, loss = 2.42351499\n",
            "Validation score: 0.188034\n",
            "Iteration 19, loss = 2.41643554\n",
            "Validation score: 0.205128\n",
            "Iteration 20, loss = 2.40898326\n",
            "Validation score: 0.196581\n",
            "Iteration 21, loss = 2.40112840\n",
            "Validation score: 0.235043\n",
            "Iteration 22, loss = 2.39370282\n",
            "Validation score: 0.200855\n",
            "Iteration 23, loss = 2.38595823\n",
            "Validation score: 0.200855\n",
            "Iteration 24, loss = 2.37900780\n",
            "Validation score: 0.222222\n",
            "Iteration 25, loss = 2.37124289\n",
            "Validation score: 0.222222\n",
            "Iteration 26, loss = 2.36378934\n",
            "Validation score: 0.213675\n",
            "Iteration 27, loss = 2.35678571\n",
            "Validation score: 0.235043\n",
            "Iteration 28, loss = 2.34916886\n",
            "Validation score: 0.239316\n",
            "Iteration 29, loss = 2.34262056\n",
            "Validation score: 0.235043\n",
            "Iteration 30, loss = 2.33650751\n",
            "Validation score: 0.230769\n",
            "Iteration 31, loss = 2.33011239\n",
            "Validation score: 0.243590\n",
            "Iteration 32, loss = 2.32338812\n",
            "Validation score: 0.243590\n",
            "Iteration 33, loss = 2.31715926\n",
            "Validation score: 0.222222\n",
            "Iteration 34, loss = 2.31216945\n",
            "Validation score: 0.235043\n",
            "Iteration 35, loss = 2.30575275\n",
            "Validation score: 0.230769\n",
            "Iteration 36, loss = 2.29997886\n",
            "Validation score: 0.226496\n",
            "Iteration 37, loss = 2.29462054\n",
            "Validation score: 0.239316\n",
            "Iteration 38, loss = 2.28915574\n",
            "Validation score: 0.230769\n",
            "Iteration 39, loss = 2.28340811\n",
            "Validation score: 0.243590\n",
            "Iteration 40, loss = 2.27842878\n",
            "Validation score: 0.239316\n",
            "Iteration 41, loss = 2.27308331\n",
            "Validation score: 0.226496\n",
            "Iteration 42, loss = 2.26890361\n",
            "Validation score: 0.235043\n",
            "Iteration 43, loss = 2.26329832\n",
            "Validation score: 0.235043\n",
            "Iteration 44, loss = 2.25958957\n",
            "Validation score: 0.205128\n",
            "Iteration 45, loss = 2.25526507\n",
            "Validation score: 0.230769\n",
            "Iteration 46, loss = 2.25070967\n",
            "Validation score: 0.235043\n",
            "Iteration 47, loss = 2.24630317\n",
            "Validation score: 0.239316\n",
            "Iteration 48, loss = 2.24230751\n",
            "Validation score: 0.239316\n",
            "Iteration 49, loss = 2.23808628\n",
            "Validation score: 0.243590\n",
            "Iteration 50, loss = 2.23477698\n",
            "Validation score: 0.239316\n",
            "Iteration 51, loss = 2.23133889\n",
            "Validation score: 0.235043\n",
            "Iteration 52, loss = 2.22671596\n",
            "Validation score: 0.235043\n",
            "Iteration 53, loss = 2.22296572\n",
            "Validation score: 0.226496\n",
            "Iteration 54, loss = 2.22031877\n",
            "Validation score: 0.239316\n",
            "Iteration 55, loss = 2.21663736\n",
            "Validation score: 0.226496\n",
            "Iteration 56, loss = 2.21319303\n",
            "Validation score: 0.235043\n",
            "Iteration 57, loss = 2.20954530\n",
            "Validation score: 0.247863\n",
            "Iteration 58, loss = 2.20610916\n",
            "Validation score: 0.247863\n",
            "Iteration 59, loss = 2.20385471\n",
            "Validation score: 0.239316\n",
            "Iteration 60, loss = 2.20088838\n",
            "Validation score: 0.239316\n",
            "Iteration 61, loss = 2.19772263\n",
            "Validation score: 0.243590\n",
            "Iteration 62, loss = 2.19392806\n",
            "Validation score: 0.235043\n",
            "Iteration 63, loss = 2.19254077\n",
            "Validation score: 0.243590\n",
            "Iteration 64, loss = 2.18916986\n",
            "Validation score: 0.235043\n",
            "Iteration 65, loss = 2.18640246\n",
            "Validation score: 0.243590\n",
            "Iteration 66, loss = 2.18341605\n",
            "Validation score: 0.247863\n",
            "Iteration 67, loss = 2.18126678\n",
            "Validation score: 0.247863\n",
            "Iteration 68, loss = 2.17807450\n",
            "Validation score: 0.247863\n",
            "Iteration 69, loss = 2.17611552\n",
            "Validation score: 0.243590\n",
            "Iteration 70, loss = 2.17411094\n",
            "Validation score: 0.230769\n",
            "Iteration 71, loss = 2.17195692\n",
            "Validation score: 0.239316\n",
            "Iteration 72, loss = 2.16905304\n",
            "Validation score: 0.260684\n",
            "Iteration 73, loss = 2.16750921\n",
            "Validation score: 0.260684\n",
            "Iteration 74, loss = 2.16482098\n",
            "Validation score: 0.260684\n",
            "Iteration 75, loss = 2.16231861\n",
            "Validation score: 0.260684\n",
            "Iteration 76, loss = 2.16028787\n",
            "Validation score: 0.247863\n",
            "Iteration 77, loss = 2.15896757\n",
            "Validation score: 0.264957\n",
            "Iteration 78, loss = 2.15651136\n",
            "Validation score: 0.260684\n",
            "Iteration 79, loss = 2.15560713\n",
            "Validation score: 0.260684\n",
            "Iteration 80, loss = 2.15210656\n",
            "Validation score: 0.256410\n",
            "Iteration 81, loss = 2.15272856\n",
            "Validation score: 0.256410\n",
            "Iteration 82, loss = 2.14882029\n",
            "Validation score: 0.269231\n",
            "Iteration 83, loss = 2.14758826\n",
            "Validation score: 0.256410\n",
            "Iteration 84, loss = 2.14548930\n",
            "Validation score: 0.243590\n",
            "Iteration 85, loss = 2.14425234\n",
            "Validation score: 0.252137\n",
            "Iteration 86, loss = 2.14146374\n",
            "Validation score: 0.264957\n",
            "Iteration 87, loss = 2.14140098\n",
            "Validation score: 0.264957\n",
            "Iteration 88, loss = 2.13937247\n",
            "Validation score: 0.252137\n",
            "Iteration 89, loss = 2.13823902\n",
            "Validation score: 0.260684\n",
            "Iteration 90, loss = 2.13626680\n",
            "Validation score: 0.256410\n",
            "Iteration 91, loss = 2.13573618\n",
            "Validation score: 0.269231\n",
            "Iteration 92, loss = 2.13388365\n",
            "Validation score: 0.256410\n",
            "Iteration 93, loss = 2.13257968\n",
            "Validation score: 0.269231\n",
            "Iteration 94, loss = 2.13101536\n",
            "Validation score: 0.260684\n",
            "Iteration 95, loss = 2.12958870\n",
            "Validation score: 0.269231\n",
            "Iteration 96, loss = 2.12857517\n",
            "Validation score: 0.252137\n",
            "Iteration 97, loss = 2.12715631\n",
            "Validation score: 0.264957\n",
            "Iteration 98, loss = 2.12587709\n",
            "Validation score: 0.264957\n",
            "Iteration 99, loss = 2.12448722\n",
            "Validation score: 0.269231\n",
            "Iteration 100, loss = 2.12414637\n",
            "Validation score: 0.264957\n",
            "Iteration 101, loss = 2.12211542\n",
            "Validation score: 0.277778\n",
            "Iteration 102, loss = 2.12131608\n",
            "Validation score: 0.260684\n",
            "Iteration 103, loss = 2.12008257\n",
            "Validation score: 0.277778\n",
            "Iteration 104, loss = 2.12025187\n",
            "Validation score: 0.282051\n",
            "Iteration 105, loss = 2.11866535\n",
            "Validation score: 0.277778\n",
            "Iteration 106, loss = 2.11827435\n",
            "Validation score: 0.269231\n",
            "Iteration 107, loss = 2.11656830\n",
            "Validation score: 0.277778\n",
            "Iteration 108, loss = 2.11580516\n",
            "Validation score: 0.282051\n",
            "Iteration 109, loss = 2.11459447\n",
            "Validation score: 0.269231\n",
            "Iteration 110, loss = 2.11410240\n",
            "Validation score: 0.282051\n",
            "Iteration 111, loss = 2.11254433\n",
            "Validation score: 0.277778\n",
            "Iteration 112, loss = 2.11247291\n",
            "Validation score: 0.277778\n",
            "Iteration 113, loss = 2.11199567\n",
            "Validation score: 0.269231\n",
            "Iteration 114, loss = 2.11192664\n",
            "Validation score: 0.290598\n",
            "Iteration 115, loss = 2.10982708\n",
            "Validation score: 0.277778\n",
            "Iteration 116, loss = 2.10872196\n",
            "Validation score: 0.277778\n",
            "Iteration 117, loss = 2.10819698\n",
            "Validation score: 0.282051\n",
            "Iteration 118, loss = 2.10733810\n",
            "Validation score: 0.277778\n",
            "Iteration 119, loss = 2.10566714\n",
            "Validation score: 0.269231\n",
            "Iteration 120, loss = 2.10726020\n",
            "Validation score: 0.264957\n",
            "Iteration 121, loss = 2.10574433\n",
            "Validation score: 0.282051\n",
            "Iteration 122, loss = 2.10412878\n",
            "Validation score: 0.282051\n",
            "Iteration 123, loss = 2.10314549\n",
            "Validation score: 0.286325\n",
            "Iteration 124, loss = 2.10362334\n",
            "Validation score: 0.273504\n",
            "Iteration 125, loss = 2.10293133\n",
            "Validation score: 0.290598\n",
            "Iteration 126, loss = 2.10137596\n",
            "Validation score: 0.290598\n",
            "Iteration 127, loss = 2.10119450\n",
            "Validation score: 0.286325\n",
            "Iteration 128, loss = 2.10032865\n",
            "Validation score: 0.282051\n",
            "Iteration 129, loss = 2.09981237\n",
            "Validation score: 0.290598\n",
            "Iteration 130, loss = 2.09903146\n",
            "Validation score: 0.269231\n",
            "Iteration 131, loss = 2.09870083\n",
            "Validation score: 0.277778\n",
            "Iteration 132, loss = 2.09824270\n",
            "Validation score: 0.273504\n",
            "Iteration 133, loss = 2.09686840\n",
            "Validation score: 0.273504\n",
            "Iteration 134, loss = 2.09661985\n",
            "Validation score: 0.286325\n",
            "Iteration 135, loss = 2.09651697\n",
            "Validation score: 0.286325\n",
            "Iteration 136, loss = 2.09477586\n",
            "Validation score: 0.273504\n",
            "Iteration 137, loss = 2.09598614\n",
            "Validation score: 0.286325\n",
            "Iteration 138, loss = 2.09462213\n",
            "Validation score: 0.282051\n",
            "Iteration 139, loss = 2.09375752\n",
            "Validation score: 0.282051\n",
            "Iteration 140, loss = 2.09318778\n",
            "Validation score: 0.273504\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.26444879\n",
            "Validation score: 0.072650\n",
            "Iteration 2, loss = 3.16502539\n",
            "Validation score: 0.115385\n",
            "Iteration 3, loss = 3.07722429\n",
            "Validation score: 0.072650\n",
            "Iteration 4, loss = 3.00065392\n",
            "Validation score: 0.115385\n",
            "Iteration 5, loss = 2.93411722\n",
            "Validation score: 0.115385\n",
            "Iteration 6, loss = 2.87641359\n",
            "Validation score: 0.115385\n",
            "Iteration 7, loss = 2.82658504\n",
            "Validation score: 0.115385\n",
            "Iteration 8, loss = 2.78368070\n",
            "Validation score: 0.115385\n",
            "Iteration 9, loss = 2.74689240\n",
            "Validation score: 0.153846\n",
            "Iteration 10, loss = 2.71515785\n",
            "Validation score: 0.153846\n",
            "Iteration 11, loss = 2.68801814\n",
            "Validation score: 0.153846\n",
            "Iteration 12, loss = 2.66477374\n",
            "Validation score: 0.153846\n",
            "Iteration 13, loss = 2.64486606\n",
            "Validation score: 0.153846\n",
            "Iteration 14, loss = 2.62774301\n",
            "Validation score: 0.153846\n",
            "Iteration 15, loss = 2.61300428\n",
            "Validation score: 0.153846\n",
            "Iteration 16, loss = 2.60052349\n",
            "Validation score: 0.153846\n",
            "Iteration 17, loss = 2.58971266\n",
            "Validation score: 0.153846\n",
            "Iteration 18, loss = 2.58059026\n",
            "Validation score: 0.153846\n",
            "Iteration 19, loss = 2.57267676\n",
            "Validation score: 0.153846\n",
            "Iteration 20, loss = 2.56594464\n",
            "Validation score: 0.153846\n",
            "Iteration 21, loss = 2.56015766\n",
            "Validation score: 0.153846\n",
            "Iteration 22, loss = 2.55515148\n",
            "Validation score: 0.153846\n",
            "Iteration 23, loss = 2.55074672\n",
            "Validation score: 0.153846\n",
            "Iteration 24, loss = 2.54707494\n",
            "Validation score: 0.153846\n",
            "Iteration 25, loss = 2.54377131\n",
            "Validation score: 0.153846\n",
            "Iteration 26, loss = 2.54100679\n",
            "Validation score: 0.153846\n",
            "Iteration 27, loss = 2.53850292\n",
            "Validation score: 0.153846\n",
            "Iteration 28, loss = 2.53625830\n",
            "Validation score: 0.153846\n",
            "Iteration 29, loss = 2.53428189\n",
            "Validation score: 0.153846\n",
            "Iteration 30, loss = 2.53257297\n",
            "Validation score: 0.153846\n",
            "Iteration 31, loss = 2.53097497\n",
            "Validation score: 0.153846\n",
            "Iteration 32, loss = 2.52968830\n",
            "Validation score: 0.153846\n",
            "Iteration 33, loss = 2.52844330\n",
            "Validation score: 0.153846\n",
            "Iteration 34, loss = 2.52740580\n",
            "Validation score: 0.153846\n",
            "Iteration 35, loss = 2.52624949\n",
            "Validation score: 0.153846\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.23987870\n",
            "Validation score: 0.106838\n",
            "Iteration 2, loss = 3.14103965\n",
            "Validation score: 0.106838\n",
            "Iteration 3, loss = 3.05422411\n",
            "Validation score: 0.106838\n",
            "Iteration 4, loss = 2.97848608\n",
            "Validation score: 0.106838\n",
            "Iteration 5, loss = 2.91257882\n",
            "Validation score: 0.106838\n",
            "Iteration 6, loss = 2.85582603\n",
            "Validation score: 0.106838\n",
            "Iteration 7, loss = 2.80691551\n",
            "Validation score: 0.106838\n",
            "Iteration 8, loss = 2.76485092\n",
            "Validation score: 0.106838\n",
            "Iteration 9, loss = 2.72864685\n",
            "Validation score: 0.106838\n",
            "Iteration 10, loss = 2.69758318\n",
            "Validation score: 0.106838\n",
            "Iteration 11, loss = 2.67102212\n",
            "Validation score: 0.106838\n",
            "Iteration 12, loss = 2.64823695\n",
            "Validation score: 0.111111\n",
            "Iteration 13, loss = 2.62885973\n",
            "Validation score: 0.111111\n",
            "Iteration 14, loss = 2.61217449\n",
            "Validation score: 0.111111\n",
            "Iteration 15, loss = 2.59789065\n",
            "Validation score: 0.111111\n",
            "Iteration 16, loss = 2.58563780\n",
            "Validation score: 0.111111\n",
            "Iteration 17, loss = 2.57515696\n",
            "Validation score: 0.111111\n",
            "Iteration 18, loss = 2.56613841\n",
            "Validation score: 0.111111\n",
            "Iteration 19, loss = 2.55856876\n",
            "Validation score: 0.111111\n",
            "Iteration 20, loss = 2.55196428\n",
            "Validation score: 0.111111\n",
            "Iteration 21, loss = 2.54620191\n",
            "Validation score: 0.111111\n",
            "Iteration 22, loss = 2.54132459\n",
            "Validation score: 0.111111\n",
            "Iteration 23, loss = 2.53715120\n",
            "Validation score: 0.111111\n",
            "Iteration 24, loss = 2.53337531\n",
            "Validation score: 0.111111\n",
            "Iteration 25, loss = 2.53009724\n",
            "Validation score: 0.111111\n",
            "Iteration 26, loss = 2.52732204\n",
            "Validation score: 0.111111\n",
            "Iteration 27, loss = 2.52480455\n",
            "Validation score: 0.111111\n",
            "Iteration 28, loss = 2.52264856\n",
            "Validation score: 0.111111\n",
            "Iteration 29, loss = 2.52062998\n",
            "Validation score: 0.111111\n",
            "Iteration 30, loss = 2.51894554\n",
            "Validation score: 0.111111\n",
            "Iteration 31, loss = 2.51732432\n",
            "Validation score: 0.111111\n",
            "Iteration 32, loss = 2.51594635\n",
            "Validation score: 0.111111\n",
            "Iteration 33, loss = 2.51469331\n",
            "Validation score: 0.111111\n",
            "Iteration 34, loss = 2.51351655\n",
            "Validation score: 0.111111\n",
            "Iteration 35, loss = 2.51252277\n",
            "Validation score: 0.111111\n",
            "Iteration 36, loss = 2.51157635\n",
            "Validation score: 0.111111\n",
            "Iteration 37, loss = 2.51072892\n",
            "Validation score: 0.111111\n",
            "Iteration 38, loss = 2.50996327\n",
            "Validation score: 0.111111\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.20170628\n",
            "Validation score: 0.213675\n",
            "Iteration 2, loss = 2.98612104\n",
            "Validation score: 0.213675\n",
            "Iteration 3, loss = 2.67856401\n",
            "Validation score: 0.213675\n",
            "Iteration 4, loss = 2.57182839\n",
            "Validation score: 0.213675\n",
            "Iteration 5, loss = 2.52245994\n",
            "Validation score: 0.213675\n",
            "Iteration 6, loss = 2.49824904\n",
            "Validation score: 0.209402\n",
            "Iteration 7, loss = 2.48369351\n",
            "Validation score: 0.205128\n",
            "Iteration 8, loss = 2.47224757\n",
            "Validation score: 0.217949\n",
            "Iteration 9, loss = 2.46268986\n",
            "Validation score: 0.205128\n",
            "Iteration 10, loss = 2.45379334\n",
            "Validation score: 0.213675\n",
            "Iteration 11, loss = 2.44591996\n",
            "Validation score: 0.213675\n",
            "Iteration 12, loss = 2.43763586\n",
            "Validation score: 0.200855\n",
            "Iteration 13, loss = 2.43053293\n",
            "Validation score: 0.213675\n",
            "Iteration 14, loss = 2.42305237\n",
            "Validation score: 0.209402\n",
            "Iteration 15, loss = 2.41570499\n",
            "Validation score: 0.200855\n",
            "Iteration 16, loss = 2.40854984\n",
            "Validation score: 0.213675\n",
            "Iteration 17, loss = 2.40152505\n",
            "Validation score: 0.217949\n",
            "Iteration 18, loss = 2.39459491\n",
            "Validation score: 0.217949\n",
            "Iteration 19, loss = 2.38733374\n",
            "Validation score: 0.222222\n",
            "Iteration 20, loss = 2.38023945\n",
            "Validation score: 0.217949\n",
            "Iteration 21, loss = 2.37372490\n",
            "Validation score: 0.222222\n",
            "Iteration 22, loss = 2.36723832\n",
            "Validation score: 0.222222\n",
            "Iteration 23, loss = 2.36099043\n",
            "Validation score: 0.213675\n",
            "Iteration 24, loss = 2.35495590\n",
            "Validation score: 0.217949\n",
            "Iteration 25, loss = 2.34906400\n",
            "Validation score: 0.222222\n",
            "Iteration 26, loss = 2.34299198\n",
            "Validation score: 0.222222\n",
            "Iteration 27, loss = 2.33757449\n",
            "Validation score: 0.213675\n",
            "Iteration 28, loss = 2.33200545\n",
            "Validation score: 0.222222\n",
            "Iteration 29, loss = 2.32663475\n",
            "Validation score: 0.235043\n",
            "Iteration 30, loss = 2.32137010\n",
            "Validation score: 0.243590\n",
            "Iteration 31, loss = 2.31684554\n",
            "Validation score: 0.235043\n",
            "Iteration 32, loss = 2.31153717\n",
            "Validation score: 0.256410\n",
            "Iteration 33, loss = 2.30687075\n",
            "Validation score: 0.256410\n",
            "Iteration 34, loss = 2.30286711\n",
            "Validation score: 0.260684\n",
            "Iteration 35, loss = 2.29867018\n",
            "Validation score: 0.264957\n",
            "Iteration 36, loss = 2.29405614\n",
            "Validation score: 0.264957\n",
            "Iteration 37, loss = 2.29029307\n",
            "Validation score: 0.260684\n",
            "Iteration 38, loss = 2.28607535\n",
            "Validation score: 0.269231\n",
            "Iteration 39, loss = 2.28225765\n",
            "Validation score: 0.256410\n",
            "Iteration 40, loss = 2.27872185\n",
            "Validation score: 0.243590\n",
            "Iteration 41, loss = 2.27526888\n",
            "Validation score: 0.252137\n",
            "Iteration 42, loss = 2.27199389\n",
            "Validation score: 0.239316\n",
            "Iteration 43, loss = 2.26844644\n",
            "Validation score: 0.256410\n",
            "Iteration 44, loss = 2.26589970\n",
            "Validation score: 0.243590\n",
            "Iteration 45, loss = 2.26290855\n",
            "Validation score: 0.252137\n",
            "Iteration 46, loss = 2.25963375\n",
            "Validation score: 0.235043\n",
            "Iteration 47, loss = 2.25717972\n",
            "Validation score: 0.247863\n",
            "Iteration 48, loss = 2.25413397\n",
            "Validation score: 0.247863\n",
            "Iteration 49, loss = 2.25180546\n",
            "Validation score: 0.252137\n",
            "Iteration 50, loss = 2.24919738\n",
            "Validation score: 0.260684\n",
            "Iteration 51, loss = 2.24712244\n",
            "Validation score: 0.252137\n",
            "Iteration 52, loss = 2.24474324\n",
            "Validation score: 0.252137\n",
            "Iteration 53, loss = 2.24263004\n",
            "Validation score: 0.247863\n",
            "Iteration 54, loss = 2.24032784\n",
            "Validation score: 0.247863\n",
            "Iteration 55, loss = 2.23820016\n",
            "Validation score: 0.243590\n",
            "Iteration 56, loss = 2.23643165\n",
            "Validation score: 0.243590\n",
            "Iteration 57, loss = 2.23415820\n",
            "Validation score: 0.247863\n",
            "Iteration 58, loss = 2.23313649\n",
            "Validation score: 0.252137\n",
            "Iteration 59, loss = 2.23041550\n",
            "Validation score: 0.256410\n",
            "Iteration 60, loss = 2.22904402\n",
            "Validation score: 0.243590\n",
            "Iteration 61, loss = 2.22755349\n",
            "Validation score: 0.247863\n",
            "Iteration 62, loss = 2.22524058\n",
            "Validation score: 0.252137\n",
            "Iteration 63, loss = 2.22387652\n",
            "Validation score: 0.252137\n",
            "Iteration 64, loss = 2.22216356\n",
            "Validation score: 0.256410\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.13646736\n",
            "Validation score: 0.153846\n",
            "Iteration 2, loss = 3.04779395\n",
            "Validation score: 0.153846\n",
            "Iteration 3, loss = 2.97011456\n",
            "Validation score: 0.153846\n",
            "Iteration 4, loss = 2.90271889\n",
            "Validation score: 0.153846\n",
            "Iteration 5, loss = 2.84479901\n",
            "Validation score: 0.153846\n",
            "Iteration 6, loss = 2.79541092\n",
            "Validation score: 0.153846\n",
            "Iteration 7, loss = 2.75330104\n",
            "Validation score: 0.153846\n",
            "Iteration 8, loss = 2.71764789\n",
            "Validation score: 0.153846\n",
            "Iteration 9, loss = 2.68726973\n",
            "Validation score: 0.153846\n",
            "Iteration 10, loss = 2.66164103\n",
            "Validation score: 0.153846\n",
            "Iteration 11, loss = 2.63970558\n",
            "Validation score: 0.153846\n",
            "Iteration 12, loss = 2.62110685\n",
            "Validation score: 0.153846\n",
            "Iteration 13, loss = 2.60532097\n",
            "Validation score: 0.153846\n",
            "Iteration 14, loss = 2.59184813\n",
            "Validation score: 0.153846\n",
            "Iteration 15, loss = 2.58030079\n",
            "Validation score: 0.153846\n",
            "Iteration 16, loss = 2.57056845\n",
            "Validation score: 0.153846\n",
            "Iteration 17, loss = 2.56228354\n",
            "Validation score: 0.153846\n",
            "Iteration 18, loss = 2.55513808\n",
            "Validation score: 0.153846\n",
            "Iteration 19, loss = 2.54905428\n",
            "Validation score: 0.153846\n",
            "Iteration 20, loss = 2.54386812\n",
            "Validation score: 0.153846\n",
            "Iteration 21, loss = 2.53925799\n",
            "Validation score: 0.153846\n",
            "Iteration 22, loss = 2.53542287\n",
            "Validation score: 0.153846\n",
            "Iteration 23, loss = 2.53204870\n",
            "Validation score: 0.153846\n",
            "Iteration 24, loss = 2.52913916\n",
            "Validation score: 0.153846\n",
            "Iteration 25, loss = 2.52658907\n",
            "Validation score: 0.153846\n",
            "Iteration 26, loss = 2.52440117\n",
            "Validation score: 0.153846\n",
            "Iteration 27, loss = 2.52229810\n",
            "Validation score: 0.153846\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.07254287\n",
            "Validation score: 0.162393\n",
            "Iteration 2, loss = 2.98802534\n",
            "Validation score: 0.162393\n",
            "Iteration 3, loss = 2.86405522\n",
            "Validation score: 0.136752\n",
            "Iteration 4, loss = 2.66052937\n",
            "Validation score: 0.128205\n",
            "Iteration 5, loss = 2.55480070\n",
            "Validation score: 0.149573\n",
            "Iteration 6, loss = 2.50240060\n",
            "Validation score: 0.179487\n",
            "Iteration 7, loss = 2.47550901\n",
            "Validation score: 0.170940\n",
            "Iteration 8, loss = 2.45798920\n",
            "Validation score: 0.162393\n",
            "Iteration 9, loss = 2.44405680\n",
            "Validation score: 0.166667\n",
            "Iteration 10, loss = 2.43145107\n",
            "Validation score: 0.153846\n",
            "Iteration 11, loss = 2.42030457\n",
            "Validation score: 0.149573\n",
            "Iteration 12, loss = 2.40979254\n",
            "Validation score: 0.166667\n",
            "Iteration 13, loss = 2.39967627\n",
            "Validation score: 0.162393\n",
            "Iteration 14, loss = 2.38965201\n",
            "Validation score: 0.175214\n",
            "Iteration 15, loss = 2.38061171\n",
            "Validation score: 0.192308\n",
            "Iteration 16, loss = 2.37157125\n",
            "Validation score: 0.179487\n",
            "Iteration 17, loss = 2.36294331\n",
            "Validation score: 0.205128\n",
            "Iteration 18, loss = 2.35505612\n",
            "Validation score: 0.209402\n",
            "Iteration 19, loss = 2.34666854\n",
            "Validation score: 0.205128\n",
            "Iteration 20, loss = 2.33898977\n",
            "Validation score: 0.200855\n",
            "Iteration 21, loss = 2.33151553\n",
            "Validation score: 0.209402\n",
            "Iteration 22, loss = 2.32433209\n",
            "Validation score: 0.213675\n",
            "Iteration 23, loss = 2.31744479\n",
            "Validation score: 0.209402\n",
            "Iteration 24, loss = 2.31110064\n",
            "Validation score: 0.205128\n",
            "Iteration 25, loss = 2.30480454\n",
            "Validation score: 0.209402\n",
            "Iteration 26, loss = 2.29925705\n",
            "Validation score: 0.205128\n",
            "Iteration 27, loss = 2.29357603\n",
            "Validation score: 0.205128\n",
            "Iteration 28, loss = 2.28793921\n",
            "Validation score: 0.217949\n",
            "Iteration 29, loss = 2.28304902\n",
            "Validation score: 0.209402\n",
            "Iteration 30, loss = 2.27834781\n",
            "Validation score: 0.209402\n",
            "Iteration 31, loss = 2.27378935\n",
            "Validation score: 0.230769\n",
            "Iteration 32, loss = 2.26940918\n",
            "Validation score: 0.239316\n",
            "Iteration 33, loss = 2.26519747\n",
            "Validation score: 0.217949\n",
            "Iteration 34, loss = 2.26084688\n",
            "Validation score: 0.226496\n",
            "Iteration 35, loss = 2.25749760\n",
            "Validation score: 0.226496\n",
            "Iteration 36, loss = 2.25350182\n",
            "Validation score: 0.226496\n",
            "Iteration 37, loss = 2.25041117\n",
            "Validation score: 0.230769\n",
            "Iteration 38, loss = 2.24716443\n",
            "Validation score: 0.239316\n",
            "Iteration 39, loss = 2.24354958\n",
            "Validation score: 0.235043\n",
            "Iteration 40, loss = 2.24102896\n",
            "Validation score: 0.239316\n",
            "Iteration 41, loss = 2.23803133\n",
            "Validation score: 0.235043\n",
            "Iteration 42, loss = 2.23533942\n",
            "Validation score: 0.230769\n",
            "Iteration 43, loss = 2.23303315\n",
            "Validation score: 0.243590\n",
            "Iteration 44, loss = 2.23024909\n",
            "Validation score: 0.239316\n",
            "Iteration 45, loss = 2.22835725\n",
            "Validation score: 0.243590\n",
            "Iteration 46, loss = 2.22591106\n",
            "Validation score: 0.235043\n",
            "Iteration 47, loss = 2.22354579\n",
            "Validation score: 0.243590\n",
            "Iteration 48, loss = 2.22148942\n",
            "Validation score: 0.239316\n",
            "Iteration 49, loss = 2.21959275\n",
            "Validation score: 0.239316\n",
            "Iteration 50, loss = 2.21741331\n",
            "Validation score: 0.230769\n",
            "Iteration 51, loss = 2.21535197\n",
            "Validation score: 0.243590\n",
            "Iteration 52, loss = 2.21355192\n",
            "Validation score: 0.243590\n",
            "Iteration 53, loss = 2.21187934\n",
            "Validation score: 0.235043\n",
            "Iteration 54, loss = 2.21038404\n",
            "Validation score: 0.235043\n",
            "Iteration 55, loss = 2.20878164\n",
            "Validation score: 0.235043\n",
            "Iteration 56, loss = 2.20688721\n",
            "Validation score: 0.235043\n",
            "Iteration 57, loss = 2.20531957\n",
            "Validation score: 0.230769\n",
            "Iteration 58, loss = 2.20385573\n",
            "Validation score: 0.222222\n",
            "Iteration 59, loss = 2.20307906\n",
            "Validation score: 0.235043\n",
            "Iteration 60, loss = 2.20116532\n",
            "Validation score: 0.235043\n",
            "Iteration 61, loss = 2.19988675\n",
            "Validation score: 0.235043\n",
            "Iteration 62, loss = 2.19857504\n",
            "Validation score: 0.230769\n",
            "Iteration 63, loss = 2.19712048\n",
            "Validation score: 0.222222\n",
            "Iteration 64, loss = 2.19579500\n",
            "Validation score: 0.230769\n",
            "Iteration 65, loss = 2.19478489\n",
            "Validation score: 0.235043\n",
            "Iteration 66, loss = 2.19356543\n",
            "Validation score: 0.230769\n",
            "Iteration 67, loss = 2.19215752\n",
            "Validation score: 0.235043\n",
            "Iteration 68, loss = 2.19176878\n",
            "Validation score: 0.230769\n",
            "Iteration 69, loss = 2.19007530\n",
            "Validation score: 0.235043\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.33124850\n",
            "Validation score: 0.008547\n",
            "Iteration 2, loss = 3.15539802\n",
            "Validation score: 0.158120\n",
            "Iteration 3, loss = 2.97892652\n",
            "Validation score: 0.162393\n",
            "Iteration 4, loss = 2.83049095\n",
            "Validation score: 0.162393\n",
            "Iteration 5, loss = 2.72312104\n",
            "Validation score: 0.162393\n",
            "Iteration 6, loss = 2.65188817\n",
            "Validation score: 0.162393\n",
            "Iteration 7, loss = 2.60660422\n",
            "Validation score: 0.162393\n",
            "Iteration 8, loss = 2.57785780\n",
            "Validation score: 0.162393\n",
            "Iteration 9, loss = 2.56085704\n",
            "Validation score: 0.162393\n",
            "Iteration 10, loss = 2.54945657\n",
            "Validation score: 0.162393\n",
            "Iteration 11, loss = 2.54183136\n",
            "Validation score: 0.162393\n",
            "Iteration 12, loss = 2.53687292\n",
            "Validation score: 0.162393\n",
            "Iteration 13, loss = 2.53299013\n",
            "Validation score: 0.162393\n",
            "Iteration 14, loss = 2.53041116\n",
            "Validation score: 0.162393\n",
            "Iteration 15, loss = 2.52848362\n",
            "Validation score: 0.162393\n",
            "Iteration 16, loss = 2.52687128\n",
            "Validation score: 0.166667\n",
            "Iteration 17, loss = 2.52524968\n",
            "Validation score: 0.153846\n",
            "Iteration 18, loss = 2.52415104\n",
            "Validation score: 0.162393\n",
            "Iteration 19, loss = 2.52358672\n",
            "Validation score: 0.162393\n",
            "Iteration 20, loss = 2.52296544\n",
            "Validation score: 0.153846\n",
            "Iteration 21, loss = 2.52260221\n",
            "Validation score: 0.166667\n",
            "Iteration 22, loss = 2.52181794\n",
            "Validation score: 0.166667\n",
            "Iteration 23, loss = 2.52150046\n",
            "Validation score: 0.158120\n",
            "Iteration 24, loss = 2.52116770\n",
            "Validation score: 0.166667\n",
            "Iteration 25, loss = 2.52079335\n",
            "Validation score: 0.166667\n",
            "Iteration 26, loss = 2.52040952\n",
            "Validation score: 0.162393\n",
            "Iteration 27, loss = 2.52031776\n",
            "Validation score: 0.149573\n",
            "Iteration 28, loss = 2.52003580\n",
            "Validation score: 0.149573\n",
            "Iteration 29, loss = 2.51985795\n",
            "Validation score: 0.170940\n",
            "Iteration 30, loss = 2.51961234\n",
            "Validation score: 0.170940\n",
            "Iteration 31, loss = 2.51937586\n",
            "Validation score: 0.166667\n",
            "Iteration 32, loss = 2.51918677\n",
            "Validation score: 0.149573\n",
            "Iteration 33, loss = 2.51901977\n",
            "Validation score: 0.170940\n",
            "Iteration 34, loss = 2.51908680\n",
            "Validation score: 0.170940\n",
            "Iteration 35, loss = 2.51871716\n",
            "Validation score: 0.166667\n",
            "Iteration 36, loss = 2.51862376\n",
            "Validation score: 0.149573\n",
            "Iteration 37, loss = 2.51857213\n",
            "Validation score: 0.166667\n",
            "Iteration 38, loss = 2.51850486\n",
            "Validation score: 0.170940\n",
            "Iteration 39, loss = 2.51830985\n",
            "Validation score: 0.170940\n",
            "Iteration 40, loss = 2.51812837\n",
            "Validation score: 0.170940\n",
            "Iteration 41, loss = 2.51838585\n",
            "Validation score: 0.170940\n",
            "Iteration 42, loss = 2.51776216\n",
            "Validation score: 0.166667\n",
            "Iteration 43, loss = 2.51789378\n",
            "Validation score: 0.166667\n",
            "Iteration 44, loss = 2.51765127\n",
            "Validation score: 0.170940\n",
            "Iteration 45, loss = 2.51754142\n",
            "Validation score: 0.170940\n",
            "Iteration 46, loss = 2.51730902\n",
            "Validation score: 0.170940\n",
            "Iteration 47, loss = 2.51715911\n",
            "Validation score: 0.162393\n",
            "Iteration 48, loss = 2.51719462\n",
            "Validation score: 0.170940\n",
            "Iteration 49, loss = 2.51707675\n",
            "Validation score: 0.162393\n",
            "Iteration 50, loss = 2.51681229\n",
            "Validation score: 0.170940\n",
            "Iteration 51, loss = 2.51682779\n",
            "Validation score: 0.166667\n",
            "Iteration 52, loss = 2.51662483\n",
            "Validation score: 0.170940\n",
            "Iteration 53, loss = 2.51640763\n",
            "Validation score: 0.166667\n",
            "Iteration 54, loss = 2.51630108\n",
            "Validation score: 0.170940\n",
            "Iteration 55, loss = 2.51598448\n",
            "Validation score: 0.170940\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.27734284\n",
            "Validation score: 0.051282\n",
            "Iteration 2, loss = 3.03521741\n",
            "Validation score: 0.158120\n",
            "Iteration 3, loss = 2.79929030\n",
            "Validation score: 0.158120\n",
            "Iteration 4, loss = 2.66061924\n",
            "Validation score: 0.162393\n",
            "Iteration 5, loss = 2.57822605\n",
            "Validation score: 0.162393\n",
            "Iteration 6, loss = 2.53105660\n",
            "Validation score: 0.192308\n",
            "Iteration 7, loss = 2.50720216\n",
            "Validation score: 0.196581\n",
            "Iteration 8, loss = 2.49533278\n",
            "Validation score: 0.196581\n",
            "Iteration 9, loss = 2.48756238\n",
            "Validation score: 0.200855\n",
            "Iteration 10, loss = 2.48171760\n",
            "Validation score: 0.196581\n",
            "Iteration 11, loss = 2.47643007\n",
            "Validation score: 0.188034\n",
            "Iteration 12, loss = 2.47159841\n",
            "Validation score: 0.196581\n",
            "Iteration 13, loss = 2.46665852\n",
            "Validation score: 0.196581\n",
            "Iteration 14, loss = 2.46148587\n",
            "Validation score: 0.192308\n",
            "Iteration 15, loss = 2.45684354\n",
            "Validation score: 0.200855\n",
            "Iteration 16, loss = 2.45194794\n",
            "Validation score: 0.205128\n",
            "Iteration 17, loss = 2.44687681\n",
            "Validation score: 0.209402\n",
            "Iteration 18, loss = 2.44139943\n",
            "Validation score: 0.213675\n",
            "Iteration 19, loss = 2.43556524\n",
            "Validation score: 0.217949\n",
            "Iteration 20, loss = 2.43031573\n",
            "Validation score: 0.213675\n",
            "Iteration 21, loss = 2.42428768\n",
            "Validation score: 0.213675\n",
            "Iteration 22, loss = 2.41802242\n",
            "Validation score: 0.196581\n",
            "Iteration 23, loss = 2.41223114\n",
            "Validation score: 0.196581\n",
            "Iteration 24, loss = 2.40576439\n",
            "Validation score: 0.192308\n",
            "Iteration 25, loss = 2.39966425\n",
            "Validation score: 0.188034\n",
            "Iteration 26, loss = 2.39281709\n",
            "Validation score: 0.200855\n",
            "Iteration 27, loss = 2.38616609\n",
            "Validation score: 0.188034\n",
            "Iteration 28, loss = 2.38027069\n",
            "Validation score: 0.188034\n",
            "Iteration 29, loss = 2.37427198\n",
            "Validation score: 0.188034\n",
            "Iteration 30, loss = 2.36814862\n",
            "Validation score: 0.192308\n",
            "Iteration 31, loss = 2.36191339\n",
            "Validation score: 0.196581\n",
            "Iteration 32, loss = 2.35587743\n",
            "Validation score: 0.205128\n",
            "Iteration 33, loss = 2.35030713\n",
            "Validation score: 0.205128\n",
            "Iteration 34, loss = 2.34438956\n",
            "Validation score: 0.200855\n",
            "Iteration 35, loss = 2.33881874\n",
            "Validation score: 0.200855\n",
            "Iteration 36, loss = 2.33386098\n",
            "Validation score: 0.205128\n",
            "Iteration 37, loss = 2.32805438\n",
            "Validation score: 0.205128\n",
            "Iteration 38, loss = 2.32315118\n",
            "Validation score: 0.200855\n",
            "Iteration 39, loss = 2.31800056\n",
            "Validation score: 0.200855\n",
            "Iteration 40, loss = 2.31345344\n",
            "Validation score: 0.209402\n",
            "Iteration 41, loss = 2.30897868\n",
            "Validation score: 0.205128\n",
            "Iteration 42, loss = 2.30390956\n",
            "Validation score: 0.217949\n",
            "Iteration 43, loss = 2.29933330\n",
            "Validation score: 0.213675\n",
            "Iteration 44, loss = 2.29575459\n",
            "Validation score: 0.213675\n",
            "Iteration 45, loss = 2.29103153\n",
            "Validation score: 0.217949\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.33836634\n",
            "Validation score: 0.047009\n",
            "Iteration 2, loss = 3.10950203\n",
            "Validation score: 0.051282\n",
            "Iteration 3, loss = 2.97797350\n",
            "Validation score: 0.106838\n",
            "Iteration 4, loss = 2.83744054\n",
            "Validation score: 0.196581\n",
            "Iteration 5, loss = 2.69385738\n",
            "Validation score: 0.205128\n",
            "Iteration 6, loss = 2.59501089\n",
            "Validation score: 0.183761\n",
            "Iteration 7, loss = 2.55201514\n",
            "Validation score: 0.170940\n",
            "Iteration 8, loss = 2.53382733\n",
            "Validation score: 0.170940\n",
            "Iteration 9, loss = 2.52403062\n",
            "Validation score: 0.158120\n",
            "Iteration 10, loss = 2.51705341\n",
            "Validation score: 0.162393\n",
            "Iteration 11, loss = 2.51244170\n",
            "Validation score: 0.158120\n",
            "Iteration 12, loss = 2.50818657\n",
            "Validation score: 0.162393\n",
            "Iteration 13, loss = 2.50534967\n",
            "Validation score: 0.166667\n",
            "Iteration 14, loss = 2.50256314\n",
            "Validation score: 0.145299\n",
            "Iteration 15, loss = 2.50029062\n",
            "Validation score: 0.158120\n",
            "Iteration 16, loss = 2.49827041\n",
            "Validation score: 0.149573\n",
            "Iteration 17, loss = 2.49654292\n",
            "Validation score: 0.149573\n",
            "Iteration 18, loss = 2.49382573\n",
            "Validation score: 0.166667\n",
            "Iteration 19, loss = 2.49181463\n",
            "Validation score: 0.166667\n",
            "Iteration 20, loss = 2.49004913\n",
            "Validation score: 0.153846\n",
            "Iteration 21, loss = 2.48719645\n",
            "Validation score: 0.162393\n",
            "Iteration 22, loss = 2.48504687\n",
            "Validation score: 0.149573\n",
            "Iteration 23, loss = 2.48189052\n",
            "Validation score: 0.158120\n",
            "Iteration 24, loss = 2.47952189\n",
            "Validation score: 0.166667\n",
            "Iteration 25, loss = 2.47621102\n",
            "Validation score: 0.158120\n",
            "Iteration 26, loss = 2.47215722\n",
            "Validation score: 0.162393\n",
            "Iteration 27, loss = 2.46828413\n",
            "Validation score: 0.158120\n",
            "Iteration 28, loss = 2.46330443\n",
            "Validation score: 0.158120\n",
            "Iteration 29, loss = 2.45881557\n",
            "Validation score: 0.158120\n",
            "Iteration 30, loss = 2.45347025\n",
            "Validation score: 0.158120\n",
            "Iteration 31, loss = 2.44783622\n",
            "Validation score: 0.162393\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.20733460\n",
            "Validation score: 0.012821\n",
            "Iteration 2, loss = 3.03584246\n",
            "Validation score: 0.072650\n",
            "Iteration 3, loss = 2.81791348\n",
            "Validation score: 0.166667\n",
            "Iteration 4, loss = 2.62234500\n",
            "Validation score: 0.162393\n",
            "Iteration 5, loss = 2.54312924\n",
            "Validation score: 0.179487\n",
            "Iteration 6, loss = 2.51602649\n",
            "Validation score: 0.166667\n",
            "Iteration 7, loss = 2.50362748\n",
            "Validation score: 0.166667\n",
            "Iteration 8, loss = 2.49402729\n",
            "Validation score: 0.166667\n",
            "Iteration 9, loss = 2.48582536\n",
            "Validation score: 0.179487\n",
            "Iteration 10, loss = 2.47831640\n",
            "Validation score: 0.175214\n",
            "Iteration 11, loss = 2.46980319\n",
            "Validation score: 0.166667\n",
            "Iteration 12, loss = 2.46108195\n",
            "Validation score: 0.170940\n",
            "Iteration 13, loss = 2.45210406\n",
            "Validation score: 0.170940\n",
            "Iteration 14, loss = 2.44364617\n",
            "Validation score: 0.170940\n",
            "Iteration 15, loss = 2.43512694\n",
            "Validation score: 0.166667\n",
            "Iteration 16, loss = 2.42642299\n",
            "Validation score: 0.166667\n",
            "Iteration 17, loss = 2.41825870\n",
            "Validation score: 0.170940\n",
            "Iteration 18, loss = 2.41003174\n",
            "Validation score: 0.170940\n",
            "Iteration 19, loss = 2.40210037\n",
            "Validation score: 0.175214\n",
            "Iteration 20, loss = 2.39355131\n",
            "Validation score: 0.188034\n",
            "Iteration 21, loss = 2.38627822\n",
            "Validation score: 0.213675\n",
            "Iteration 22, loss = 2.37793488\n",
            "Validation score: 0.222222\n",
            "Iteration 23, loss = 2.37039556\n",
            "Validation score: 0.217949\n",
            "Iteration 24, loss = 2.36338358\n",
            "Validation score: 0.217949\n",
            "Iteration 25, loss = 2.35572781\n",
            "Validation score: 0.217949\n",
            "Iteration 26, loss = 2.34908493\n",
            "Validation score: 0.213675\n",
            "Iteration 27, loss = 2.34238204\n",
            "Validation score: 0.217949\n",
            "Iteration 28, loss = 2.33579763\n",
            "Validation score: 0.222222\n",
            "Iteration 29, loss = 2.32979066\n",
            "Validation score: 0.226496\n",
            "Iteration 30, loss = 2.32409923\n",
            "Validation score: 0.235043\n",
            "Iteration 31, loss = 2.31782963\n",
            "Validation score: 0.235043\n",
            "Iteration 32, loss = 2.31250568\n",
            "Validation score: 0.243590\n",
            "Iteration 33, loss = 2.30709065\n",
            "Validation score: 0.243590\n",
            "Iteration 34, loss = 2.30232286\n",
            "Validation score: 0.252137\n",
            "Iteration 35, loss = 2.29725620\n",
            "Validation score: 0.247863\n",
            "Iteration 36, loss = 2.29303394\n",
            "Validation score: 0.247863\n",
            "Iteration 37, loss = 2.28815724\n",
            "Validation score: 0.243590\n",
            "Iteration 38, loss = 2.28400254\n",
            "Validation score: 0.247863\n",
            "Iteration 39, loss = 2.28006917\n",
            "Validation score: 0.243590\n",
            "Iteration 40, loss = 2.27652315\n",
            "Validation score: 0.239316\n",
            "Iteration 41, loss = 2.27290244\n",
            "Validation score: 0.230769\n",
            "Iteration 42, loss = 2.26912472\n",
            "Validation score: 0.243590\n",
            "Iteration 43, loss = 2.26604486\n",
            "Validation score: 0.243590\n",
            "Iteration 44, loss = 2.26253123\n",
            "Validation score: 0.247863\n",
            "Iteration 45, loss = 2.25947718\n",
            "Validation score: 0.252137\n",
            "Iteration 46, loss = 2.25637397\n",
            "Validation score: 0.247863\n",
            "Iteration 47, loss = 2.25412787\n",
            "Validation score: 0.239316\n",
            "Iteration 48, loss = 2.25129492\n",
            "Validation score: 0.239316\n",
            "Iteration 49, loss = 2.24896532\n",
            "Validation score: 0.239316\n",
            "Iteration 50, loss = 2.24620387\n",
            "Validation score: 0.239316\n",
            "Iteration 51, loss = 2.24410683\n",
            "Validation score: 0.235043\n",
            "Iteration 52, loss = 2.24168793\n",
            "Validation score: 0.235043\n",
            "Iteration 53, loss = 2.23916543\n",
            "Validation score: 0.252137\n",
            "Iteration 54, loss = 2.23744416\n",
            "Validation score: 0.235043\n",
            "Iteration 55, loss = 2.23552226\n",
            "Validation score: 0.247863\n",
            "Iteration 56, loss = 2.23285107\n",
            "Validation score: 0.235043\n",
            "Iteration 57, loss = 2.23150709\n",
            "Validation score: 0.239316\n",
            "Iteration 58, loss = 2.22904736\n",
            "Validation score: 0.247863\n",
            "Iteration 59, loss = 2.22789606\n",
            "Validation score: 0.230769\n",
            "Iteration 60, loss = 2.22581260\n",
            "Validation score: 0.247863\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.14401291\n",
            "Validation score: 0.128205\n",
            "Iteration 2, loss = 2.99281873\n",
            "Validation score: 0.128205\n",
            "Iteration 3, loss = 2.86403687\n",
            "Validation score: 0.128205\n",
            "Iteration 4, loss = 2.75307854\n",
            "Validation score: 0.128205\n",
            "Iteration 5, loss = 2.67216525\n",
            "Validation score: 0.128205\n",
            "Iteration 6, loss = 2.61816514\n",
            "Validation score: 0.158120\n",
            "Iteration 7, loss = 2.58304992\n",
            "Validation score: 0.158120\n",
            "Iteration 8, loss = 2.56066474\n",
            "Validation score: 0.158120\n",
            "Iteration 9, loss = 2.54638802\n",
            "Validation score: 0.158120\n",
            "Iteration 10, loss = 2.53676051\n",
            "Validation score: 0.158120\n",
            "Iteration 11, loss = 2.53034412\n",
            "Validation score: 0.162393\n",
            "Iteration 12, loss = 2.52579024\n",
            "Validation score: 0.162393\n",
            "Iteration 13, loss = 2.52204019\n",
            "Validation score: 0.162393\n",
            "Iteration 14, loss = 2.51923475\n",
            "Validation score: 0.162393\n",
            "Iteration 15, loss = 2.51593073\n",
            "Validation score: 0.162393\n",
            "Iteration 16, loss = 2.51280561\n",
            "Validation score: 0.162393\n",
            "Iteration 17, loss = 2.50929117\n",
            "Validation score: 0.162393\n",
            "Iteration 18, loss = 2.50519352\n",
            "Validation score: 0.183761\n",
            "Iteration 19, loss = 2.50043393\n",
            "Validation score: 0.175214\n",
            "Iteration 20, loss = 2.49564949\n",
            "Validation score: 0.183761\n",
            "Iteration 21, loss = 2.49059291\n",
            "Validation score: 0.175214\n",
            "Iteration 22, loss = 2.48535680\n",
            "Validation score: 0.183761\n",
            "Iteration 23, loss = 2.47977254\n",
            "Validation score: 0.175214\n",
            "Iteration 24, loss = 2.47411346\n",
            "Validation score: 0.175214\n",
            "Iteration 25, loss = 2.46799780\n",
            "Validation score: 0.175214\n",
            "Iteration 26, loss = 2.46197055\n",
            "Validation score: 0.183761\n",
            "Iteration 27, loss = 2.45650186\n",
            "Validation score: 0.179487\n",
            "Iteration 28, loss = 2.45173384\n",
            "Validation score: 0.183761\n",
            "Iteration 29, loss = 2.44733310\n",
            "Validation score: 0.179487\n",
            "Iteration 30, loss = 2.44304430\n",
            "Validation score: 0.179487\n",
            "Iteration 31, loss = 2.43907772\n",
            "Validation score: 0.179487\n",
            "Iteration 32, loss = 2.43487282\n",
            "Validation score: 0.179487\n",
            "Iteration 33, loss = 2.43068039\n",
            "Validation score: 0.179487\n",
            "Iteration 34, loss = 2.42698534\n",
            "Validation score: 0.183761\n",
            "Iteration 35, loss = 2.42266810\n",
            "Validation score: 0.188034\n",
            "Iteration 36, loss = 2.41872368\n",
            "Validation score: 0.192308\n",
            "Iteration 37, loss = 2.41453070\n",
            "Validation score: 0.192308\n",
            "Iteration 38, loss = 2.41058224\n",
            "Validation score: 0.196581\n",
            "Iteration 39, loss = 2.40660942\n",
            "Validation score: 0.196581\n",
            "Iteration 40, loss = 2.40203045\n",
            "Validation score: 0.205128\n",
            "Iteration 41, loss = 2.39772593\n",
            "Validation score: 0.200855\n",
            "Iteration 42, loss = 2.39282385\n",
            "Validation score: 0.209402\n",
            "Iteration 43, loss = 2.38789990\n",
            "Validation score: 0.196581\n",
            "Iteration 44, loss = 2.38296976\n",
            "Validation score: 0.217949\n",
            "Iteration 45, loss = 2.37842286\n",
            "Validation score: 0.200855\n",
            "Iteration 46, loss = 2.37364727\n",
            "Validation score: 0.217949\n",
            "Iteration 47, loss = 2.36924946\n",
            "Validation score: 0.213675\n",
            "Iteration 48, loss = 2.36508074\n",
            "Validation score: 0.209402\n",
            "Iteration 49, loss = 2.36107754\n",
            "Validation score: 0.209402\n",
            "Iteration 50, loss = 2.35691326\n",
            "Validation score: 0.226496\n",
            "Iteration 51, loss = 2.35262344\n",
            "Validation score: 0.222222\n",
            "Iteration 52, loss = 2.34886982\n",
            "Validation score: 0.226496\n",
            "Iteration 53, loss = 2.34514100\n",
            "Validation score: 0.217949\n",
            "Iteration 54, loss = 2.34152263\n",
            "Validation score: 0.235043\n",
            "Iteration 55, loss = 2.33840142\n",
            "Validation score: 0.230769\n",
            "Iteration 56, loss = 2.33461944\n",
            "Validation score: 0.243590\n",
            "Iteration 57, loss = 2.33132137\n",
            "Validation score: 0.230769\n",
            "Iteration 58, loss = 2.32792232\n",
            "Validation score: 0.226496\n",
            "Iteration 59, loss = 2.32454758\n",
            "Validation score: 0.226496\n",
            "Iteration 60, loss = 2.32160088\n",
            "Validation score: 0.217949\n",
            "Iteration 61, loss = 2.31892351\n",
            "Validation score: 0.222222\n",
            "Iteration 62, loss = 2.31543476\n",
            "Validation score: 0.239316\n",
            "Iteration 63, loss = 2.31317853\n",
            "Validation score: 0.217949\n",
            "Iteration 64, loss = 2.31074066\n",
            "Validation score: 0.230769\n",
            "Iteration 65, loss = 2.30753328\n",
            "Validation score: 0.239316\n",
            "Iteration 66, loss = 2.30506741\n",
            "Validation score: 0.217949\n",
            "Iteration 67, loss = 2.30242294\n",
            "Validation score: 0.252137\n",
            "Iteration 68, loss = 2.30020823\n",
            "Validation score: 0.243590\n",
            "Iteration 69, loss = 2.29769360\n",
            "Validation score: 0.247863\n",
            "Iteration 70, loss = 2.29532381\n",
            "Validation score: 0.217949\n",
            "Iteration 71, loss = 2.29364375\n",
            "Validation score: 0.239316\n",
            "Iteration 72, loss = 2.29132556\n",
            "Validation score: 0.230769\n",
            "Iteration 73, loss = 2.28903508\n",
            "Validation score: 0.222222\n",
            "Iteration 74, loss = 2.28694845\n",
            "Validation score: 0.226496\n",
            "Iteration 75, loss = 2.28486867\n",
            "Validation score: 0.226496\n",
            "Iteration 76, loss = 2.28313688\n",
            "Validation score: 0.222222\n",
            "Iteration 77, loss = 2.28134196\n",
            "Validation score: 0.226496\n",
            "Iteration 78, loss = 2.27930489\n",
            "Validation score: 0.222222\n",
            "Iteration 79, loss = 2.27763871\n",
            "Validation score: 0.226496\n",
            "Iteration 80, loss = 2.27589964\n",
            "Validation score: 0.213675\n",
            "Iteration 81, loss = 2.27410383\n",
            "Validation score: 0.235043\n",
            "Iteration 82, loss = 2.27196415\n",
            "Validation score: 0.239316\n",
            "Iteration 83, loss = 2.27131743\n",
            "Validation score: 0.205128\n",
            "Iteration 84, loss = 2.26930411\n",
            "Validation score: 0.222222\n",
            "Iteration 85, loss = 2.26795987\n",
            "Validation score: 0.239316\n",
            "Iteration 86, loss = 2.26581981\n",
            "Validation score: 0.243590\n",
            "Iteration 87, loss = 2.26485303\n",
            "Validation score: 0.230769\n",
            "Iteration 88, loss = 2.26316525\n",
            "Validation score: 0.243590\n",
            "Iteration 89, loss = 2.26134181\n",
            "Validation score: 0.247863\n",
            "Iteration 90, loss = 2.26050007\n",
            "Validation score: 0.235043\n",
            "Iteration 91, loss = 2.25883448\n",
            "Validation score: 0.230769\n",
            "Iteration 92, loss = 2.25746183\n",
            "Validation score: 0.239316\n",
            "Iteration 93, loss = 2.25622458\n",
            "Validation score: 0.222222\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.06720506\n",
            "Validation score: 0.149573\n",
            "Iteration 2, loss = 2.92207540\n",
            "Validation score: 0.149573\n",
            "Iteration 3, loss = 2.78069113\n",
            "Validation score: 0.149573\n",
            "Iteration 4, loss = 2.67681339\n",
            "Validation score: 0.149573\n",
            "Iteration 5, loss = 2.60945084\n",
            "Validation score: 0.149573\n",
            "Iteration 6, loss = 2.56585867\n",
            "Validation score: 0.149573\n",
            "Iteration 7, loss = 2.53828181\n",
            "Validation score: 0.149573\n",
            "Iteration 8, loss = 2.52175852\n",
            "Validation score: 0.149573\n",
            "Iteration 9, loss = 2.51208540\n",
            "Validation score: 0.149573\n",
            "Iteration 10, loss = 2.50519427\n",
            "Validation score: 0.149573\n",
            "Iteration 11, loss = 2.49912766\n",
            "Validation score: 0.149573\n",
            "Iteration 12, loss = 2.49425540\n",
            "Validation score: 0.149573\n",
            "Iteration 13, loss = 2.48960521\n",
            "Validation score: 0.149573\n",
            "Iteration 14, loss = 2.48485341\n",
            "Validation score: 0.149573\n",
            "Iteration 15, loss = 2.48055477\n",
            "Validation score: 0.149573\n",
            "Iteration 16, loss = 2.47574963\n",
            "Validation score: 0.149573\n",
            "Iteration 17, loss = 2.47097365\n",
            "Validation score: 0.153846\n",
            "Iteration 18, loss = 2.46610827\n",
            "Validation score: 0.153846\n",
            "Iteration 19, loss = 2.46185584\n",
            "Validation score: 0.153846\n",
            "Iteration 20, loss = 2.45696550\n",
            "Validation score: 0.166667\n",
            "Iteration 21, loss = 2.45292876\n",
            "Validation score: 0.166667\n",
            "Iteration 22, loss = 2.44878402\n",
            "Validation score: 0.153846\n",
            "Iteration 23, loss = 2.44482095\n",
            "Validation score: 0.170940\n",
            "Iteration 24, loss = 2.44108298\n",
            "Validation score: 0.175214\n",
            "Iteration 25, loss = 2.43704924\n",
            "Validation score: 0.170940\n",
            "Iteration 26, loss = 2.43350129\n",
            "Validation score: 0.170940\n",
            "Iteration 27, loss = 2.42985067\n",
            "Validation score: 0.170940\n",
            "Iteration 28, loss = 2.42603088\n",
            "Validation score: 0.175214\n",
            "Iteration 29, loss = 2.42311944\n",
            "Validation score: 0.162393\n",
            "Iteration 30, loss = 2.42012749\n",
            "Validation score: 0.158120\n",
            "Iteration 31, loss = 2.41623151\n",
            "Validation score: 0.162393\n",
            "Iteration 32, loss = 2.41301504\n",
            "Validation score: 0.158120\n",
            "Iteration 33, loss = 2.41042295\n",
            "Validation score: 0.200855\n",
            "Iteration 34, loss = 2.40764098\n",
            "Validation score: 0.188034\n",
            "Iteration 35, loss = 2.40406443\n",
            "Validation score: 0.170940\n",
            "Iteration 36, loss = 2.40076819\n",
            "Validation score: 0.192308\n",
            "Iteration 37, loss = 2.39858262\n",
            "Validation score: 0.200855\n",
            "Iteration 38, loss = 2.39557654\n",
            "Validation score: 0.200855\n",
            "Iteration 39, loss = 2.39300890\n",
            "Validation score: 0.183761\n",
            "Iteration 40, loss = 2.39036865\n",
            "Validation score: 0.196581\n",
            "Iteration 41, loss = 2.38775295\n",
            "Validation score: 0.196581\n",
            "Iteration 42, loss = 2.38539580\n",
            "Validation score: 0.205128\n",
            "Iteration 43, loss = 2.38294178\n",
            "Validation score: 0.205128\n",
            "Iteration 44, loss = 2.38105795\n",
            "Validation score: 0.196581\n",
            "Iteration 45, loss = 2.37808768\n",
            "Validation score: 0.200855\n",
            "Iteration 46, loss = 2.37603265\n",
            "Validation score: 0.200855\n",
            "Iteration 47, loss = 2.37404596\n",
            "Validation score: 0.192308\n",
            "Iteration 48, loss = 2.37221718\n",
            "Validation score: 0.213675\n",
            "Iteration 49, loss = 2.36972037\n",
            "Validation score: 0.196581\n",
            "Iteration 50, loss = 2.36746810\n",
            "Validation score: 0.205128\n",
            "Iteration 51, loss = 2.36596122\n",
            "Validation score: 0.200855\n",
            "Iteration 52, loss = 2.36404043\n",
            "Validation score: 0.196581\n",
            "Iteration 53, loss = 2.36241858\n",
            "Validation score: 0.179487\n",
            "Iteration 54, loss = 2.36004432\n",
            "Validation score: 0.183761\n",
            "Iteration 55, loss = 2.35838052\n",
            "Validation score: 0.209402\n",
            "Iteration 56, loss = 2.35689594\n",
            "Validation score: 0.183761\n",
            "Iteration 57, loss = 2.35538780\n",
            "Validation score: 0.209402\n",
            "Iteration 58, loss = 2.35347848\n",
            "Validation score: 0.183761\n",
            "Iteration 59, loss = 2.35232701\n",
            "Validation score: 0.183761\n",
            "Iteration 60, loss = 2.35068394\n",
            "Validation score: 0.183761\n",
            "Iteration 61, loss = 2.34832975\n",
            "Validation score: 0.205128\n",
            "Iteration 62, loss = 2.34713380\n",
            "Validation score: 0.196581\n",
            "Iteration 63, loss = 2.34538561\n",
            "Validation score: 0.209402\n",
            "Iteration 64, loss = 2.34449268\n",
            "Validation score: 0.205128\n",
            "Iteration 65, loss = 2.34312121\n",
            "Validation score: 0.217949\n",
            "Iteration 66, loss = 2.34156060\n",
            "Validation score: 0.192308\n",
            "Iteration 67, loss = 2.34015657\n",
            "Validation score: 0.179487\n",
            "Iteration 68, loss = 2.33950324\n",
            "Validation score: 0.209402\n",
            "Iteration 69, loss = 2.33796051\n",
            "Validation score: 0.196581\n",
            "Iteration 70, loss = 2.33639679\n",
            "Validation score: 0.200855\n",
            "Iteration 71, loss = 2.33526102\n",
            "Validation score: 0.183761\n",
            "Iteration 72, loss = 2.33453455\n",
            "Validation score: 0.188034\n",
            "Iteration 73, loss = 2.33271669\n",
            "Validation score: 0.188034\n",
            "Iteration 74, loss = 2.33155917\n",
            "Validation score: 0.205128\n",
            "Iteration 75, loss = 2.33098513\n",
            "Validation score: 0.209402\n",
            "Iteration 76, loss = 2.33014075\n",
            "Validation score: 0.196581\n",
            "Iteration 77, loss = 2.32942512\n",
            "Validation score: 0.196581\n",
            "Iteration 78, loss = 2.32777490\n",
            "Validation score: 0.196581\n",
            "Iteration 79, loss = 2.32711635\n",
            "Validation score: 0.196581\n",
            "Iteration 80, loss = 2.32638615\n",
            "Validation score: 0.200855\n",
            "Iteration 81, loss = 2.32522517\n",
            "Validation score: 0.196581\n",
            "Iteration 82, loss = 2.32462298\n",
            "Validation score: 0.192308\n",
            "Iteration 83, loss = 2.32405065\n",
            "Validation score: 0.200855\n",
            "Iteration 84, loss = 2.32256409\n",
            "Validation score: 0.179487\n",
            "Iteration 85, loss = 2.32206730\n",
            "Validation score: 0.200855\n",
            "Iteration 86, loss = 2.32122962\n",
            "Validation score: 0.188034\n",
            "Iteration 87, loss = 2.32090414\n",
            "Validation score: 0.183761\n",
            "Iteration 88, loss = 2.31976211\n",
            "Validation score: 0.200855\n",
            "Iteration 89, loss = 2.31905501\n",
            "Validation score: 0.166667\n",
            "Iteration 90, loss = 2.31814961\n",
            "Validation score: 0.183761\n",
            "Iteration 91, loss = 2.31743663\n",
            "Validation score: 0.183761\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 3.39586776\n",
            "Validation score: 0.034188\n",
            "Iteration 2, loss = 3.28611449\n",
            "Validation score: 0.034188\n",
            "Iteration 3, loss = 3.18803785\n",
            "Validation score: 0.034188\n",
            "Iteration 4, loss = 3.10038513\n",
            "Validation score: 0.042735\n",
            "Iteration 5, loss = 3.02249349\n",
            "Validation score: 0.102564\n",
            "Iteration 6, loss = 2.95391575\n",
            "Validation score: 0.102564\n",
            "Iteration 7, loss = 2.89391031\n",
            "Validation score: 0.102564\n",
            "Iteration 8, loss = 2.84182558\n",
            "Validation score: 0.102564\n",
            "Iteration 9, loss = 2.79671289\n",
            "Validation score: 0.192308\n",
            "Iteration 10, loss = 2.75792197\n",
            "Validation score: 0.192308\n",
            "Iteration 11, loss = 2.72451449\n",
            "Validation score: 0.192308\n",
            "Iteration 12, loss = 2.69603226\n",
            "Validation score: 0.192308\n",
            "Iteration 13, loss = 2.67194251\n",
            "Validation score: 0.166667\n",
            "Iteration 14, loss = 2.65126537\n",
            "Validation score: 0.166667\n",
            "Iteration 15, loss = 2.63373127\n",
            "Validation score: 0.166667\n",
            "Iteration 16, loss = 2.61882715\n",
            "Validation score: 0.166667\n",
            "Iteration 17, loss = 2.60608422\n",
            "Validation score: 0.166667\n",
            "Iteration 18, loss = 2.59522718\n",
            "Validation score: 0.166667\n",
            "Iteration 19, loss = 2.58595267\n",
            "Validation score: 0.166667\n",
            "Iteration 20, loss = 2.57799139\n",
            "Validation score: 0.166667\n",
            "Iteration 21, loss = 2.57114567\n",
            "Validation score: 0.166667\n",
            "Iteration 22, loss = 2.56529971\n",
            "Validation score: 0.166667\n",
            "Iteration 23, loss = 2.56016213\n",
            "Validation score: 0.166667\n",
            "Iteration 24, loss = 2.55576618\n",
            "Validation score: 0.166667\n",
            "Iteration 25, loss = 2.55179885\n",
            "Validation score: 0.166667\n",
            "Iteration 26, loss = 2.54847011\n",
            "Validation score: 0.166667\n",
            "Iteration 27, loss = 2.54544941\n",
            "Validation score: 0.166667\n",
            "Iteration 28, loss = 2.54280072\n",
            "Validation score: 0.166667\n",
            "Iteration 29, loss = 2.54038580\n",
            "Validation score: 0.166667\n",
            "Iteration 30, loss = 2.53821158\n",
            "Validation score: 0.166667\n",
            "Iteration 31, loss = 2.53639916\n",
            "Validation score: 0.166667\n",
            "Iteration 32, loss = 2.53464732\n",
            "Validation score: 0.166667\n",
            "Iteration 33, loss = 2.53301323\n",
            "Validation score: 0.166667\n",
            "Iteration 34, loss = 2.53165186\n",
            "Validation score: 0.166667\n",
            "Iteration 35, loss = 2.53039664\n",
            "Validation score: 0.166667\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "1050 fits failed out of a total of 1800.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "300 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 384, in _fit\n",
            "    self._validate_hyperparameters()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 481, in _validate_hyperparameters\n",
            "    raise ValueError(\"beta_1 must be >= 0 and < 1, got %s\" % self.beta_1)\n",
            "ValueError: beta_1 must be >= 0 and < 1, got 1\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "750 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n",
            "    return self._fit(X, y, incremental=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 384, in _fit\n",
            "    self._validate_hyperparameters()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 493, in _validate_hyperparameters\n",
            "    raise ValueError(\n",
            "ValueError: The activation 'sigmoide' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.20865355 0.2217094  0.1895024  0.25556434 0.25624107 0.24833977\n",
            " 0.22581431 0.19979218 0.17964231 0.16933322 0.23640206 0.24153378\n",
            " 0.21723744 0.20426238 0.23740955 0.26581665 0.20970612 0.23469324\n",
            " 0.25282461 0.21925126 0.24769055 0.18919857 0.22748683 0.15086934\n",
            " 0.17445967 0.24392518 0.22441576 0.20251961 0.21688444 0.19192776\n",
            " 0.21689088 0.25623405 0.20489287 0.23846271 0.22751844 0.25794755\n",
            " 0.24118136 0.2445908  0.24358155 0.18269758 0.24940171 0.23367112\n",
            " 0.25178609 0.21176443 0.24392811 0.27129083 0.22683527 0.22136518\n",
            " 0.24939995 0.20697693 0.26342641 0.1809712  0.25213207 0.19053331\n",
            " 0.20148812 0.20594485 0.16591968 0.21828123 0.16899485 0.17416228\n",
            " 0.21213441 0.21930863 0.15771865 0.2141494  0.19467275 0.17786969\n",
            " 0.17412305 0.20218885 0.19673106 0.17002107 0.2343578  0.22065449\n",
            " 0.1703893  0.21862487 0.2333146  0.25588514 0.17754127 0.20596886\n",
            " 0.20903173 0.20868458 0.22407446 0.16967861 0.24084007 0.18302599\n",
            " 0.23060063 0.22409261 0.19570484 0.21312961 0.18609823 0.18578445\n",
            " 0.19056726 0.23158354 0.19128088 0.21312434 0.23363365 0.21585412\n",
            " 0.23674511 0.25828709 0.22956855 0.15805468 0.2175881  0.24255064\n",
            " 0.20937537 0.25111345 0.23641494 0.25590505 0.23332104 0.24598056\n",
            " 0.24769406 0.1884791  0.25862662 0.18100632 0.23227315 0.17790306\n",
            " 0.20215724 0.20832865 0.19531671 0.20662569 0.22714495 0.22920091\n",
            " 0.19261445 0.24836963 0.22511006 0.23778188 0.24016333 0.24116146\n",
            " 0.26034715 0.16045779 0.23056609 0.1984229  0.22410022 0.25076221\n",
            " 0.22547711 0.22442337 0.21723335 0.23774909 0.21248039 0.23025758\n",
            " 0.20664325 0.21552687 0.2432262  0.17584709 0.18166667 0.16830992\n",
            " 0.2186237  0.19567088 0.20081841 0.19052746 0.19670062 0.17584768\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.23672757\n",
            "Validation score: 0.177474\n",
            "Iteration 2, loss = 3.03127272\n",
            "Validation score: 0.187713\n",
            "Iteration 3, loss = 2.69212154\n",
            "Validation score: 0.187713\n",
            "Iteration 4, loss = 2.54445424\n",
            "Validation score: 0.191126\n",
            "Iteration 5, loss = 2.47001858\n",
            "Validation score: 0.218430\n",
            "Iteration 6, loss = 2.37083871\n",
            "Validation score: 0.211604\n",
            "Iteration 7, loss = 2.28938246\n",
            "Validation score: 0.245734\n",
            "Iteration 8, loss = 2.24959963\n",
            "Validation score: 0.252560\n",
            "Iteration 9, loss = 2.22563777\n",
            "Validation score: 0.252560\n",
            "Iteration 10, loss = 2.20921312\n",
            "Validation score: 0.245734\n",
            "Iteration 11, loss = 2.19586016\n",
            "Validation score: 0.259386\n",
            "Iteration 12, loss = 2.18499811\n",
            "Validation score: 0.249147\n",
            "Iteration 13, loss = 2.17545248\n",
            "Validation score: 0.262799\n",
            "Iteration 14, loss = 2.16815545\n",
            "Validation score: 0.242321\n",
            "Iteration 15, loss = 2.16113238\n",
            "Validation score: 0.266212\n",
            "Iteration 16, loss = 2.15495127\n",
            "Validation score: 0.262799\n",
            "Iteration 17, loss = 2.14897101\n",
            "Validation score: 0.259386\n",
            "Iteration 18, loss = 2.14495196\n",
            "Validation score: 0.259386\n",
            "Iteration 19, loss = 2.13997524\n",
            "Validation score: 0.269625\n",
            "Iteration 20, loss = 2.13537514\n",
            "Validation score: 0.266212\n",
            "Iteration 21, loss = 2.13161657\n",
            "Validation score: 0.269625\n",
            "Iteration 22, loss = 2.12738013\n",
            "Validation score: 0.242321\n",
            "Iteration 23, loss = 2.12410448\n",
            "Validation score: 0.273038\n",
            "Iteration 24, loss = 2.12127126\n",
            "Validation score: 0.266212\n",
            "Iteration 25, loss = 2.11751493\n",
            "Validation score: 0.266212\n",
            "Iteration 26, loss = 2.11446194\n",
            "Validation score: 0.266212\n",
            "Iteration 27, loss = 2.11155360\n",
            "Validation score: 0.266212\n",
            "Iteration 28, loss = 2.10786920\n",
            "Validation score: 0.259386\n",
            "Iteration 29, loss = 2.10566870\n",
            "Validation score: 0.273038\n",
            "Iteration 30, loss = 2.10305803\n",
            "Validation score: 0.273038\n",
            "Iteration 31, loss = 2.10071447\n",
            "Validation score: 0.255973\n",
            "Iteration 32, loss = 2.09697159\n",
            "Validation score: 0.273038\n",
            "Iteration 33, loss = 2.09459229\n",
            "Validation score: 0.269625\n",
            "Iteration 34, loss = 2.09191854\n",
            "Validation score: 0.252560\n",
            "Iteration 35, loss = 2.08948626\n",
            "Validation score: 0.279863\n",
            "Iteration 36, loss = 2.08631833\n",
            "Validation score: 0.273038\n",
            "Iteration 37, loss = 2.08452724\n",
            "Validation score: 0.259386\n",
            "Iteration 38, loss = 2.08169808\n",
            "Validation score: 0.283276\n",
            "Iteration 39, loss = 2.07900951\n",
            "Validation score: 0.273038\n",
            "Iteration 40, loss = 2.07746790\n",
            "Validation score: 0.276451\n",
            "Iteration 41, loss = 2.07343747\n",
            "Validation score: 0.286689\n",
            "Iteration 42, loss = 2.07172392\n",
            "Validation score: 0.276451\n",
            "Iteration 43, loss = 2.07010594\n",
            "Validation score: 0.262799\n",
            "Iteration 44, loss = 2.06721035\n",
            "Validation score: 0.273038\n",
            "Iteration 45, loss = 2.06456460\n",
            "Validation score: 0.279863\n",
            "Iteration 46, loss = 2.06301882\n",
            "Validation score: 0.262799\n",
            "Iteration 47, loss = 2.06093762\n",
            "Validation score: 0.276451\n",
            "Iteration 48, loss = 2.05890798\n",
            "Validation score: 0.266212\n",
            "Iteration 49, loss = 2.05551035\n",
            "Validation score: 0.276451\n",
            "Iteration 50, loss = 2.05432823\n",
            "Validation score: 0.269625\n",
            "Iteration 51, loss = 2.05241810\n",
            "Validation score: 0.269625\n",
            "Iteration 52, loss = 2.04990947\n",
            "Validation score: 0.269625\n",
            "Iteration 53, loss = 2.04705806\n",
            "Validation score: 0.269625\n",
            "Iteration 54, loss = 2.04539092\n",
            "Validation score: 0.307167\n",
            "Iteration 55, loss = 2.04350885\n",
            "Validation score: 0.273038\n",
            "Iteration 56, loss = 2.04070355\n",
            "Validation score: 0.273038\n",
            "Iteration 57, loss = 2.03962108\n",
            "Validation score: 0.279863\n",
            "Iteration 58, loss = 2.03726300\n",
            "Validation score: 0.273038\n",
            "Iteration 59, loss = 2.03486467\n",
            "Validation score: 0.276451\n",
            "Iteration 60, loss = 2.03357201\n",
            "Validation score: 0.252560\n",
            "Iteration 61, loss = 2.03040332\n",
            "Validation score: 0.269625\n",
            "Iteration 62, loss = 2.02863091\n",
            "Validation score: 0.259386\n",
            "Iteration 63, loss = 2.02768616\n",
            "Validation score: 0.262799\n",
            "Iteration 64, loss = 2.02471698\n",
            "Validation score: 0.276451\n",
            "Iteration 65, loss = 2.02402161\n",
            "Validation score: 0.276451\n",
            "Iteration 66, loss = 2.02119098\n",
            "Validation score: 0.273038\n",
            "Iteration 67, loss = 2.01993660\n",
            "Validation score: 0.269625\n",
            "Iteration 68, loss = 2.01717361\n",
            "Validation score: 0.279863\n",
            "Iteration 69, loss = 2.01648400\n",
            "Validation score: 0.259386\n",
            "Iteration 70, loss = 2.01485927\n",
            "Validation score: 0.259386\n",
            "Iteration 71, loss = 2.01288534\n",
            "Validation score: 0.273038\n",
            "Iteration 72, loss = 2.01181444\n",
            "Validation score: 0.279863\n",
            "Iteration 73, loss = 2.01005027\n",
            "Validation score: 0.245734\n",
            "Iteration 74, loss = 2.00784602\n",
            "Validation score: 0.252560\n",
            "Iteration 75, loss = 2.00706332\n",
            "Validation score: 0.249147\n",
            "Iteration 76, loss = 2.00539976\n",
            "Validation score: 0.266212\n",
            "Iteration 77, loss = 2.00407669\n",
            "Validation score: 0.266212\n",
            "Iteration 78, loss = 2.00348591\n",
            "Validation score: 0.262799\n",
            "Iteration 79, loss = 2.00092998\n",
            "Validation score: 0.245734\n",
            "Iteration 80, loss = 2.00039320\n",
            "Validation score: 0.273038\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
            "{'activation': 'relu', 'batch_size': 16, 'beta_1': 0.8, 'hidden_layer_sizes': array([4, 4]), 'n_iter_no_change': 25, 'solver': 'adam'}\n"
          ]
        }
      ],
      "source": [
        "rede = MLPClassifier(early_stopping=True)\n",
        "\n",
        "grid_search = GridSearchCV(rede, param_grid, cv=3, n_jobs=-1, refit=False)\n",
        "grid_search.fit(X_train_norm.values, Y_train)\n",
        "\n",
        "# guardar os resultados\n",
        "results_grid_search = grid_search.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHYIqxqf4S0R"
      },
      "outputs": [],
      "source": [
        "results_test = results_grid_search['mean_test_score']\n",
        "results_test_clean = results_test[~np.isnan(results_test)]\n",
        "idx_sorted = np.argsort(results_test_clean)[::-1]\n",
        "\n",
        "three_bests = []\n",
        "for i in range(3):\n",
        "  three_bests.append(results_grid_search['params'][idx_sorted[i]])\n",
        "\n",
        "print(three_bests)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4ub38-G4S0R"
      },
      "outputs": [],
      "source": [
        "three_bests = [{'activation': 'relu', 'batch_size': 16, 'beta_1': 0.9, 'beta_2': 0.999, 'hidden_layer_sizes': (3, 5), 'learning_rate_init': 0.009, 'n_iter_no_change': 60, 'solver': 'adam'},\n",
        "               {'activation': 'relu', 'batch_size': 16, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (2, 1), 'learning_rate_init': 0.009, 'n_iter_no_change': 60, 'solver': 'adam'},\n",
        "               {'activation': 'relu', 'batch_size': 16, 'beta_1': 0.9, 'beta_2': 0.95, 'hidden_layer_sizes': (2, 6), 'learning_rate_init': 0.09, 'n_iter_no_change': 60, 'solver': 'adam'}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7kORgTM4S0R"
      },
      "outputs": [],
      "source": [
        "# Mostra as métricas dos três melhores\n",
        "for params in three_bests:\n",
        "    RNA = MLPClassifier(**params, max_iter=100, verbose=False)\n",
        "    RNA.fit(X_train_norm.values, Y_train)\n",
        "    RNA_y_prev =RNA.predict(X_test_norm)\n",
        "    print('---------------------')\n",
        "    show_metrics(Y_test, RNA_y_prev)\n",
        "    print('---------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpJdppybXzpL"
      },
      "source": [
        "### Argumente\n",
        "\n",
        "\"A busca em grade foi eficaz para encontrar boas RNAs MLP para o problema?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMRWUh4x4S0S"
      },
      "source": [
        "**Mesmo com a busca em grade as RNAs MLP encontradas se mostraram insatisfatórias. Com isso pode-se constatar que mesmo ao testar várias arquiteturas pode ser que não se ache de primeira a ideal para determinado problema.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAzfJCmBXzpL"
      },
      "source": [
        "## Otimização por Ajuste Fino (Fine-Tuning)\n",
        "\n",
        "Considerando a etapa anterior, foram identificadas 3 melhores RNAs MLPs com seus parâmetros e hiperparâmetros para o problema da classificação multi-classe da idade do Abalone. Uma das questões remanescentes é se o número de épocas foi suficiente para o treinamento e melhor aprendizado das características do problema, mas lembrando-se de prevenir overfitting.\n",
        "\n",
        "Com essas Top-3 RNAs identificadas, faça o que se pede:\n",
        "1. Aumente o número de épocas do treinamento para 600\n",
        "2. Aumenta a paciência para 60 (10% das épocas do treinamento)\n",
        "\n",
        "Repita o treinamento e o teste das 3 melhores RNAs e verifique se houve melhoria de desempenho. Apresente detalhadamente, para cada uma das redes, as métricas de acurácia, precisão, revocação e F1-Score (weighted), bem como a matriz de confusão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrCed4VOXzpL"
      },
      "outputs": [],
      "source": [
        "#Valores adquiridos da questão anterior e atribuidos diretamente por razões de tempo\n",
        "\n",
        "# Valor de beta_1 modificado pois 1 não é aceito.\n",
        "\n",
        "three_bests = [{'activation': 'relu', 'batch_size': 16, 'beta_1': 0.9, 'beta_2': 0.999, 'hidden_layer_sizes': (3, 5), 'learning_rate_init': 0.009, 'n_iter_no_change': 25, 'solver': 'adam'},\n",
        "               {'activation': 'relu', 'batch_size': 16, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (2, 1), 'learning_rate_init': 0.009, 'n_iter_no_change': 25, 'solver': 'adam'},\n",
        "               {'activation': 'relu', 'batch_size': 16, 'beta_1': 0.9, 'beta_2': 0.95, 'hidden_layer_sizes': (2, 6), 'learning_rate_init': 0.09, 'n_iter_no_change': 25, 'solver': 'adam'}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLz05GihXzpM"
      },
      "outputs": [],
      "source": [
        "rede1 = MLPClassifier(**three_bests[0], max_iter=600, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVbb7SCM4S0S"
      },
      "outputs": [],
      "source": [
        "rede1.fit(X_train_norm.values, Y_train)\n",
        "rede1_y_prev = rede1.predict(X_test_norm)\n",
        "confusion_matrix_plot(Y_test, rede1_y_prev)\n",
        "plot_results(X_train_norm, Y_train, X_test_norm, Y_test, rede1_y_prev)\n",
        "show_metrics(Y_test, rede1_y_prev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buNMTkfT4S0T"
      },
      "outputs": [],
      "source": [
        "rede2 = MLPClassifier(**three_bests[1], max_iter=600, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrsK9yK34S0T"
      },
      "outputs": [],
      "source": [
        "rede2.fit(X_train_norm.values, Y_train)\n",
        "rede2_y_prev = rede2.predict(X_test_norm)\n",
        "\n",
        "\n",
        "confusion_matrix_plot(Y_test, rede2_y_prev)\n",
        "plot_results(X_train_norm, Y_train, X_test_norm, Y_test, rede2_y_prev)\n",
        "show_metrics(Y_test, rede2_y_prev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_pHvCxs4S0T"
      },
      "outputs": [],
      "source": [
        "rede3 = MLPClassifier(**three_bests[2], max_iter=600, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxoGhLGz4S0T"
      },
      "outputs": [],
      "source": [
        "rede3.fit(X_train_norm.values, Y_train)\n",
        "rede3_y_prev = rede3.predict(X_test_norm)\n",
        "confusion_matrix_plot(Y_test, rede3_y_prev)\n",
        "plot_results(X_train_norm, Y_train, X_test_norm, Y_test, rede3_y_prev)\n",
        "show_metrics(Y_test, rede3_y_prev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-jwoYzpXzpM"
      },
      "source": [
        "### Argumente\n",
        "\n",
        "\"Houve melhoria no desempenho após o ajuste fino?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7C43KDJ4S0T"
      },
      "source": [
        "**Mesmo após o ajuste fino não houve melhoria nas métricas do modelo, com isto pode-se constatar que dentre as combinações possíveis dos parâmetros e hiperparametros inseridos na grade de busca, não estava dentre elas aquele que melhor funciona para o problema.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4pMGRAev6Fr"
      },
      "source": [
        "## Validação Cruzada k-fold\n",
        "\n",
        "Na elaboração da busca em grade e com sua posterior otimização, fomos capazes de identificar as três melhores arquiteturas para o problema. O passo seguinte consiste em avaliar a robustez da RNA MLP com melhor desempenho. Caso os valores de desempenho tenham sido muito próximos, assuma que é a melhor rede é a que possui menos parâmetros, isto é, a menor quantidade de pesos.\n",
        "\n",
        "Nessa etapa, vamos utilizar uma estratégia de validação cruzada ainda não explorada até o momento: a validação cruzada k-fold. Segundo a mesma, o conjunto de dados é particionado em k partes: a cada iteração, separa-se uma das partes para teste e o modelo é treinado com as k-1 partes remanescentes. Valores sugestivos de k na literatura são k = 3, 5 ou 10, pois o custo computacional desta validação dos modelos é alto. A métrica de desempenho é resultante da média dos desempenhos nas k iterações. A figura a seguir ilustra a ideia desta avaliação\n",
        "\n",
        "<img src = \"https://ethen8181.github.io/machine-learning/model_selection/img/kfolds.png\" width=600></img>\n",
        "\n",
        "Considerando a métrica de desempenho F1-Score, avalie a melhor RNA MLP no tocante ao seu desempenho em uma validação cruzada $10$-fold. Consulte: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html. Apresente claramente os resultados obtidos desta validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVaGXTaUVAmg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "# A melhor é a rede 2 considerando suas metricas e o número de neuronios "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s1dAc93XzpM"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiRk8TIFXzpM"
      },
      "outputs": [],
      "source": [
        "f1_scores = []\n",
        "\n",
        "for train_idx, test_idx in kf.split(predictive_attributes):\n",
        "    X_train, y_train = predictive_attributes.iloc[train_idx], target_attributes.iloc[train_idx]\n",
        "    X_test, y_test = predictive_attributes.iloc[test_idx], target_attributes.iloc[test_idx]\n",
        "    \n",
        "    best_score = 0\n",
        "        \n",
        "    rede2.fit(X_train, y_train)\n",
        "    y_pred = rede2.predict(X_test)\n",
        "    score = f1_score(y_test, y_pred,average='macro')\n",
        "    \n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "    \n",
        "    f1_scores.append(best_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6D8jaBL4S0U"
      },
      "outputs": [],
      "source": [
        "print(f1_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5s63pE6XzpM"
      },
      "source": [
        "### Argumente\n",
        "\n",
        "\"O modelo elencado como melhor mostrou-se robusto perante a validação cruzada 10-fold?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-93ZvyX4S0U"
      },
      "source": [
        "**Não, apesar de ser o melhor dentre as possíveis escolhas com os parâmetros recebidos, o modelo não se mostrou robusto a avaliação 10-fold.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFgIIIovv6Fu"
      },
      "source": [
        "## Empacotando a solução\n",
        "\n",
        "Suponha que você deva entregar este classificador ao órgão responsável pelo manejo dos abalones em uma determinada região. Para tanto, você deve fazer uma preparação do mesmo para utilização neste cenário. Uma vez que já identificou os melhores parâmetros e hiperparâmetros, o passo remanescente consiste em treinar o modelo com estes valores e todos os dados disponíveis, salvando o conjunto de pesos do modelo ao final para entrega ao cliente. Assim, finalize o projeto prático realizando tais passos.\n",
        "\n",
        "1. Consulte a documentação a seguir:\n",
        "https://scikit-learn.org/stable/modules/model_persistence.html  \n",
        "2. Treine o modelo com todos os dados  \n",
        "3. Salve o modelo em disco  \n",
        "4. Construa uma rotina que recupere o modelo em disco  \n",
        "5. Mostre que a rotina é funcional, fazendo previsões com todos os elementos do dataset e exibindo uma matriz de confusão das mesmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9o1T7pzVAmn",
        "outputId": "9cd1dbe0-e985-44c3-cc7b-4bf4a72f9b45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 16,\n",
              " 'beta_1': 0.8,\n",
              " 'hidden_layer_sizes': array([4, 4]),\n",
              " 'n_iter_no_change': 25,\n",
              " 'solver': 'adam'}"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from joblib import dump, load\n",
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxJ8HRLQXzpN",
        "outputId": "dbc7b8e6-4e66-4427-b714-2df6b63edd9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.27788232\n",
            "Validation score: 0.075085\n",
            "Iteration 2, loss = 2.90198377\n",
            "Validation score: 0.143345\n",
            "Iteration 3, loss = 2.61757729\n",
            "Validation score: 0.143345\n",
            "Iteration 4, loss = 2.54156232\n",
            "Validation score: 0.143345\n",
            "Iteration 5, loss = 2.50960324\n",
            "Validation score: 0.146758\n",
            "Iteration 6, loss = 2.48490870\n",
            "Validation score: 0.194539\n",
            "Iteration 7, loss = 2.45494218\n",
            "Validation score: 0.204778\n",
            "Iteration 8, loss = 2.42113709\n",
            "Validation score: 0.204778\n",
            "Iteration 9, loss = 2.38929297\n",
            "Validation score: 0.208191\n",
            "Iteration 10, loss = 2.36268615\n",
            "Validation score: 0.218430\n",
            "Iteration 11, loss = 2.34142616\n",
            "Validation score: 0.201365\n",
            "Iteration 12, loss = 2.32405886\n",
            "Validation score: 0.204778\n",
            "Iteration 13, loss = 2.30952146\n",
            "Validation score: 0.208191\n",
            "Iteration 14, loss = 2.29707310\n",
            "Validation score: 0.201365\n",
            "Iteration 15, loss = 2.28590376\n",
            "Validation score: 0.197952\n",
            "Iteration 16, loss = 2.27538042\n",
            "Validation score: 0.204778\n",
            "Iteration 17, loss = 2.26650071\n",
            "Validation score: 0.204778\n",
            "Iteration 18, loss = 2.25360556\n",
            "Validation score: 0.211604\n",
            "Iteration 19, loss = 2.24049004\n",
            "Validation score: 0.194539\n",
            "Iteration 20, loss = 2.22986143\n",
            "Validation score: 0.211604\n",
            "Iteration 21, loss = 2.21950983\n",
            "Validation score: 0.218430\n",
            "Iteration 22, loss = 2.20872106\n",
            "Validation score: 0.215017\n",
            "Iteration 23, loss = 2.19916403\n",
            "Validation score: 0.208191\n",
            "Iteration 24, loss = 2.19090770\n",
            "Validation score: 0.211604\n",
            "Iteration 25, loss = 2.18320774\n",
            "Validation score: 0.215017\n",
            "Iteration 26, loss = 2.17668073\n",
            "Validation score: 0.215017\n",
            "Iteration 27, loss = 2.17011335\n",
            "Validation score: 0.215017\n",
            "Iteration 28, loss = 2.16334560\n",
            "Validation score: 0.225256\n",
            "Iteration 29, loss = 2.15883940\n",
            "Validation score: 0.211604\n",
            "Iteration 30, loss = 2.15315676\n",
            "Validation score: 0.215017\n",
            "Iteration 31, loss = 2.14829643\n",
            "Validation score: 0.218430\n",
            "Iteration 32, loss = 2.14355380\n",
            "Validation score: 0.228669\n",
            "Iteration 33, loss = 2.13958212\n",
            "Validation score: 0.221843\n",
            "Iteration 34, loss = 2.13497734\n",
            "Validation score: 0.245734\n",
            "Iteration 35, loss = 2.13115849\n",
            "Validation score: 0.228669\n",
            "Iteration 36, loss = 2.12835086\n",
            "Validation score: 0.235495\n",
            "Iteration 37, loss = 2.12443446\n",
            "Validation score: 0.232082\n",
            "Iteration 38, loss = 2.12120250\n",
            "Validation score: 0.242321\n",
            "Iteration 39, loss = 2.11788687\n",
            "Validation score: 0.252560\n",
            "Iteration 40, loss = 2.11524944\n",
            "Validation score: 0.249147\n",
            "Iteration 41, loss = 2.11240160\n",
            "Validation score: 0.245734\n",
            "Iteration 42, loss = 2.10985115\n",
            "Validation score: 0.242321\n",
            "Iteration 43, loss = 2.10682414\n",
            "Validation score: 0.269625\n",
            "Iteration 44, loss = 2.10394845\n",
            "Validation score: 0.259386\n",
            "Iteration 45, loss = 2.10165394\n",
            "Validation score: 0.249147\n",
            "Iteration 46, loss = 2.09878692\n",
            "Validation score: 0.255973\n",
            "Iteration 47, loss = 2.09675930\n",
            "Validation score: 0.249147\n",
            "Iteration 48, loss = 2.09438225\n",
            "Validation score: 0.255973\n",
            "Iteration 49, loss = 2.09225485\n",
            "Validation score: 0.252560\n",
            "Iteration 50, loss = 2.08953826\n",
            "Validation score: 0.249147\n",
            "Iteration 51, loss = 2.08704756\n",
            "Validation score: 0.249147\n",
            "Iteration 52, loss = 2.08540222\n",
            "Validation score: 0.245734\n",
            "Iteration 53, loss = 2.08238198\n",
            "Validation score: 0.266212\n",
            "Iteration 54, loss = 2.07960957\n",
            "Validation score: 0.259386\n",
            "Iteration 55, loss = 2.07841033\n",
            "Validation score: 0.245734\n",
            "Iteration 56, loss = 2.07528416\n",
            "Validation score: 0.262799\n",
            "Iteration 57, loss = 2.07361615\n",
            "Validation score: 0.262799\n",
            "Iteration 58, loss = 2.07128526\n",
            "Validation score: 0.252560\n",
            "Iteration 59, loss = 2.06816424\n",
            "Validation score: 0.235495\n",
            "Iteration 60, loss = 2.06726959\n",
            "Validation score: 0.242321\n",
            "Iteration 61, loss = 2.06471390\n",
            "Validation score: 0.245734\n",
            "Iteration 62, loss = 2.06290078\n",
            "Validation score: 0.228669\n",
            "Iteration 63, loss = 2.06122403\n",
            "Validation score: 0.242321\n",
            "Iteration 64, loss = 2.05783135\n",
            "Validation score: 0.255973\n",
            "Iteration 65, loss = 2.05572072\n",
            "Validation score: 0.252560\n",
            "Iteration 66, loss = 2.05443213\n",
            "Validation score: 0.235495\n",
            "Iteration 67, loss = 2.05193626\n",
            "Validation score: 0.238908\n",
            "Iteration 68, loss = 2.04975718\n",
            "Validation score: 0.245734\n",
            "Iteration 69, loss = 2.04847389\n",
            "Validation score: 0.245734\n",
            "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(batch_size=16, beta_1=0.8, early_stopping=True,\n",
              "              hidden_layer_sizes=array([4, 4]), max_iter=300,\n",
              "              n_iter_no_change=25, verbose=True)"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bp = grid_search.best_params_\n",
        "best_rede = MLPClassifier(hidden_layer_sizes=bp['hidden_layer_sizes'], activation=bp['activation'], batch_size=bp['batch_size'], solver=bp['solver'],beta_1=bp['beta_1'], n_iter_no_change=bp['n_iter_no_change'], max_iter = 300, early_stopping=True, verbose=True)\n",
        "best_rede.fit(X_train_norm.values, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMIlMbKLXzpN"
      },
      "outputs": [],
      "source": [
        "# armazena o modelo no disco local do collab\n",
        "def storage_best_model(model, name_model):\n",
        "  dump(model, name_model)\n",
        "\n",
        "# Carrega um modelo presente no disco local do collab\n",
        "# Mostra as novas métricas dos resultados obtidos do modelo armazenado em disco\n",
        "# Exibi a matriz de confusão do modelo armazenado em disco\n",
        "def Courotine_in_prev_storaged_model(name_model, x_test, y_test):\n",
        "  new_rede = load(name_model)\n",
        "  y_rede_prev = new_rede.predict(x_test)\n",
        "  confusion_matrix_plot(y_test, y_rede_prev)\n",
        "  show_metrics(y_test, y_rede_prev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUxivCFmN8US"
      },
      "outputs": [],
      "source": [
        "storage_best_model(best_rede, 'Abalone_model_set.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "bVQrLgMqIkRA",
        "outputId": "b18d09fb-47a8-4bbc-aa12-0c0a1239cfa1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia:  0.24740622505985635\n",
            "F-score:  0.24740622505985635\n",
            "Precisão:  0.24740622505985635\n",
            "Revocação:  0.24740622505985635\n"
          ]
        }
      ],
      "source": [
        "Courotine_in_prev_storaged_model('Abalone_model_set.joblib', X_test.values, Y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}